{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae84cb9",
   "metadata": {},
   "source": [
    "<h1>Tutorial: Hierarchical Refinement for Large-Scale Optimal Transport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9cbc5c",
   "metadata": {},
   "source": [
    "This tutorial presents the implementation of the Hierarchical Refinement (HiRef) algorithm from the paper \"Hierarchical Refinement: Optimal Transport to Infinity and Beyond\" (Halmos et al., 2025). This algorithm solves the optimal transport (OT) problem for two large sets of points with linear memory complexity. The key idea is to exploit the fact that low-rank optimal transport solutions co-cluster each point with its image under the (bijective) Monge map. HiRef therefore recursively constructs a multi-scale partition of the data by solving a hierarchy of low-rank OT sub-problems, ultimately leading to a complete bijective coupling. Below we detail the implementation steps, highlighting methodological choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945f7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import operator\n",
    "import functools\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from ott.geometry import geometry\n",
    "from ott.problems.linear import linear_problem\n",
    "from ott.solvers.linear import sinkhorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cae2dc",
   "metadata": {},
   "source": [
    "# 1. Load images & model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084270ae",
   "metadata": {},
   "source": [
    "The tutorial begins by loading a set of images (here a subset of 5000 images from COCO/ImageNet). Each image is transformed (resized to 224×224 and converted to a tensor) then passed through a pre-trained neural network (ResNet-50). The final classification layer (model.fc = Identity) is removed to obtain only the feature vectors (embeddings) of dimension 2048."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9e27ff",
   "metadata": {},
   "source": [
    "We chose COCO because it's significantly lighter than ImageNet while still providing a robust dataset. The smaller size and complexity allows for faster training cycles and reduced computational requirements, making it more practical for our research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8173d8ca",
   "metadata": {},
   "source": [
    "To save time during future executions, we save the embeddings with pickle. In the end, we obtain an embeddings tensor of shape (5000, 2048) containing the vector representations of our images. So you can also directly go to part 3 if you want to start directly from the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d50b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        # Liste tous les fichiers .jpg\n",
    "        self.image_paths = [os.path.join(root_dir, fname)\n",
    "                            for fname in os.listdir(root_dir)\n",
    "                            if fname.endswith('.jpg')]\n",
    "        # Si le nombre d'images est impair, enlever la dernière\n",
    "        if len(self.image_paths) % 2 != 0:\n",
    "            self.image_paths = self.image_paths[:-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')  # Toujours convertir en RGB\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image  # Pas d'étiquette ici, juste l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1d362e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000 images from ImageNet!\n"
     ]
    }
   ],
   "source": [
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images for CNN input\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load COCO dataset from extracted path\n",
    "imagenet_dataset = CustomImageDataset(root_dir='images', transform=transform)\n",
    "\n",
    "\n",
    "# Create DataLoader for batching\n",
    "imagenet_loader = DataLoader(imagenet_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Loaded {len(imagenet_dataset)} images from ImageNet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "280953f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VONG\\AppData\\Local\\Temp\\ipykernel_11692\\1851330435.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.expanduser(\"resnet50-0676ba61.pth\")\n",
    "\n",
    "# Load pretrained ResNet model\n",
    "model = models.resnet50()\n",
    "model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "model.fc = torch.nn.Identity()  # Remove classification layer to extract features\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f1229",
   "metadata": {},
   "source": [
    "# 2. Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6001bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting embeddings!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 157/157 [00:57<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_features(dataloader, model):\n",
    "    \"\"\"\n",
    "    Compute embeddings\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for idx, images in tqdm(enumerate(dataloader), desc=\"Extracting features\", total=len(dataloader)):\n",
    "            images = images.to(device)\n",
    "            features = model(images)\n",
    "            embeddings.append(jnp.array(features.detach().cpu().numpy()))  \n",
    "    return jnp.vstack(embeddings)  # Stack all embeddings\n",
    "\n",
    "print('extracting embeddings!')\n",
    "embeddings = extract_features(imagenet_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0dbe4e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved successfully to embeddings/embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "with open('embeddings/embeddings.pkl', \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "print(\"Embeddings saved successfully to embeddings/embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb07d8",
   "metadata": {},
   "source": [
    "# 3. Load embeddings / Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde20a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded successfully! Shape: (5000, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings from the pickle file\n",
    "with open('embeddings/embeddings.pkl', \"rb\") as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "print(f\"Embeddings loaded successfully! Shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed818250",
   "metadata": {},
   "source": [
    "In the paper, OT is formulated between two uniform distributions of the same size, where the problem is actually an assignment problem (Monge bijection). To reproduce this, we start with the embeddings extracted from 5000 images and do:  \n",
    "Random permutation: We create a random index vector of size 5000 (fixed with a seed for reproducibility).  \n",
    "Separation into two equal subsets:We take the first 2500 entries of this permutation to form set X and the next 2500 for Y.  \n",
    "Thus, |X| = |Y| = 2500, with the same uniform measure a priori.\n",
    "These two sets X and Y of 2048-dim vectors will be the input points for the HiRef algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155a4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2500, 2048), Y shape: (2500, 2048)\n"
     ]
    }
   ],
   "source": [
    "num_samples = embeddings.shape[0]\n",
    "\n",
    "# Shuffle indices\n",
    "key = jax.random.PRNGKey(42)\n",
    "indices = jax.random.permutation(key, num_samples)\n",
    "\n",
    "# Split into two tensors\n",
    "X = embeddings[indices[:num_samples // 2]]\n",
    "Y = embeddings[indices[num_samples // 2:]]\n",
    "\n",
    "print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa4c1e",
   "metadata": {},
   "source": [
    "# 4. Sinkhorn with epsilon-schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd34493",
   "metadata": {},
   "source": [
    "Entropic optimal transport with the Sinkhorn algorithm is the foundation on which we'll build. Here's an implementation of the log-stabilized Sinkhorn with the utility functions for optimal transport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e92a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ott_log_sinkhorn(grad,\n",
    "                     a,\n",
    "                     b,\n",
    "                     gamma_k,\n",
    "                     max_iter = 50,\n",
    "                     balanced = True,\n",
    "                     unbalanced = False,\n",
    "                     tau = None,\n",
    "                     tau2 = None):\n",
    "    \"\"\"\n",
    "    grad: cost matrix (n, m)\n",
    "    a: source histogram (n,)\n",
    "    b: target histogram (m,)\n",
    "    gamma_k: régularisation inverse (1/epsilon)\n",
    "    \"\"\"\n",
    "    epsilon = 1.0 / gamma_k\n",
    "\n",
    "    # Choix des tau pour marges\n",
    "    if balanced and not unbalanced:\n",
    "        tau_a, tau_b = 1.0, 1.0\n",
    "    elif not balanced and unbalanced:\n",
    "        tau_a = tau / (tau + epsilon)\n",
    "        tau_b = tau2 / (tau2 + epsilon) if tau2 is not None else tau_a\n",
    "    else:  # semi-relaxed\n",
    "        tau_a, tau_b = 1.0, tau / (tau + epsilon)\n",
    "\n",
    "    # Géométrie entropique sur la matrice de coût\n",
    "    geom = geometry.Geometry(cost_matrix=grad, epsilon=epsilon)\n",
    "\n",
    "    # Construction du problème linéaire\n",
    "    prob = linear_problem.LinearProblem(\n",
    "        geom,\n",
    "        a=a,\n",
    "        b=b,\n",
    "        tau_a=tau_a,\n",
    "        tau_b=tau_b\n",
    "    )\n",
    "\n",
    "    # Solveur Sinkhorn\n",
    "    solver = sinkhorn.Sinkhorn(max_iterations=max_iter)\n",
    "    out = solver(prob)\n",
    "\n",
    "    return out.matrix\n",
    "\n",
    "def utils__Delta(vark, varkm1, gamma_k):\n",
    "    return (gamma_k**-2) * (jnp.linalg.norm(vark[0] - varkm1[0]) + jnp.linalg.norm(vark[1] - varkm1[1]) + jnp.linalg.norm(vark[2] - varkm1[2]))\n",
    "\n",
    "def utils__random_simplex_sample(key, N, dtype = jnp.float64):\n",
    "    \"\"\"\n",
    "    Draws a random point from the (N-1)-simplex using normalized exponentiated Gaussian variates.\n",
    "\n",
    "    Args:\n",
    "        key: PRNGKey for random number generation.\n",
    "        N: Dimensionality of the simplex (vector length).\n",
    "        dtype: Desired floating-point type of the output.\n",
    "\n",
    "    Returns:\n",
    "        A 1D array of shape (N,) with non-negative entries summing to 1.\n",
    "    \"\"\"\n",
    "    # Sample N independent standard normals\n",
    "    z = jax.random.normal(key, shape=(N,), dtype=dtype)\n",
    "    # Exponentiate\n",
    "    e = jnp.exp(z)\n",
    "    # Normalize to sum to 1\n",
    "    return e / jnp.sum(e)\n",
    "\n",
    "def utils__initialize_couplings(a, b, gQ, gR, gamma, full_rank = True, key = jax.random.PRNGKey(0), dtype = float, rank2_random = False, max_iter = 50):\n",
    "    \"\"\"\n",
    "    Initialize coupling factors in JAX.\n",
    "    \"\"\"\n",
    "    N1 = a.shape[0]\n",
    "    N2 = b.shape[0]\n",
    "    r = gQ.shape[0]\n",
    "    r2 = gR.shape[0]\n",
    "\n",
    "    one_N1 = jnp.ones((N1,), dtype=dtype)\n",
    "    one_N2 = jnp.ones((N2,), dtype=dtype)\n",
    "\n",
    "    if full_rank:\n",
    "        # Full-rank initialization via log-Sinkhorn\n",
    "        key, subkey = jax.random.split(key)\n",
    "        C_random = jax.random.uniform(subkey, (N1, r), dtype=dtype)\n",
    "        Q = ott_log_sinkhorn(C_random, a, gQ, gamma,\n",
    "                                max_iter=max_iter,\n",
    "                                balanced=True)\n",
    "\n",
    "        key, subkey = jax.random.split(key)\n",
    "        C_random = jax.random.uniform(subkey, (N2, r2), dtype=dtype)\n",
    "        R = ott_log_sinkhorn(C_random, b, gR, gamma,\n",
    "                                max_iter=max_iter,\n",
    "                                balanced=True)\n",
    "\n",
    "        # Compute updated inner marginals\n",
    "        gR_new = R.T @ one_N2\n",
    "        gQ_new = Q.T @ one_N1\n",
    "\n",
    "        key, subkey = jax.random.split(key)\n",
    "        C_random = jax.random.uniform(subkey, (r, r2), dtype=dtype)\n",
    "        T = ott_log_sinkhorn(C_random, gQ_new, gR_new, gamma,\n",
    "                                max_iter=max_iter,\n",
    "                                balanced=True)\n",
    "\n",
    "        # Inner inverse coupling\n",
    "        if r == r2:\n",
    "            Lambda = jnp.linalg.inv(T)\n",
    "        else:\n",
    "            Lambda = jnp.diag(1.0 / gQ_new) @ T @ jnp.diag(1.0 / gR_new)\n",
    "\n",
    "    else:\n",
    "        # Rank-2 initialization (Scetbon et al. 2021)\n",
    "        if r != r2:\n",
    "            raise ValueError(\"Rank-2 init requires equal inner ranks.\")\n",
    "        g = gQ\n",
    "        lambd = jnp.minimum(jnp.min(a), jnp.min(b))\n",
    "        lambd = jnp.minimum(lambd, jnp.min(g)) / 2.0\n",
    "\n",
    "        # Sample or deterministic\n",
    "        if rank2_random:\n",
    "            key, *splits = random.split(key, 4)\n",
    "            a1 = utils__random_simplex_sample(N1, splits[0], dtype)\n",
    "            b1 = utils__random_simplex_sample(N2, splits[1], dtype)\n",
    "            g1 = utils__random_simplex_sample(r, splits[2], dtype)\n",
    "        else:\n",
    "            g1 = jnp.arange(1, r + 1, dtype=dtype)\n",
    "            g1 = g1 / jnp.sum(g1)\n",
    "            a1 = jnp.arange(1, N1 + 1, dtype=dtype)\n",
    "            a1 = a1 / jnp.sum(a1)\n",
    "            b1 = jnp.arange(1, N2 + 1, dtype=dtype)\n",
    "            b1 = b1 / jnp.sum(b1)\n",
    "\n",
    "        a2 = (a - lambd * a1) / (1 - lambd)\n",
    "        b2 = (b - lambd * b1) / (1 - lambd)\n",
    "        g2 = (g - lambd * g1) / (1 - lambd)\n",
    "\n",
    "        Q = lambd * jnp.outer(a1, g1) + (1 - lambd) * jnp.outer(a2, g2)\n",
    "        R = lambd * jnp.outer(b1, g1) + (1 - lambd) * jnp.outer(b2, g2)\n",
    "\n",
    "        gR_new = R.T @ one_N2\n",
    "        gQ_new = Q.T @ one_N1\n",
    "\n",
    "        T = (1 - lambd) * jnp.diag(g) + lambd * jnp.outer(gR_new, gQ_new)\n",
    "        Lambda = jnp.linalg.inv(T)\n",
    "\n",
    "    return Q, R, T, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "905adddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd__compute_grad_A(C, Q, R, Lambda, gamma,\n",
    "                       semiRelaxedLeft, semiRelaxedRight,\n",
    "                       Wasserstein = True, FGW = False,\n",
    "                       A  = None,\n",
    "                       B = None,\n",
    "                       alpha = 0.0,\n",
    "                       unbalanced = False,\n",
    "                       full_grad = True):\n",
    "    \"\"\"\n",
    "    JAX version of gradient computation for Wasserstein, GW and FGW.\n",
    "    \"\"\"\n",
    "\n",
    "    r = Lambda.shape[0]\n",
    "    one_r = jnp.ones((r,))\n",
    "    One_rr = jnp.outer(one_r, one_r)\n",
    "\n",
    "    if Wasserstein:\n",
    "        gradQ, gradR = gd__Wasserstein_Grad(C, Q, R, Lambda, full_grad=full_grad)  # À adapter avec OTT-JAX\n",
    "    elif A is not None and B is not None:\n",
    "        if not semiRelaxedLeft and not semiRelaxedRight and not unbalanced:\n",
    "            gradQ = -4 * (A @ Q) @ Lambda @ (R.T @ B @ R) @ Lambda.T\n",
    "            gradR = -4 * (B @ R @ Lambda.T) @ (Q.T @ A @ Q) @ Lambda\n",
    "        elif semiRelaxedRight:\n",
    "            gradQ = -4 * (A @ Q) @ Lambda @ (R.T @ B @ R) @ Lambda.T\n",
    "            gradR = 2 * (B @ B) @ R @ One_rr - 4 * (B @ R @ Lambda.T) @ (Q.T @ A @ Q) @ Lambda\n",
    "        elif semiRelaxedLeft:\n",
    "            gradQ = 2 * (A @ A) @ Q @ One_rr - 4 * (A @ Q) @ Lambda @ (R.T @ B @ R) @ Lambda.T\n",
    "            gradR = -4 * (B @ R @ Lambda.T) @ (Q.T @ A @ Q) @ Lambda\n",
    "        elif unbalanced:\n",
    "            gradQ = 2 * (A @ A) @ Q @ One_rr - 4 * (A @ Q) @ Lambda @ (R.T @ B @ R) @ Lambda.T\n",
    "            gradR = 2 * (B @ B) @ R @ One_rr - 4 * (B @ R @ Lambda.T) @ (Q.T @ A @ Q) @ Lambda\n",
    "\n",
    "        if full_grad:\n",
    "            N1, N2 = Q.shape[0], R.shape[0]\n",
    "            one_N1 = jnp.ones((N1,))\n",
    "            one_N2 = jnp.ones((N2,))\n",
    "            gQ = Q.T @ one_N1\n",
    "            gR = R.T @ one_N2\n",
    "            F = Q @ Lambda @ R.T\n",
    "            MR = Lambda.T @ Q.T @ A @ F @ B @ R @ jnp.diag(1. / gR)\n",
    "            MQ = Lambda @ R.T @ B @ F.T @ A @ Q @ jnp.diag(1. / gQ)\n",
    "            gradQ += 4 * jnp.outer(one_N1, jnp.diag(MQ))\n",
    "            gradR += 4 * jnp.outer(one_N2, jnp.diag(MR))\n",
    "\n",
    "        if FGW:\n",
    "            gradQW, gradRW = gd__Wasserstein_Grad(C, Q, R, Lambda, full_grad=full_grad)  # À adapter\n",
    "            gradQ = (1 - alpha) * gradQW + alpha * gradQ\n",
    "            gradR = (1 - alpha) * gradRW + alpha * gradR\n",
    "    else:\n",
    "        raise ValueError(\"Provide either Wasserstein=True or distance matrices A and B for GW problem.\")\n",
    "\n",
    "    normalizer = jnp.max(jnp.array([jnp.max(jnp.abs(gradQ)), jnp.max(jnp.abs(gradR))]))\n",
    "    gamma_k = gamma / normalizer\n",
    "\n",
    "    return gradQ, gradR, gamma_k\n",
    "\n",
    "\n",
    "def gd__compute_grad_B(C, Q, R, Lambda, gQ, gR, gamma, Wasserstein=True,\n",
    "                       FGW=False, A=None, B=None, alpha=0.0):\n",
    "    '''\n",
    "    JAX version of the Wasserstein / GW / FGW gradient w.r.t. the transport plan T.\n",
    "    '''\n",
    "    if Wasserstein:\n",
    "        gradLambda = Q.T @ C @ R\n",
    "    else:\n",
    "        gradLambda = -4 * Q.T @ A @ Q @ Lambda @ R.T @ B @ R\n",
    "        if FGW:\n",
    "            gradLambda = (1 - alpha) * (Q.T @ C @ R) + alpha * gradLambda\n",
    "\n",
    "    gradT = jnp.diag(1.0 / gQ) @ gradLambda @ jnp.diag(1.0 / gR)\n",
    "    gamma_T = gamma / jnp.max(jnp.abs(gradT))\n",
    "    return gradT, gamma_T\n",
    "\n",
    "def gd__Wasserstein_Grad(C, Q, R, Lambda, full_grad=True):\n",
    "    gradQ = (C @ R) @ Lambda.T\n",
    "    if full_grad:\n",
    "        N1 = Q.shape[0]\n",
    "        one_N1 = jnp.ones((N1,), dtype=Q.dtype)\n",
    "        gQ = Q.T @ one_N1\n",
    "        w1 = jnp.diag((gradQ.T @ Q) @ jnp.diag(1.0 / gQ))\n",
    "        gradQ = gradQ - jnp.outer(one_N1, w1)\n",
    "\n",
    "    gradR = (C.T @ Q) @ Lambda\n",
    "    if full_grad:\n",
    "        N2 = R.shape[0]\n",
    "        one_N2 = jnp.ones((N2,), dtype=R.dtype)\n",
    "        gR = R.T @ one_N2\n",
    "        w2 = jnp.diag(jnp.diag(1.0 / gR) @ (R.T @ gradR))\n",
    "        gradR = gradR - jnp.outer(one_N2, w2)\n",
    "\n",
    "    return gradQ, gradR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "953000d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FRLC_opt(C, a=None, b=None, A=None, B=None, tau_in=50, tau_out=50,\n",
    "             gamma=90, r=10, r2=None, max_iter=200,\n",
    "             semiRelaxedLeft=False, semiRelaxedRight=False, Wasserstein=True,\n",
    "             returnFull=False, FGW=False, alpha=0.0, unbalanced=False,\n",
    "             initialization='Full', init_args=None, full_grad=True,\n",
    "             convergence_criterion=True, tol=1e-5, min_iter=25,\n",
    "             min_iterGW=500, max_iterGW=1000,\n",
    "             max_inneriters_balanced=300, max_inneriters_relaxed=50,\n",
    "             diagonalize_return=False):\n",
    "\n",
    "    N1, N2 = C.shape\n",
    "    k = 0\n",
    "\n",
    "    one_N1 = jnp.ones((N1,))\n",
    "    one_N2 = jnp.ones((N2,))\n",
    "\n",
    "    if a is None:\n",
    "        a = one_N1 / N1\n",
    "    if b is None:\n",
    "        b = one_N2 / N2\n",
    "    if r2 is None:\n",
    "        r2 = r\n",
    "\n",
    "    one_r = jnp.ones((r,))\n",
    "    one_r2 = jnp.ones((r2,))\n",
    "\n",
    "    gQ = one_r / r\n",
    "    gR = one_r2 / r2\n",
    "\n",
    "    full_rank = initialization == 'Full' or initialization not in ['Full', 'Rank-2']\n",
    "\n",
    "    if init_args is None:\n",
    "        Q, R, T, Lambda = utils__initialize_couplings(a, b, gQ, gR,\n",
    "                                                      gamma, full_rank=full_rank,\n",
    "                                                      max_iter=max_inneriters_balanced)\n",
    "    else:\n",
    "        Q, R, T = init_args\n",
    "        Lambda = jnp.diag(1 / (Q.T @ one_N1)) @ T @ jnp.diag(1 / (R.T @ one_N2))\n",
    "\n",
    "    if not Wasserstein:\n",
    "        min_iter = min_iterGW\n",
    "        max_iter = max_iterGW\n",
    "\n",
    "    errs = []\n",
    "    gamma_k = gamma\n",
    "    Q_prev, R_prev, T_prev = None, None, None\n",
    "\n",
    "    def not_converged(k, Q, R, T, Q_prev, R_prev, T_prev, gamma_k):\n",
    "        if not convergence_criterion:\n",
    "            return True\n",
    "        if k < min_iter:\n",
    "            return True\n",
    "        delta = utils__Delta((Q, R, T), (Q_prev, R_prev, T_prev), gamma_k)\n",
    "        return delta > tol\n",
    "\n",
    "    while (k < max_iter and not_converged(k, Q, R, T, Q_prev, R_prev, T_prev, gamma_k)):\n",
    "        if convergence_criterion:\n",
    "            Q_prev, R_prev, T_prev = Q, R, T\n",
    "\n",
    "        if k % 25 == 0:\n",
    "            print(f'Iteration: {k}')\n",
    "\n",
    "        gradQ, gradR, gamma_k = gd__compute_grad_A(C, Q, R, Lambda, gamma,\n",
    "                                                   semiRelaxedLeft, semiRelaxedRight,\n",
    "                                                   Wasserstein=Wasserstein, A=A, B=B,\n",
    "                                                   FGW=FGW, alpha=alpha,\n",
    "                                                   unbalanced=unbalanced, full_grad=full_grad)\n",
    "\n",
    "        logQ = jnp.log(Q)\n",
    "        logR = jnp.log(R)\n",
    "\n",
    "        # Gestion explicite des modes de relaxation\n",
    "        if semiRelaxedLeft:\n",
    "            balanced_Q, unbalanced_Q = False, True\n",
    "            balanced_R, unbalanced_R = False, False\n",
    "        elif semiRelaxedRight:\n",
    "            balanced_Q, unbalanced_Q = False, False\n",
    "            balanced_R, unbalanced_R = False, True\n",
    "        elif unbalanced:\n",
    "            balanced_Q, unbalanced_Q = False, True\n",
    "            balanced_R, unbalanced_R = False, True\n",
    "        else:\n",
    "            balanced_Q, unbalanced_Q = True, False\n",
    "            balanced_R, unbalanced_R = True, False\n",
    "\n",
    "        Q = ott_log_sinkhorn(gradQ - (1 / gamma_k) * logQ, a, gQ, gamma_k,\n",
    "                             max_iter=max_inneriters_relaxed,\n",
    "                             balanced=balanced_Q, unbalanced=unbalanced_Q,\n",
    "                             tau=tau_out, tau2=tau_in)\n",
    "\n",
    "        R = ott_log_sinkhorn(gradR - (1 / gamma_k) * logR, b, gR, gamma_k,\n",
    "                             max_iter=max_inneriters_relaxed,\n",
    "                             balanced=balanced_R, unbalanced=unbalanced_R,\n",
    "                             tau=tau_out, tau2=tau_in)\n",
    "\n",
    "        gQ = Q.T @ one_N1\n",
    "        gR = R.T @ one_N2\n",
    "\n",
    "        gradT, gamma_T = gd__compute_grad_B(C, Q, R, Lambda, gQ, gR,\n",
    "                                            gamma, Wasserstein=Wasserstein,\n",
    "                                            A=A, B=B, FGW=FGW, alpha=alpha)\n",
    "\n",
    "        T = ott_log_sinkhorn(gradT - (1 / gamma_T) * jnp.log(T), gQ, gR, gamma_T,\n",
    "                             max_iter=max_inneriters_balanced,\n",
    "                             balanced=True, unbalanced=False)\n",
    "\n",
    "        Lambda = jnp.diag(1 / gQ) @ T @ jnp.diag(1 / gR)\n",
    "        k += 1\n",
    "\n",
    "    if returnFull:\n",
    "        P = Q @ Lambda @ R.T\n",
    "        return P, errs\n",
    "    else:\n",
    "        if diagonalize_return:\n",
    "            Q = Q @ jnp.diag(1 / gQ) @ T\n",
    "            gR = R.T @ one_N2\n",
    "            T = jnp.diag(gR)\n",
    "        return Q, R, T, errs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def FRLC_compute_OT_cost(X, Y, C = None, Monge_clusters = None, sq_Euclidean = True):\n",
    "    \"\"\"\n",
    "    Compute the optimal transport cost in linear space and time (without coupling), in JAX.\n",
    "    Supports squared Euclidean cost via OTT cost object.\n",
    "    \"\"\"\n",
    "    if Monge_clusters is None or len(Monge_clusters) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    def compute_pair_cost(pair):\n",
    "        idx1, idx2 = pair\n",
    "        if C is not None:\n",
    "            return C[idx1, idx2]\n",
    "        else:\n",
    "            diff = X[idx1] - Y[idx2]\n",
    "            if sq_Euclidean:\n",
    "                return jnp.sum(diff**2)\n",
    "            else:\n",
    "                return jnp.linalg.norm(diff)\n",
    "\n",
    "    pair_costs = jax.vmap(compute_pair_cost)(jnp.array(Monge_clusters))\n",
    "    total_cost = jnp.sum(pair_costs)\n",
    "    return total_cost / len(Monge_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b05f2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "Iteration: 75\n",
      "FRLC cost: 24.058168411254883\n"
     ]
    }
   ],
   "source": [
    "# 1. Calcul de la matrice des coûts (distance euclidienne)\n",
    "def cdist_jax(X, Y):\n",
    "    # ||x - y||^2 = ||x||^2 + ||y||^2 - 2<x, y>\n",
    "    X_norm = jnp.sum(X ** 2, axis=1)[:, None]\n",
    "    Y_norm = jnp.sum(Y ** 2, axis=1)[None, :]\n",
    "    C = jnp.sqrt(jnp.maximum(X_norm + Y_norm - 2 * jnp.dot(X, Y.T), 0.0))\n",
    "    return C\n",
    "\n",
    "C = cdist_jax(X, Y)\n",
    "\n",
    "try:\n",
    "    # 2. Appel à FRLC_opt (on passe dtype=jnp.float32)\n",
    "    Q, R, T, errs = FRLC_opt(\n",
    "        C=C,\n",
    "        gamma=30,\n",
    "        r=40,\n",
    "        max_iter=100,\n",
    "        tau_in=100000\n",
    "    )\n",
    "\n",
    "    # 3. Calcul de la matrice de couplage P complète\n",
    "    inv_sum_Q = 1.0 / jnp.sum(Q, axis=0)  # shape (r,)\n",
    "    inv_sum_R = 1.0 / jnp.sum(R, axis=0)  # shape (r,)\n",
    "    P = (Q\n",
    "         @ jnp.diag(inv_sum_Q)\n",
    "         @ T\n",
    "         @ jnp.diag(inv_sum_R)\n",
    "         @ R.T)  # shape (n_X, n_Y)\n",
    "\n",
    "    # 4. Extraction des paires (i,j) où P[i,j] > 0\n",
    "    ij = jnp.argwhere(P > 0)  # shape (num_pairs, 2)\n",
    "    Monge_clusters = [(int(i), int(j)) for i, j in ij]\n",
    "\n",
    "    # 5. Calcul du coût OT via la fonction JAXisée\n",
    "    cost_frlc = FRLC_compute_OT_cost(\n",
    "        X, Y,\n",
    "        C=C,\n",
    "        Monge_clusters=Monge_clusters,\n",
    "        sq_Euclidean=True\n",
    "    )\n",
    "\n",
    "    print(f'FRLC cost: {cost_frlc}')\n",
    "\n",
    "    # 6. Approximation du couplage pour l'extraction de correspondances\n",
    "    P_approx = Q @ T @ R.T  # shape (n_X, n_Y)\n",
    "    matches_Y = jnp.argmax(P_approx, axis=1)  # shape (n_X,)\n",
    "\n",
    "    # 7. Construction de la liste F de paires indices\n",
    "    F = [\n",
    "        (jnp.array([i], dtype=jnp.int32),\n",
    "         jnp.array([int(matches_Y[i])], dtype=jnp.int32))\n",
    "        for i in range(X.shape[0])\n",
    "    ]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'FRLC failed for sample size {X.shape[0]}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1158f",
   "metadata": {},
   "source": [
    "# 5. Hierarchical Refinement Algorithm Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a4f4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "--------------\n",
    "Code for gradients assuming low-rank distance matrices C, A, B\n",
    "--------------\n",
    "'''\n",
    "\n",
    "def gd__compute_grad_A_LR(C_factors, A_factors, B_factors, Q, R, Lambda, gamma, alpha=0.0, full_grad=False):\n",
    "    \n",
    "    N1, N2 = C_factors[0].shape[0], C_factors[1].shape[1]\n",
    "\n",
    "    if A_factors is not None and B_factors is not None:\n",
    "        A1, A2 = A_factors\n",
    "        B1, B2 = B_factors\n",
    "\n",
    "        # GW gradients\n",
    "        gradQ = -4 * (A1 @ (A2 @ (Q @ Lambda @ ((R.T @ B1) @ (B2 @ R)) @ Lambda.T)))\n",
    "        gradR = -4 * (B1 @ (B2 @ (R @ (Lambda.T @ ((Q.T @ A1) @ (A2 @ Q)) @ Lambda))))\n",
    "\n",
    "        one_N1 = jnp.ones((N1,), dtype=Q.dtype)\n",
    "        one_N2 = jnp.ones((N2,), dtype=R.dtype)\n",
    "\n",
    "        if full_grad:\n",
    "            gQ = Q.T @ one_N1\n",
    "            gR = R.T @ one_N2\n",
    "\n",
    "            MR = (Lambda.T @ ((Q.T @ A1) @ (A2 @ Q)) @ Lambda\n",
    "                  @ ((R.T @ B1) @ (B2 @ R)) @ jnp.diag(1.0 / gR))\n",
    "            MQ = (Lambda @ ((R.T @ B1) @ (B2 @ R)) @ Lambda.T\n",
    "                  @ ((Q.T @ A1) @ (A2 @ Q)) @ jnp.diag(1.0 / gQ))\n",
    "\n",
    "            gradQ += 4 * jnp.outer(one_N1, jnp.diag(MQ))\n",
    "            gradR += 4 * jnp.outer(one_N2, jnp.diag(MR))\n",
    "    else:\n",
    "        gradQ = jnp.zeros_like(Q)\n",
    "        gradR = jnp.zeros_like(R)\n",
    "\n",
    "    # Appel à une version jaxifiée de gd__Wasserstein_Grad_LR\n",
    "    gradQW, gradRW = gd__Wasserstein_Grad_LR(C_factors, Q, R, Lambda, full_grad=full_grad)\n",
    "\n",
    "    gradQ = (1 - alpha) * gradQW + (alpha / 2.0) * gradQ\n",
    "    gradR = (1 - alpha) * gradRW + (alpha / 2.0) * gradR\n",
    "\n",
    "    normalizer = jnp.maximum(jnp.max(jnp.abs(gradQ)), jnp.max(jnp.abs(gradR)))\n",
    "    gamma_k = gamma / normalizer\n",
    "\n",
    "    return gradQ, gradR, gamma_k\n",
    "\n",
    "def gd__compute_grad_B_LR(C_factors, A_factors, B_factors, Q, R, Lambda, gQ, gR, gamma, alpha=0.0):\n",
    "    \"\"\"\n",
    "    Low-rank gradient computation in JAX for Wasserstein / Gromov-Wasserstein.\n",
    "    \"\"\"\n",
    "    C1, C2 = C_factors  # (N1, rC), (rC, N2)\n",
    "    gradLambda = 0.0\n",
    "\n",
    "    if A_factors is not None and B_factors is not None:\n",
    "        A1, A2 = A_factors  # (N1, rA), (rA, N1)\n",
    "        B1, B2 = B_factors  # (N2, rB), (rB, N2)\n",
    "        term_A = (Q.T @ A1) @ (A2 @ Q)         # shape: (r, r)\n",
    "        term_B = (R.T @ B1) @ (B2 @ R)         # shape: (r, r)\n",
    "        gradLambda = -4.0 * term_A @ Lambda @ term_B\n",
    "\n",
    "    term_C = (Q.T @ C1) @ (C2 @ R)             # shape: (r, r)\n",
    "    gradLambda = (1 - alpha) * term_C + (alpha / 2.0) * gradLambda\n",
    "\n",
    "    gradT = jnp.diag(1.0 / gQ) @ gradLambda @ jnp.diag(1.0 / gR)\n",
    "    gamma_T = gamma / jnp.max(jnp.abs(gradT))\n",
    "    return gradT, gamma_T\n",
    "\n",
    "def gd__Wasserstein_Grad_LR(C_factors, Q, R, Lambda, full_grad=True):\n",
    "    \"\"\"\n",
    "    JAX version of Wasserstein gradient with low-rank cost approximation:\n",
    "    C ≈ C1 @ C2.T\n",
    "    \"\"\"\n",
    "    C1, C2 = C_factors\n",
    "\n",
    "    gradQ = C1 @ ((C2 @ R) @ Lambda.T)\n",
    "    if full_grad:\n",
    "        N1 = Q.shape[0]\n",
    "        one_N1 = jnp.ones((N1,), dtype=Q.dtype)\n",
    "        gQ = Q.T @ one_N1\n",
    "        w1 = jnp.diag((gradQ.T @ Q) @ jnp.diag(1.0 / gQ))\n",
    "        gradQ = gradQ - jnp.outer(one_N1, w1)\n",
    "\n",
    "    gradR = C2.T @ ((C1.T @ Q) @ Lambda)\n",
    "    if full_grad:\n",
    "        N2 = R.shape[0]\n",
    "        one_N2 = jnp.ones((N2,), dtype=R.dtype)\n",
    "        gR = R.T @ one_N2\n",
    "        w2 = jnp.diag(jnp.diag(1.0 / gR) @ (R.T @ gradR))\n",
    "        gradR = gradR - jnp.outer(one_N2, w2)\n",
    "\n",
    "    return gradQ, gradR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e3726",
   "metadata": {},
   "source": [
    "<h2> Rank annealing schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc954f0c",
   "metadata": {},
   "source": [
    "HiRef works according to a hierarchy of sub-problems with increasing ranks. It is crucial to determine a \"rank schedule\" such that the cluster size is progressively reduced until the final rank.  \n",
    "The code automatically calculates an optimal rank annealing schedule by factorizing the size n = 2500 into products of factors, while respecting a maximum depth. For this:\n",
    "\n",
    ".We look for a largest possible factor Q (by default 2048) of n, corresponding to the terminal rank (before switching to 1-1 correspondence). Here, for n=2500, we get Q = 1250.  \n",
    ".We solve a small dynamic program (rank_annealing__min_sum_partial_products_with_factors) that factorizes n / Q = 2 into at most k factors (here depth 6) with a constraint on the intermediate rank (here max_rank=64).  \n",
    "For ndivQ=2 and k=6, the only factorization is trivially 2 = 2.\n",
    ".We thus obtain the final sorted schedule, excluding 1: rank_schedule = [2, 1250]. In other words, we will first process an OT at rank 2 on 2500 points, then an OT at rank 1250 on each subset.  \n",
    ".The code verifies that the product of the ranks gives n (here 2×1250=2500).\n",
    "\n",
    "This schedule corresponds  to the \"factor decomposition\" used in the paper to refine the resolution. At each step i (rank r_i), we will divide the points into r_i clusters of the same capacity, decreasing the size of the sub-problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe4033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:76: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:76: SyntaxWarning: invalid escape sequence '\\l'\n",
      "/tmp/ipykernel_5029/427638459.py:15: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  \"\"\"\n",
      "/tmp/ipykernel_5029/427638459.py:23: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  \"\"\"\n",
      "/tmp/ipykernel_5029/427638459.py:76: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def rank_annealing__factors(n):\n",
    "    \"\"\"\n",
    "    Return list of all factors of an integer\n",
    "    \"\"\"\n",
    "    n = int(n)  # Conversion pour compatibilité avec jnp.arange\n",
    "    candidates = jnp.arange(1, jnp.floor(jnp.sqrt(n)) + 1).astype(int)\n",
    "    divisible = (n % candidates) == 0\n",
    "    factors1 = candidates[divisible]\n",
    "    factors2 = n // factors1\n",
    "    all_factors = jnp.concatenate([factors1, factors2])\n",
    "    unique_factors = jnp.unique(all_factors)\n",
    "    return unique_factors\n",
    "\n",
    "def rank_annealing__max_factor_lX(n, max_X):\n",
    "    \"\"\"\n",
    "    Find max factor of n , such that max_factor \\leq max_X\n",
    "    \"\"\"\n",
    "    factor_lst = rank_annealing__factors(n)\n",
    "    factors_leq_max = factor_lst[factor_lst <= max_X]\n",
    "    return jnp.max(factors_leq_max)\n",
    "\n",
    "def rank_annealing__min_sum_partial_products_with_factors(n, k, C):\n",
    "    \"\"\"\n",
    "    Dynamic program to compute the rank-schedule, subject to a constraint of intermediates being \\leq C\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        The dataset size to be factored into a rank-scheduler. Assumed to be non-prime.\n",
    "    k: int\n",
    "        The depth of the hierarchy.\n",
    "    C: int\n",
    "        A constraint on the maximal intermediate rank across the hierarchy.\n",
    "    \n",
    "    \"\"\"\n",
    "    INF = 1e10  # Large constant instead of float('inf') for JAX compatibility\n",
    "\n",
    "    dp = jnp.full((n+1, k+1), INF)\n",
    "    choice = jnp.full((n+1, k+1), -1)\n",
    "\n",
    "    def init_base_case(dp, choice):\n",
    "        d = jnp.arange(1, n+1)\n",
    "        mask = d <= C\n",
    "        dp = dp.at[d[mask], 1].set(d[mask])\n",
    "        choice = choice.at[d[mask], 1].set(d[mask])\n",
    "        return dp, choice\n",
    "\n",
    "    dp, choice = init_base_case(dp, choice)\n",
    "\n",
    "    for t in range(2, k+1):\n",
    "        for d in range(1, n+1):\n",
    "            if dp[d, t-1] >= INF:\n",
    "                continue\n",
    "            for r in range(1, min(C, d)+1):\n",
    "                if d % r == 0:\n",
    "                    candidate = r + r * dp[d // r, t-1]\n",
    "                    if candidate < dp[d, t]:\n",
    "                        dp = dp.at[d, t].set(candidate)\n",
    "                        choice = choice.at[d, t].set(r)\n",
    "\n",
    "    if dp[n, k] >= INF:\n",
    "        return None, []\n",
    "\n",
    "    # Backtracking\n",
    "    factors = []\n",
    "    d_cur, t_cur = n, k\n",
    "    while t_cur > 0:\n",
    "        r_cur = int(choice[d_cur, t_cur])\n",
    "        factors.append(r_cur)\n",
    "        d_cur //= r_cur\n",
    "        t_cur -= 1\n",
    "\n",
    "    return dp[n, k], factors\n",
    "\n",
    "def rank_annealing__optimal_rank_schedule(n, hierarchy_depth=6, max_Q=int(2**10), max_rank=16):\n",
    "    \"\"\"\n",
    "    A function to compute the optimal rank-scheduler of refinement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Size of the input dataset -- cannot be a prime number\n",
    "    hierarchy_depth: int\n",
    "        Maximal permissible depth of the multi-scale hierarchy\n",
    "    max_Q: int\n",
    "        Maximal rank at terminal base case (before reducing the \\leq max_Q rank coupling to a 1-1 alignment)\n",
    "    max_rank: int\n",
    "        Maximal rank at the intermediate steps of the rank-schedule\n",
    "        \n",
    "    \"\"\"\n",
    "    Q = int(rank_annealing__max_factor_lX(n, max_Q))\n",
    "    ndivQ = int(n // Q)\n",
    "\n",
    "    _, rank_schedule = rank_annealing__min_sum_partial_products_with_factors(ndivQ, hierarchy_depth, max_rank)\n",
    "    rank_schedule = sorted(rank_schedule)\n",
    "    rank_schedule.append(Q)\n",
    "    rank_schedule = [x for x in rank_schedule if x != 1]\n",
    "\n",
    "    print(f'Optimized rank-annealing schedule: {rank_schedule}')\n",
    "\n",
    "    assert functools.reduce(operator.mul, rank_schedule, 1) == n, \"Error! Rank-schedule does not factorize n!\"\n",
    "\n",
    "    return rank_schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab919ac2",
   "metadata": {},
   "source": [
    "The following function allows representing the squared Euclidean cost matrix in factorized form to avoid storing the full matrix, which is crucial for scaling the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa9fe3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils__low_rank_distance_factorization(X1, X2, r, eps, key=jax.random.PRNGKey(0)):\n",
    "    n = X1.shape[0]\n",
    "    m = X2.shape[0]\n",
    "    t = int(r / eps)\n",
    "\n",
    "    key1, key2, key3, key4 = jax.random.split(key, 4)\n",
    "    i_star = jax.random.randint(key1, (), 0, n)\n",
    "    j_star = jax.random.randint(key2, (), 0, m)\n",
    "\n",
    "    x1_i = X1[i_star]\n",
    "    x2_j = X2[j_star]\n",
    "\n",
    "    # Compute p\n",
    "    cd1 = jnp.linalg.norm(X1 - x2_j[None, :], axis=1) ** 2\n",
    "    cd2 = jnp.linalg.norm(X2 - x1_i[None, :], axis=1) ** 2\n",
    "    cd3 = jnp.mean(jnp.linalg.norm(X2 - x1_i[None, :], axis=1))\n",
    "\n",
    "    p = (cd1 + jnp.linalg.norm(x1_i - x2_j) ** 2 + cd3) ** 2\n",
    "    p = p / jnp.sum(p)\n",
    "\n",
    "    indices_p = jax.random.choice(key3, n, shape=(t,), p=p)\n",
    "    X1_t = X1[indices_p]\n",
    "    P_t = jnp.sqrt(p[indices_p] * t)\n",
    "\n",
    "    S = jnp.linalg.norm(X1_t[:, None, :] - X2[None, :, :], axis=2) / P_t[:, None]  # shape: (t, m)\n",
    "\n",
    "    # Compute q\n",
    "    S_norm = jnp.linalg.norm(S)\n",
    "    q = jnp.linalg.norm(S, axis=0) ** 2 / (S_norm ** 2)\n",
    "    q = q / jnp.sum(q)\n",
    "\n",
    "    indices_q = jax.random.choice(key4, m, shape=(t,), p=q)\n",
    "    S_t = S[:, indices_q]\n",
    "    Q_t = jnp.sqrt(q[indices_q] * t)\n",
    "    W = S_t / Q_t[None, :]\n",
    "\n",
    "    # SVD\n",
    "    U, Sig, Vh = jnp.linalg.svd(W, full_matrices=False)\n",
    "    F = U[:, :r]\n",
    "\n",
    "    # Compute U_t\n",
    "    W_F = W.T @ F\n",
    "    norm_WF = jnp.linalg.norm(W_F)\n",
    "    U_t = (S.T @ F) / norm_WF\n",
    "\n",
    "    # Chen & Price 2017 step\n",
    "    key5 = jax.random.PRNGKey(42)  # For deterministic behavior\n",
    "    indices = jax.random.choice(key5, m, shape=(t,))\n",
    "    X2_t = X2[indices]\n",
    "    D_t = jnp.linalg.norm(X1[:, None, :] - X2_t[None, :, :], axis=2) / jnp.sqrt(t)\n",
    "\n",
    "    Q = U_t.T @ U_t\n",
    "    UQ, SigQ, VhQ = jnp.linalg.svd(Q)\n",
    "    UQ = UQ / SigQ\n",
    "    U_tSub = U_t[indices].T\n",
    "    B = (UQ.T @ U_tSub) / jnp.sqrt(t)\n",
    "    A = jnp.linalg.inv(B @ B.T)\n",
    "    Z = (A @ B) @ D_t.T\n",
    "    V = Z.T @ UQ\n",
    "\n",
    "    return V.astype(jnp.float64), U_t.T.astype(jnp.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b79b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils__hadamard_square_lr(A1, A2):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        A1: jax.numpy array, low-rank subcoupling of shape (n, r)\n",
    "        A2: jax.numpy array, low-rank subcoupling of shape (n, r)\n",
    "                ( such that A ≈ A1 @ A2.T )\n",
    "\n",
    "    Output\n",
    "        A1_tilde: jax.numpy array, low-rank subcoupling of shape (n, r**2)\n",
    "        A2_tilde: jax.numpy array, low-rank subcoupling of shape (n, r**2)\n",
    "               ( such that A * A ≈ A1_tilde @ A2_tilde.T )\n",
    "    \"\"\"\n",
    "    n, r = A1.shape\n",
    "    A1_tilde = jnp.einsum(\"ij,ik->ijk\", A1, A1).reshape(n, r * r)\n",
    "    A2_tilde = jnp.einsum(\"ij,ik->ijk\", A2, A2).reshape(n, r * r)\n",
    "\n",
    "    return A1_tilde, A2_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f6faf",
   "metadata": {},
   "source": [
    "<h2> Implementation of the FRLC Solver (Low-Rank Optimal Transport)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db9e5c",
   "metadata": {},
   "source": [
    "To solve the low-rank OT sub-problems, the tutorial uses the FRLC (Factorized Regularized Low-rank Coupling) solver described in Halmos et al. (2024).  \n",
    " This solver parameterizes the transport matrix T as a product Q Λ Rᵀ of rank r, and optimizes via entropic gradient descent. Concretely:\n",
    "\n",
    "If sq_Euclidean=True, we use a factorization of the squared Euclidean cost via the compute_lr_sqeuclidean_matrix function, otherwise we use a factorization based on utils__low_rank_distance_factorization.  \n",
    "The FRLC_opt solver takes as input either the dense cost matrix C_XY, or C_factors for the cost, as well as the uniform histograms a=b.  \n",
    "It returns the normalized Q, R matrices (size n×r) and the diagonal Λ.\n",
    "The obtained Q and R factors contain the clustering information in the form of \"soft\" vectors (positive real values per cluster).  \n",
    "This FRLC solver is the instance of Low-rank OT used at each hierarchical step in the paper. It computes an approximate OT coupling of rank r and serves as a building block for HiRef."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6235124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FRLC_LR_opt(\n",
    "    C_factors, A_factors, B_factors, a=None, b=None,\n",
    "    tau_in=50, tau_out=50, gamma=90, r=10, r2=None,\n",
    "    max_iter=200, printCost=True, returnFull=False, alpha=0.0,\n",
    "    initialization='Full', init_args=None, full_grad=True,\n",
    "    convergence_criterion=True, tol=5e-6, min_iter=25,\n",
    "    max_inneriters_balanced=300, max_inneriters_relaxed=50,\n",
    "    diagonalize_return=False\n",
    "):\n",
    "    N1, N2 = C_factors[0].shape[0], C_factors[1].shape[1]\n",
    "    k = 0\n",
    "    stationarity_gap = jnp.inf\n",
    "\n",
    "    one_N1 = jnp.ones((N1,))\n",
    "    one_N2 = jnp.ones((N2,))\n",
    "\n",
    "    if a is None:\n",
    "        a = one_N1 / N1\n",
    "    if b is None:\n",
    "        b = one_N2 / N2\n",
    "    if r2 is None:\n",
    "        r2 = r\n",
    "\n",
    "    one_r = jnp.ones((r,))\n",
    "    one_r2 = jnp.ones((r2,))\n",
    "\n",
    "    gQ = one_r / r\n",
    "    gR = one_r2 / r2\n",
    "\n",
    "    full_rank = initialization == 'Full'\n",
    "    \n",
    "    if initialization not in ['Full', 'Rank-2']:\n",
    "        print('Initialization must be either \"Full\" or \"Rank-2\", defaulting to \"Full\".')\n",
    "        full_rank = True\n",
    "\n",
    "    if init_args is None:\n",
    "        Q, R, T, Lambda = utils__initialize_couplings(a, b, gQ, gR, gamma, full_rank=full_rank, max_iter=max_inneriters_balanced)\n",
    "    else:\n",
    "        Q, R, T = init_args\n",
    "        if Q is not None:\n",
    "            gQ = Q.T @ one_N1\n",
    "        if R is not None:\n",
    "            gR = R.T @ one_N2\n",
    "        if Q is None or R is None or T is None:\n",
    "            _Q, _R, _T, Lambda = utils__initialize_couplings(a, b, gQ, gR, gamma, full_rank=full_rank, max_iter=max_inneriters_balanced)\n",
    "            Q = Q if Q is not None else _Q\n",
    "            R = R if R is not None else _R\n",
    "            T = T if T is not None else _T\n",
    "\n",
    "        Lambda = jnp.diag(1 / (Q.T @ one_N1)) @ T @ jnp.diag(1 / (R.T @ one_N2))\n",
    "\n",
    "    errs = {'total_cost': [], 'W_cost': [], 'GW_cost': []}\n",
    "    gamma_k = gamma\n",
    "    Q_prev, R_prev, T_prev = None, None, None\n",
    "\n",
    "    while k < max_iter and (not convergence_criterion or (k < min_iter or utils__Delta((Q, R, T), (Q_prev, R_prev, T_prev), gamma_k) > tol)):\n",
    "        if convergence_criterion:\n",
    "            Q_prev, R_prev, T_prev = Q, R, T\n",
    "\n",
    "        if k % 25 == 0:\n",
    "            print(f\"Iteration: {k}\")\n",
    "\n",
    "        gradQ, gradR, gamma_k = gd__compute_grad_A_LR(C_factors, A_factors, B_factors, Q, R, Lambda, gamma, alpha=alpha, full_grad=full_grad)\n",
    "\n",
    "        R = ott_log_sinkhorn(gradR - (1 / gamma_k) * jnp.log(R), b, gR, gamma_k, max_iter=max_inneriters_relaxed, tau=tau_in)\n",
    "        Q = ott_log_sinkhorn(gradQ - (1 / gamma_k) * jnp.log(Q), a, gQ, gamma_k, max_iter=max_inneriters_relaxed, tau=tau_in)\n",
    "\n",
    "        gQ, gR = Q.T @ one_N1, R.T @ one_N2\n",
    "\n",
    "        gradT, gamma_T = gd__compute_grad_B_LR(C_factors, A_factors, B_factors, Q, R, Lambda, gQ, gR, gamma, alpha=alpha)\n",
    "        T = ott_log_sinkhorn(gradT - (1 / gamma_T) * jnp.log(T), gQ, gR, gamma_T, max_iter=max_inneriters_balanced)\n",
    "\n",
    "        Lambda = jnp.diag(1 / gQ) @ T @ jnp.diag(1 / gR)\n",
    "\n",
    "        if printCost:\n",
    "            primal_cost = jnp.trace(((Q.T @ C_factors[0]) @ (C_factors[1] @ R)) @ Lambda.T)\n",
    "            errs['W_cost'].append(primal_cost)\n",
    "            if A_factors is not None and B_factors is not None:\n",
    "                X = R @ ((Lambda.T @ ((Q.T @ A_factors[0]) @ (A_factors[1] @ Q)) @ Lambda) @ (R.T @ B_factors[0])) @ B_factors[1]\n",
    "                GW_cost = -2 * jnp.trace(X)\n",
    "                A1_tild, A2_tild = utils__hadamard_square_lr(A_factors[0], A_factors[1].T)\n",
    "                GW_cost += jnp.dot(A1_tild.T @ (Q @ one_r), A2_tild.T @ (Q @ one_r))\n",
    "                B1_tild, B2_tild = utils__hadamard_square_lr(B_factors[0], B_factors[1].T)\n",
    "                GW_cost += jnp.dot(B1_tild.T @ (R @ one_r2), B2_tild.T @ (R @ one_r2))\n",
    "                errs['GW_cost'].append(GW_cost)\n",
    "                errs['total_cost'].append((1 - alpha) * primal_cost + alpha * GW_cost)\n",
    "            else:\n",
    "                errs['GW_cost'].append(0)\n",
    "                errs['total_cost'].append(primal_cost)\n",
    "        k += 1\n",
    "\n",
    "    if printCost:\n",
    "        print(f\"Initial Wasserstein cost: {errs['W_cost'][0]}, GW-cost: {errs['GW_cost'][0]}, Total cost: {errs['total_cost'][0]}\")\n",
    "        print(f\"Final Wasserstein cost: {errs['W_cost'][-1]}, GW-cost: {errs['GW_cost'][-1]}, Total cost: {errs['total_cost'][-1]}\")\n",
    "        plt.plot(errs['total_cost'])\n",
    "        plt.show()\n",
    "\n",
    "    if returnFull:\n",
    "        P = Q @ Lambda @ R.T\n",
    "        return P, errs\n",
    "    else:\n",
    "        if diagonalize_return:\n",
    "            Q = Q @ (jnp.diag(1 / gQ) @ T)\n",
    "            gR = R.T @ one_N2\n",
    "            T = jnp.diag(gR)\n",
    "        return Q, R, T, errs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07818c0b",
   "metadata": {},
   "source": [
    "<h2> Implementation of Hierarchical Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1814682",
   "metadata": {},
   "source": [
    "The central algorithm consists of recursively applying these OT sub-problems hierarchically. The code implements the HierarchicalRefinementOT class that performs the following loop:\n",
    "\n",
    "We initialize a single global \"cluster\" (idxX = [0..N-1], idxY = [0..N-1]) covering everything.\n",
    "For each level i of the rank schedule rank_schedule[i]:\n",
    "\n",
    "For each pair of clusters (idxX, idxY) obtained at the previous level, we solve an OT at rank r = rank_schedule[i]. If we have provided C explicitly, we directly index the cost sub-matrix; otherwise we calculate a cost factorization via _solve_LR_prob.  \n",
    "This produces Q, R for this sub-problem.\n",
    "We transform the Q (for X) and R (for Y) factors into concrete partitions of these points. With soft clustering:\n",
    "\n",
    "\"Soft\" clustering : we impose equal capacities in each cluster. For each sub-cluster z from 0 to r−1, we choose the capacity = N / (r_0 * ... * r_i) points with the highest \"affinity\" in Q and R (via topk).  \n",
    "These points form new sub-clusters (idxX_z, idxY_z) of equal size. We iterate until all points are assigned.\n",
    "\n",
    "This co-clustering step is the concrete application of the theoretical result: the columns of Q and R indicate the probabilistic co-assignment of a point X_i to a sub-partition z and of point Y_j to the same sub-partition z.  \n",
    "The key invariant of the paper is that, at the optimal rank, these factors cluster together the pairs {X_i, Monge(X_i)}. Here, we use this invariant to divide our problem.\n",
    "We update the list of clusters F_tp1 containing all the new sub-clusters (idxX_z, idxY_z) obtained. Then we repeat at the next level.\n",
    "When we reach the last level, each cluster is of size 1×1 and corresponds to a single pair of points. The final coupling is given by the set of pairs (idxX, idxY).\n",
    "\n",
    "\n",
    "\n",
    "At the end, we have a list Monge_clusters = [(x_0,y_0), (x_1,y_1), …] ensuring a bijective correspondence between X and Y. The paper shows that this procedure does provide a full-rank optimal transport solution, while never having stored a complete cost matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e86dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalRefinementOT:\n",
    "    \"\"\"\n",
    "    Classe pour effectuer le raffinage hiérarchique OT en JAX.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 C,\n",
    "                 rank_schedule,\n",
    "                 solver = FRLC_opt,\n",
    "                 solver_params = None,\n",
    "                 device = 'cpu',\n",
    "                 base_rank= 1,\n",
    "                 clustering_type = 'soft',\n",
    "                 plot_clusterings = False,\n",
    "                 parallel = False,\n",
    "                 num_processes = None):\n",
    "        # Matrice de coût et paramètres initiaux\n",
    "        self.C = jnp.array(C)                     # Coût en tant que jnp.array\n",
    "        self.rank_schedule = rank_schedule\n",
    "        self.solver = solver\n",
    "        self.device = device\n",
    "        self.base_rank = base_rank\n",
    "        self.clustering_type = clustering_type\n",
    "        self.plot_clusterings = plot_clusterings\n",
    "        self.parallel = parallel\n",
    "        self.num_processes = num_processes\n",
    "\n",
    "        self.X, self.Y = None, None\n",
    "        self.N = self.C.shape[0]\n",
    "        self.Monge_clusters = None\n",
    "\n",
    "        # Paramètres par défaut du solveur FRLC\n",
    "        default_solver_params = {\n",
    "            'gamma': 30,\n",
    "            'max_iter': 60,\n",
    "            'min_iter': 25,\n",
    "            'max_inneriters_balanced': 100,\n",
    "            'max_inneriters_relaxed': 40,\n",
    "            'printCost': False,\n",
    "            'tau_in': 100000\n",
    "        }\n",
    "        if solver_params is not None:\n",
    "            default_solver_params.update(solver_params)\n",
    "        self.solver_params = default_solver_params\n",
    "\n",
    "        assert self.C.shape[0] == self.C.shape[1], \\\n",
    "            \"La matrice de coût doit être carrée (|X| = |Y| = N)\"\n",
    "\n",
    "    @classmethod\n",
    "    def init_from_point_clouds(cls,\n",
    "                               X,\n",
    "                               Y,\n",
    "                               rank_schedule,\n",
    "                               distance_rank_schedule = None,\n",
    "                               solver = FRLC_LR_opt,\n",
    "                               solver_params = None,\n",
    "                               device = 'cpu',\n",
    "                               base_rank = 1,\n",
    "                               clustering_type = 'soft',\n",
    "                               plot_clusterings = False,\n",
    "                               parallel = False,\n",
    "                               num_processes = None,\n",
    "                               sq_Euclidean = False):\n",
    "        \"\"\"\n",
    "        Constructeur à partir de nuages de points X, Y.\n",
    "        \"\"\"\n",
    "        obj = cls.__new__(cls)\n",
    "        obj.X = jnp.array(X)\n",
    "        obj.Y = jnp.array(Y)\n",
    "        obj.rank_schedule = rank_schedule\n",
    "        obj.distance_rank_schedule = rank_schedule if distance_rank_schedule is None else distance_rank_schedule\n",
    "        obj.solver = solver\n",
    "        obj.device = device\n",
    "        obj.base_rank = base_rank\n",
    "        obj.clustering_type = clustering_type\n",
    "        obj.plot_clusterings = plot_clusterings\n",
    "        obj.parallel = parallel\n",
    "        obj.num_processes = num_processes\n",
    "        obj.N = X.shape[0]\n",
    "        obj.C = None\n",
    "        obj.Monge_clusters = None\n",
    "        obj.sq_Euclidean = sq_Euclidean\n",
    "\n",
    "        default_solver_params = {\n",
    "            'gamma': 30,\n",
    "            'max_iter': 60,\n",
    "            'min_iter': 25,\n",
    "            'max_inneriters_balanced': 100,\n",
    "            'max_inneriters_relaxed': 40,\n",
    "            'printCost': False,\n",
    "            'tau_in': 100000\n",
    "        }\n",
    "        if solver_params is not None:\n",
    "            default_solver_params.update(solver_params)\n",
    "        obj.solver_params = default_solver_params\n",
    "\n",
    "        assert X.shape[0] == Y.shape[0], \"Assume |X| = |Y| = N\"\n",
    "        return obj\n",
    "\n",
    "    def run(self, return_as_coupling: bool = False):\n",
    "        \"\"\"\n",
    "        Lance le raffinage hiérarchique (série ou parallèle).\n",
    "        \"\"\"\n",
    "        if self.parallel:\n",
    "            return self._hierarchical_refinement_parallelized(return_as_coupling=return_as_coupling)\n",
    "        else:\n",
    "            return self._hierarchical_refinement(return_as_coupling=return_as_coupling)\n",
    "\n",
    "    def _hierarchical_refinement(self, return_as_coupling: bool = False):\n",
    "        \"\"\"\n",
    "        Raffinement hiérarchique mono-processus.\n",
    "        \"\"\"\n",
    "        # Partition initiale (tous les points dans un seul cluster)\n",
    "        F_t = [(jnp.arange(self.N), jnp.arange(self.N))]\n",
    "        for i, rank_level in enumerate(self.rank_schedule):\n",
    "            F_tp1 = []\n",
    "            is_last = (i == len(self.rank_schedule) - 1)\n",
    "            if is_last:\n",
    "                fin_iters = int(self.N) // int(jnp.prod(jnp.array(self.rank_schedule[:i+1])))\n",
    "                print(f'Last level, chunk-size {rank_level}, {fin_iters} itérations.')\n",
    "\n",
    "            j = 0\n",
    "            for (idxX, idxY) in F_t:\n",
    "                if is_last:\n",
    "                    print(f'{j}/{fin_iters} itérations finalistes')\n",
    "                    j += 1\n",
    "\n",
    "                # Si cluster arrivé à la taille base_rank, on le conserve tel quel\n",
    "                if len(idxX) <= self.base_rank or len(idxY) <= self.base_rank:\n",
    "                    F_tp1.append((idxX, idxY))\n",
    "                    continue\n",
    "\n",
    "                # Résoudre sous-problème d'OT (coût explicite ou low-rank sur distance)\n",
    "                if self.C is not None:\n",
    "                    Q, R = self._solve_prob(idxX, idxY, rank_level)\n",
    "                else:\n",
    "                    rank_D = self.distance_rank_schedule[i]\n",
    "                    Q, R = self._solve_LR_prob(idxX, idxY, rank_level, rank_D)\n",
    "\n",
    "                # Calcul de la nouvelle taille de cluster (capacités)\n",
    "                capacity = int(self.N) // int(jnp.prod(jnp.array(self.rank_schedule[:i+1])))\n",
    "                idx_seenX = jnp.arange(Q.shape[0])\n",
    "                idx_seenY = jnp.arange(R.shape[0])\n",
    "\n",
    "                # Clustering \"soft\" ou \"hard\"\n",
    "                if self.clustering_type == 'soft':\n",
    "                    for z in range(rank_level):\n",
    "                        # top-k sur les colonnes de Q et R\n",
    "                        _, topk_X = jax.lax.top_k(Q[idx_seenX, z], capacity)\n",
    "                        idxX_z = idxX[idx_seenX[topk_X]]\n",
    "                        _, topk_Y = jax.lax.top_k(R[idx_seenY, z], capacity)\n",
    "                        idxY_z = idxY[idx_seenY[topk_Y]]\n",
    "                        F_tp1.append((idxX_z, idxY_z))\n",
    "                        # Retirer ces indices pour la suite\n",
    "                        idx_seenX = idx_seenX[~jnp.isin(idx_seenX, idx_seenX[topk_X])]\n",
    "                        idx_seenY = idx_seenY[~jnp.isin(idx_seenY, idx_seenY[topk_Y])]\n",
    "\n",
    "                elif self.clustering_type == 'hard':\n",
    "                    # Assignations par argmax\n",
    "                    zX = jnp.argmax(Q, axis=1)\n",
    "                    zY = jnp.argmax(R, axis=1)\n",
    "                    for z in range(rank_level):\n",
    "                        idxX_z = idxX[zX == z]\n",
    "                        idxY_z = idxY[zY == z]\n",
    "                        # On s’assure que c’est effectivement un hard-clustering\n",
    "                        assert len(idxX_z) == len(idxY_z) == capacity, \\\n",
    "                            \"Cluster déséquilibre ou pas du hard-clustering!\"\n",
    "                        F_tp1.append((idxX_z, idxY_z))\n",
    "\n",
    "            F_t = F_tp1\n",
    "\n",
    "        self.Monge_clusters = F_t\n",
    "        if return_as_coupling:\n",
    "            return self._compute_coupling_from_Ft()\n",
    "        else:\n",
    "            return self.Monge_clusters\n",
    "\n",
    "    def _hierarchical_refinement_parallelized(self, return_as_coupling: bool = False):\n",
    "        # Non implémenté dans cette classe\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _solve_LR_prob(self, idxX, idxY, rank_level, rankD, eps=0.04):\n",
    "        \"\"\"\n",
    "        Solve sub-problème OT en utilisant la factorisation low-rank de la distance.\n",
    "        \"\"\"\n",
    "        _x0 = self.X[idxX]    # Extrait les points X\n",
    "        _x1 = self.Y[idxY]    # Extrait les points Y\n",
    "        if rankD < _x0.shape[0]:\n",
    "            # Calcul des facteurs de la matrice de distance\n",
    "            C_factors, A_factors, B_factors = self.get_dist_mats(_x0, _x1, rankD, eps, self.sq_Euclidean)\n",
    "            Q, R, _, _ = self.solver(\n",
    "                C_factors, A_factors, B_factors,\n",
    "                gamma=self.solver_params['gamma'],\n",
    "                r=rank_level,\n",
    "                max_iter=self.solver_params['max_iter'],\n",
    "                min_iter=self.solver_params['min_iter'],\n",
    "                max_inneriters_balanced=self.solver_params['max_inneriters_balanced'],\n",
    "                max_inneriters_relaxed=self.solver_params['max_inneriters_relaxed'],\n",
    "                diagonalize_return=True,\n",
    "                tau_in=self.solver_params['tau_in']\n",
    "            )\n",
    "        else:\n",
    "            # Cas final (sous-cluster) : calcul direct des distances\n",
    "            if self.sq_Euclidean:\n",
    "                # Distance euclidienne au carré\n",
    "                C_XY = jnp.linalg.norm(_x0[:, None, :] - _x1[None, :, :], axis=2)**2\n",
    "            else:\n",
    "                # Distance euclidienne normale\n",
    "                C_XY = jnp.linalg.norm(_x0[:, None, :] - _x1[None, :, :], axis=2)\n",
    "            Q, R, _, _ = FRLC_opt(\n",
    "                C_XY,\n",
    "                gamma=self.solver_params['gamma'],\n",
    "                r=rank_level,\n",
    "                max_iter=self.solver_params['max_iter'],\n",
    "                min_iter=self.solver_params['min_iter'],\n",
    "                max_inneriters_balanced=self.solver_params['max_inneriters_balanced'],\n",
    "                max_inneriters_relaxed=self.solver_params['max_inneriters_relaxed'],\n",
    "                diagonalize_return=True,\n",
    "                tau_in=self.solver_params['tau_in']\n",
    "            )\n",
    "        return Q, R\n",
    "\n",
    "    def _solve_prob(self, idxX, idxY, rank_level):\n",
    "        \"\"\"\n",
    "        Solve sous-problème OT en indexant la sous-matrice de coût explicite.\n",
    "        \"\"\"\n",
    "        C_sub = self.C[idxX][:, idxY]\n",
    "        Q, R, _, _ = self.solver(\n",
    "            C_sub,\n",
    "            gamma=self.solver_params['gamma'],\n",
    "            r=rank_level,\n",
    "            max_iter=self.solver_params['max_iter'],\n",
    "            min_iter=self.solver_params['min_iter'],\n",
    "            max_inneriters_balanced=self.solver_params['max_inneriters_balanced'],\n",
    "            max_inneriters_relaxed=self.solver_params['max_inneriters_relaxed'],\n",
    "            diagonalize_return=True,\n",
    "            tau_in=self.solver_params['tau_in'],\n",
    "            dtype=C_sub.dtype\n",
    "        )\n",
    "        return Q, R\n",
    "\n",
    "    def _compute_coupling_from_Ft(self):\n",
    "        \"\"\"\n",
    "        Construit la matrice de couplage dense à partir des clusters Monge map.\n",
    "        \"\"\"\n",
    "        size = (self.N, self.N)\n",
    "        P = jnp.zeros(size)\n",
    "        for idx1, idx2 in self.Monge_clusters:\n",
    "            for i in range(idx1.shape[0]):\n",
    "                P = P.at[idx1[i], idx2[i]].set(1)\n",
    "        # On normalise par N (masse uniformément répartie)\n",
    "        return P / self.N\n",
    "\n",
    "    def compute_OT_cost(self):\n",
    "        \"\"\"\n",
    "        Calcule le coût OT associé aux clusters Monge (sans construire explicitement le couplage).\n",
    "        \"\"\"\n",
    "        cost = 0.0\n",
    "        for idx1, idx2 in self.Monge_clusters:\n",
    "            if self.C is not None:\n",
    "                cost += jnp.sum(self.C[idx1, idx2])\n",
    "            else:\n",
    "                if self.sq_Euclidean:\n",
    "                    cost += jnp.sum((self.X[idx1] - self.Y[idx2])**2)\n",
    "                else:\n",
    "                    cost += jnp.linalg.norm(self.X[idx1] - self.Y[idx2])\n",
    "        return cost / self.N\n",
    "\n",
    "    def get_dist_mats(self, _x0, _x1, rankD, eps, sq_Euclidean):\n",
    "        \"\"\"\n",
    "        Retourne les facteurs de la matrice de distance low-rank.\n",
    "        \"\"\"\n",
    "        if sq_Euclidean:\n",
    "            # Facteurs pour une distance euclidienne au carré\n",
    "            C_factors = compute_lr_sqeuclidean_matrix(_x0, _x1, True)\n",
    "            A_factors = None\n",
    "            B_factors = None\n",
    "        else:\n",
    "            # Low-rank factorisation pour distance standard\n",
    "            C_factors = self.ret_normalized_cost(_x0, _x1, rankD, eps)\n",
    "            A_factors = None\n",
    "            B_factors = None\n",
    "        return C_factors, A_factors, B_factors\n",
    "\n",
    "    def ret_normalized_cost(self, X, Y, rankD, eps):\n",
    "        \"\"\"\n",
    "        Facteur de coût normalisé via factorisation low-rank de distance.\n",
    "        \"\"\"\n",
    "        C1, C2 = utils__low_rank_distance_factorization(\n",
    "            X, Y, r=rankD, eps=eps\n",
    "        )\n",
    "        c = (jnp.max(C1)**0.5) * (jnp.max(C2)**0.5)\n",
    "        C1 = (C1 / c).astype(X.dtype)\n",
    "        C2 = (C2 / c).astype(X.dtype)\n",
    "        return C1, C2\n",
    "\n",
    "def compute_lr_sqeuclidean_matrix(X_s, X_t, rescale_cost, device=None, dtype=None):\n",
    "    \"\"\"\n",
    "    Calcul de la factorisation low-rank de la distance euclidienne au carré.\n",
    "    \"\"\"\n",
    "    dtype = X_s.dtype\n",
    "    ns, _ = X_s.shape\n",
    "    nt, _ = X_t.shape\n",
    "\n",
    "    sum_Xs_sq = jnp.sum(X_s ** 2, axis=1).reshape(ns, 1)\n",
    "    ones_ns = jnp.ones((ns, 1), dtype=dtype)\n",
    "    neg_two_Xs = -2 * X_s\n",
    "    M1 = jnp.concatenate([sum_Xs_sq, ones_ns, neg_two_Xs], axis=1)\n",
    "\n",
    "    ones_nt = jnp.ones((nt, 1), dtype=dtype)\n",
    "    sum_Xt_sq = jnp.sum(X_t ** 2, axis=1).reshape(nt, 1)\n",
    "    M2 = jnp.concatenate([ones_nt, sum_Xt_sq, X_t], axis=1)\n",
    "\n",
    "    if rescale_cost:\n",
    "        max_M1 = jnp.max(M1)\n",
    "        max_M2 = jnp.max(M2)\n",
    "        if max_M1 > 0:\n",
    "            M1 = M1 / jnp.sqrt(max_M1)\n",
    "        if max_M2 > 0:\n",
    "            M2 = M2 / jnp.sqrt(max_M2)\n",
    "\n",
    "    return (M1, M2.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d1363f",
   "metadata": {},
   "source": [
    "<h2> Execution and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1290a60a",
   "metadata": {},
   "source": [
    "We build the rank schedule and then launch HiRef as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc0dfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized rank-annealing schedule: [2, 1250]\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "Initial Wasserstein cost: 4.628808975219727, GW-cost: 0, Total cost: 4.628808975219727\n",
      "Final Wasserstein cost: 4.5346856117248535, GW-cost: 0, Total cost: 4.5346856117248535\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last level, chunk-size 1250, 1 itérations.\n",
      "0/1 itérations finalistes\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "1/1 itérations finalistes\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "HR-OT cost: 18.2893009185791\n"
     ]
    }
   ],
   "source": [
    "rank_schedule = rank_annealing__optimal_rank_schedule( X.shape[0] , hierarchy_depth = 6, max_Q = int(2**11), max_rank = 64 )\n",
    "\n",
    "try:\n",
    "    hrot_lr = HierarchicalRefinementOT.init_from_point_clouds(X, Y, rank_schedule, base_rank=1)\n",
    "    F = hrot_lr.run(return_as_coupling=False)\n",
    "    cost_hrot_lr = hrot_lr.compute_OT_cost()\n",
    "    print(f'HR-OT cost: {cost_hrot_lr}')\n",
    "except Exception as e:\n",
    "    print(f'HROT-LR failed for sample size: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab2d468",
   "metadata": {},
   "source": [
    "![Benchmark](bench.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d88247",
   "metadata": {},
   "source": [
    "As we can see on this benchmark from the article, our result of 18.28 is very close even though our dataset is different. This can be explained by :  \n",
    ". The use of the same feature extractor (ResNet)  \n",
    ". Also it operates solely on distances in the embedding space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
