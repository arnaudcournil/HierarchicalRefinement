{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945f7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable, Union, Dict, Any\n",
    "import random\n",
    "import operator\n",
    "import functools\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from ott.geometry import costs, pointcloud\n",
    "from ott.tools import sinkhorn_divergence, progot\n",
    "from ott.problems.linear import linear_problem\n",
    "from ott.solvers.linear import sinkhorn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from ott.geometry import geometry\n",
    "from ott.problems.linear import linear_problem\n",
    "from ott.solvers.linear import sinkhorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cae2dc",
   "metadata": {},
   "source": [
    "# 1. Load images & model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8173d8ca",
   "metadata": {},
   "source": [
    "You can also directly go to part 3 if you want to start directly from the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d50b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        # Liste tous les fichiers .jpg\n",
    "        self.image_paths = [os.path.join(root_dir, fname)\n",
    "                            for fname in os.listdir(root_dir)\n",
    "                            if fname.endswith('.jpg')]\n",
    "        # Si le nombre d'images est impair, enlever la dernière\n",
    "        if len(self.image_paths) % 2 != 0:\n",
    "            self.image_paths = self.image_paths[:-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')  # Toujours convertir en RGB\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image  # Pas d'étiquette ici, juste l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1d362e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000 images from ImageNet!\n"
     ]
    }
   ],
   "source": [
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images for CNN input\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load COCO dataset from extracted path\n",
    "imagenet_dataset = CustomImageDataset(root_dir='images', transform=transform)\n",
    "\n",
    "\n",
    "# Create DataLoader for batching\n",
    "imagenet_loader = DataLoader(imagenet_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Loaded {len(imagenet_dataset)} images from ImageNet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "280953f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VONG\\AppData\\Local\\Temp\\ipykernel_11692\\1851330435.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.expanduser(\"resnet50-0676ba61.pth\")\n",
    "\n",
    "# Load pretrained ResNet model\n",
    "model = models.resnet50()\n",
    "model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "model.fc = torch.nn.Identity()  # Remove classification layer to extract features\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f1229",
   "metadata": {},
   "source": [
    "# 2. Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6001bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting embeddings!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 157/157 [00:57<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_features(dataloader, model):\n",
    "    \"\"\"\n",
    "    Compute embeddings\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for idx, images in tqdm(enumerate(dataloader), desc=\"Extracting features\", total=len(dataloader)):\n",
    "            images = images.to(device)\n",
    "            features = model(images)\n",
    "            embeddings.append(jnp.array(features.detach().cpu().numpy()))  \n",
    "    return jnp.vstack(embeddings)  # Stack all embeddings\n",
    "\n",
    "print('extracting embeddings!')\n",
    "embeddings = extract_features(imagenet_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0dbe4e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved successfully to embeddings/embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "with open('embeddings/embeddings.pkl', \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "print(\"Embeddings saved successfully to embeddings/embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb07d8",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde20a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded successfully! Shape: (5000, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings from the pickle file\n",
    "with open('embeddings/embeddings.pkl', \"rb\") as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "print(f\"Embeddings loaded successfully! Shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155a4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2500, 2048), Y shape: (2500, 2048)\n"
     ]
    }
   ],
   "source": [
    "num_samples = embeddings.shape[0]\n",
    "\n",
    "# Shuffle indices\n",
    "key = jax.random.PRNGKey(42)\n",
    "indices = jax.random.permutation(key, num_samples)\n",
    "\n",
    "# Split into two tensors\n",
    "X = embeddings[indices[:num_samples // 2]]\n",
    "Y = embeddings[indices[num_samples // 2:]]\n",
    "\n",
    "print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa4c1e",
   "metadata": {},
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e92a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ott_log_sinkhorn(grad,\n",
    "                     a,\n",
    "                     b,\n",
    "                     gamma_k,\n",
    "                     max_iter = 50,\n",
    "                     balanced = True,\n",
    "                     unbalanced = False,\n",
    "                     tau = None,\n",
    "                     tau2 = None):\n",
    "    \"\"\"\n",
    "    grad: cost matrix (n, m)\n",
    "    a: source histogram (n,)\n",
    "    b: target histogram (m,)\n",
    "    gamma_k: régularisation inverse (1/epsilon)\n",
    "    \"\"\"\n",
    "    epsilon = 1.0 / gamma_k\n",
    "\n",
    "    # Choix des tau pour marges\n",
    "    if balanced and not unbalanced:\n",
    "        tau_a, tau_b = 1.0, 1.0\n",
    "    elif not balanced and unbalanced:\n",
    "        tau_a = tau / (tau + epsilon)\n",
    "        tau_b = tau2 / (tau2 + epsilon) if tau2 is not None else tau_a\n",
    "    else:  # semi-relaxed\n",
    "        tau_a, tau_b = 1.0, tau / (tau + epsilon)\n",
    "\n",
    "    # Géométrie entropique sur la matrice de coût\n",
    "    geom = geometry.Geometry(cost_matrix=grad, epsilon=epsilon)\n",
    "\n",
    "    # Construction du problème linéaire\n",
    "    prob = linear_problem.LinearProblem(\n",
    "        geom,\n",
    "        a=a,\n",
    "        b=b,\n",
    "        tau_a=tau_a,\n",
    "        tau_b=tau_b\n",
    "    )\n",
    "\n",
    "    # Solveur Sinkhorn\n",
    "    solver = sinkhorn.Sinkhorn(max_iterations=max_iter)\n",
    "    out = solver(prob)\n",
    "\n",
    "    return out.matrix\n",
    "\n",
    "def utils__Delta(vark, varkm1, gamma_k):\n",
    "    return (gamma_k**-2) * (jnp.linalg.norm(vark[0] - varkm1[0]) + jnp.linalg.norm(vark[1] - varkm1[1]) + jnp.linalg.norm(vark[2] - varkm1[2]))\n",
    "\n",
    "def utils__random_simplex_sample(key, N, dtype = jnp.float64):\n",
    "    \"\"\"\n",
    "    Draws a random point from the (N-1)-simplex using normalized exponentiated Gaussian variates.\n",
    "\n",
    "    Args:\n",
    "        key: PRNGKey for random number generation.\n",
    "        N: Dimensionality of the simplex (vector length).\n",
    "        dtype: Desired floating-point type of the output.\n",
    "\n",
    "    Returns:\n",
    "        A 1D array of shape (N,) with non-negative entries summing to 1.\n",
    "    \"\"\"\n",
    "    # Sample N independent standard normals\n",
    "    z = jax.random.normal(key, shape=(N,), dtype=dtype)\n",
    "    # Exponentiate\n",
    "    e = jnp.exp(z)\n",
    "    # Normalize to sum to 1\n",
    "    return e / jnp.sum(e)\n",
    "\n",
    "def utils__initialize_couplings(a, b, gQ, gR, gamma, full_rank = True, key = jax.random.PRNGKey(0), dtype = float, rank2_random = False, max_iter = 50):\n",
    "    \"\"\"\n",
    "    Initialize coupling factors in JAX.\n",
    "    \"\"\"\n",
    "    N1 = a.shape[0]\n",
    "    N2 = b.shape[0]\n",
    "    r = gQ.shape[0]\n",
    "    r2 = gR.shape[0]\n",
    "\n",
    "    one_N1 = jnp.ones((N1,), dtype=dtype)\n",
    "    one_N2 = jnp.ones((N2,), dtype=dtype)\n",
    "\n",
    "    if full_rank:\n",
    "        # Full-rank initialization via log-Sinkhorn\n",
    "        key, subkey = jax.random.split(key)\n",
    "        C_random = jax.random.uniform(subkey, (N1, r), dtype=dtype)\n",
    "        Q = ott_log_sinkhorn(C_random, a, gQ, gamma,\n",
    "                                max_iter=max_iter,\n",
    "                                balanced=True)\n",
    "\n",
    "        key, subkey = jax.random.split(key)\n",
    "        C_random = jax.random.uniform(subkey, (N2, r2), dtype=dtype)\n",
    "        R = ott_log_sinkhorn(C_random, b, gR, gamma,\n",
    "                                max_iter=max_iter,\n",
    "                                balanced=True)\n",
    "\n",
    "        # Compute updated inner marginals\n",
    "        gR_new = R.T @ one_N2\n",
    "        gQ_new = Q.T @ one_N1\n",
    "\n",
    "        key, subkey = jax.random.split(key)\n",
    "        C_random = jax.random.uniform(subkey, (r, r2), dtype=dtype)\n",
    "        T = ott_log_sinkhorn(C_random, gQ_new, gR_new, gamma,\n",
    "                                max_iter=max_iter,\n",
    "                                balanced=True)\n",
    "\n",
    "        # Inner inverse coupling\n",
    "        if r == r2:\n",
    "            Lambda = jnp.linalg.inv(T)\n",
    "        else:\n",
    "            Lambda = jnp.diag(1.0 / gQ_new) @ T @ jnp.diag(1.0 / gR_new)\n",
    "\n",
    "    else:\n",
    "        # Rank-2 initialization (Scetbon et al. 2021)\n",
    "        if r != r2:\n",
    "            raise ValueError(\"Rank-2 init requires equal inner ranks.\")\n",
    "        g = gQ\n",
    "        lambd = jnp.minimum(jnp.min(a), jnp.min(b))\n",
    "        lambd = jnp.minimum(lambd, jnp.min(g)) / 2.0\n",
    "\n",
    "        # Sample or deterministic\n",
    "        if rank2_random:\n",
    "            key, *splits = random.split(key, 4)\n",
    "            a1 = utils__random_simplex_sample(N1, splits[0], dtype)\n",
    "            b1 = utils__random_simplex_sample(N2, splits[1], dtype)\n",
    "            g1 = utils__random_simplex_sample(r, splits[2], dtype)\n",
    "        else:\n",
    "            g1 = jnp.arange(1, r + 1, dtype=dtype)\n",
    "            g1 = g1 / jnp.sum(g1)\n",
    "            a1 = jnp.arange(1, N1 + 1, dtype=dtype)\n",
    "            a1 = a1 / jnp.sum(a1)\n",
    "            b1 = jnp.arange(1, N2 + 1, dtype=dtype)\n",
    "            b1 = b1 / jnp.sum(b1)\n",
    "\n",
    "        a2 = (a - lambd * a1) / (1 - lambd)\n",
    "        b2 = (b - lambd * b1) / (1 - lambd)\n",
    "        g2 = (g - lambd * g1) / (1 - lambd)\n",
    "\n",
    "        Q = lambd * jnp.outer(a1, g1) + (1 - lambd) * jnp.outer(a2, g2)\n",
    "        R = lambd * jnp.outer(b1, g1) + (1 - lambd) * jnp.outer(b2, g2)\n",
    "\n",
    "        gR_new = R.T @ one_N2\n",
    "        gQ_new = Q.T @ one_N1\n",
    "\n",
    "        T = (1 - lambd) * jnp.diag(g) + lambd * jnp.outer(gR_new, gQ_new)\n",
    "        Lambda = jnp.linalg.inv(T)\n",
    "\n",
    "    return Q, R, T, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905adddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd__compute_grad_A(C, Q, R, Lambda, gamma,\n",
    "                       semiRelaxedLeft, semiRelaxedRight,\n",
    "                       Wasserstein = True, FGW = False,\n",
    "                       A  = None,\n",
    "                       B = None,\n",
    "                       alpha = 0.0,\n",
    "                       unbalanced = False,\n",
    "                       full_grad = True):\n",
    "    \"\"\"\n",
    "    JAX version of gradient computation for Wasserstein, GW and FGW.\n",
    "    \"\"\"\n",
    "\n",
    "    r = Lambda.shape[0]\n",
    "    one_r = jnp.ones((r,))\n",
    "    One_rr = jnp.outer(one_r, one_r)\n",
    "\n",
    "    if Wasserstein:\n",
    "        gradQ, gradR = gd__Wasserstein_Grad(C, Q, R, Lambda, full_grad=full_grad)  # À adapter avec OTT-JAX\n",
    "    elif A is not None and B is not None:\n",
    "        if not semiRelaxedLeft and not semiRelaxedRight and not unbalanced:\n",
    "            gradQ = -4 * (A @ Q) @ Lambda @ (R.T @ B @ R) @ Lambda.T\n",
    "            gradR = -4 * (B @ R @ Lambda.T) @ (Q.T @ A @ Q) @ Lambda\n",
    "        elif semiRelaxedRight:\n",
    "            gradQ = -4 * (A @ Q) @ Lambda @ (R.T @ B @ R) @ Lambda.T\n",
    "            gradR = 2 * (B @ B) @ R @ One_rr - 4 * (B @ R @ Lambda.T) @ (Q.T @ A @ Q) @ Lambda\n",
    "        elif semiRelaxedLeft:\n",
    "            gradQ = 2 * (A @ A) @ Q @ One_rr - 4 * (A @ Q) @ Lambda @ (R.T @ B @ R) @ Lambda.T\n",
    "            gradR = -4 * (B @ R @ Lambda.T) @ (Q.T @ A @ Q) @ Lambda\n",
    "        elif unbalanced:\n",
    "            gradQ = 2 * (A @ A) @ Q @ One_rr - 4 * (A @ Q) @ Lambda @ (R.T @ B @ R) @ Lambda.T\n",
    "            gradR = 2 * (B @ B) @ R @ One_rr - 4 * (B @ R @ Lambda.T) @ (Q.T @ A @ Q) @ Lambda\n",
    "\n",
    "        if full_grad:\n",
    "            N1, N2 = Q.shape[0], R.shape[0]\n",
    "            one_N1 = jnp.ones((N1,))\n",
    "            one_N2 = jnp.ones((N2,))\n",
    "            gQ = Q.T @ one_N1\n",
    "            gR = R.T @ one_N2\n",
    "            F = Q @ Lambda @ R.T\n",
    "            MR = Lambda.T @ Q.T @ A @ F @ B @ R @ jnp.diag(1. / gR)\n",
    "            MQ = Lambda @ R.T @ B @ F.T @ A @ Q @ jnp.diag(1. / gQ)\n",
    "            gradQ += 4 * jnp.outer(one_N1, jnp.diag(MQ))\n",
    "            gradR += 4 * jnp.outer(one_N2, jnp.diag(MR))\n",
    "\n",
    "        if FGW:\n",
    "            gradQW, gradRW = gd__Wasserstein_Grad(C, Q, R, Lambda, full_grad=full_grad)  # À adapter\n",
    "            gradQ = (1 - alpha) * gradQW + alpha * gradQ\n",
    "            gradR = (1 - alpha) * gradRW + alpha * gradR\n",
    "    else:\n",
    "        raise ValueError(\"Provide either Wasserstein=True or distance matrices A and B for GW problem.\")\n",
    "\n",
    "    normalizer = jnp.max(jnp.array([jnp.max(jnp.abs(gradQ)), jnp.max(jnp.abs(gradR))]))\n",
    "    gamma_k = gamma / normalizer\n",
    "\n",
    "    return gradQ, gradR, gamma_k\n",
    "\n",
    "\n",
    "def gd__compute_grad_B(C, Q, R, Lambda, gQ, gR, gamma, Wasserstein=True,\n",
    "                       FGW=False, A=None, B=None, alpha=0.0):\n",
    "    '''\n",
    "    JAX version of the Wasserstein / GW / FGW gradient w.r.t. the transport plan T.\n",
    "    '''\n",
    "    if Wasserstein:\n",
    "        gradLambda = Q.T @ C @ R\n",
    "    else:\n",
    "        gradLambda = -4 * Q.T @ A @ Q @ Lambda @ R.T @ B @ R\n",
    "        if FGW:\n",
    "            gradLambda = (1 - alpha) * (Q.T @ C @ R) + alpha * gradLambda\n",
    "\n",
    "    gradT = jnp.diag(1.0 / gQ) @ gradLambda @ jnp.diag(1.0 / gR)\n",
    "    gamma_T = gamma / jnp.max(jnp.abs(gradT))\n",
    "    return gradT, gamma_T\n",
    "\n",
    "def gd__Wasserstein_Grad(C, Q, R, Lambda, full_grad=True):\n",
    "    gradQ = (C @ R) @ Lambda.T\n",
    "    if full_grad:\n",
    "        N1 = Q.shape[0]\n",
    "        one_N1 = jnp.ones((N1,), dtype=Q.dtype)\n",
    "        gQ = Q.T @ one_N1\n",
    "        w1 = jnp.diag((gradQ.T @ Q) @ jnp.diag(1.0 / gQ))\n",
    "        gradQ = gradQ - jnp.outer(one_N1, w1)\n",
    "\n",
    "    gradR = (C.T @ Q) @ Lambda\n",
    "    if full_grad:\n",
    "        N2 = R.shape[0]\n",
    "        one_N2 = jnp.ones((N2,), dtype=R.dtype)\n",
    "        gR = R.T @ one_N2\n",
    "        w2 = jnp.diag(jnp.diag(1.0 / gR) @ (R.T @ gradR))\n",
    "        gradR = gradR - jnp.outer(one_N2, w2)\n",
    "\n",
    "    return gradQ, gradR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "953000d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FRLC_opt(C, a=None, b=None, A=None, B=None, tau_in=50, tau_out=50,\n",
    "             gamma=90, r=10, r2=None, max_iter=200,\n",
    "             semiRelaxedLeft=False, semiRelaxedRight=False, Wasserstein=True,\n",
    "             returnFull=False, FGW=False, alpha=0.0, unbalanced=False,\n",
    "             initialization='Full', init_args=None, full_grad=True,\n",
    "             convergence_criterion=True, tol=1e-5, min_iter=25,\n",
    "             min_iterGW=500, max_iterGW=1000,\n",
    "             max_inneriters_balanced=300, max_inneriters_relaxed=50,\n",
    "             diagonalize_return=False):\n",
    "\n",
    "    N1, N2 = C.shape\n",
    "    k = 0\n",
    "\n",
    "    one_N1 = jnp.ones((N1,))\n",
    "    one_N2 = jnp.ones((N2,))\n",
    "\n",
    "    if a is None:\n",
    "        a = one_N1 / N1\n",
    "    if b is None:\n",
    "        b = one_N2 / N2\n",
    "    if r2 is None:\n",
    "        r2 = r\n",
    "\n",
    "    one_r = jnp.ones((r,))\n",
    "    one_r2 = jnp.ones((r2,))\n",
    "\n",
    "    gQ = one_r / r\n",
    "    gR = one_r2 / r2\n",
    "\n",
    "    full_rank = initialization == 'Full' or initialization not in ['Full', 'Rank-2']\n",
    "\n",
    "    if init_args is None:\n",
    "        Q, R, T, Lambda = utils__initialize_couplings(a, b, gQ, gR,\n",
    "                                                      gamma, full_rank=full_rank,\n",
    "                                                      max_iter=max_inneriters_balanced)\n",
    "    else:\n",
    "        Q, R, T = init_args\n",
    "        Lambda = jnp.diag(1 / (Q.T @ one_N1)) @ T @ jnp.diag(1 / (R.T @ one_N2))\n",
    "\n",
    "    if not Wasserstein:\n",
    "        min_iter = min_iterGW\n",
    "        max_iter = max_iterGW\n",
    "\n",
    "    errs = []\n",
    "    gamma_k = gamma\n",
    "    Q_prev, R_prev, T_prev = None, None, None\n",
    "\n",
    "    def not_converged(k, Q, R, T, Q_prev, R_prev, T_prev, gamma_k):\n",
    "        if not convergence_criterion:\n",
    "            return True\n",
    "        if k < min_iter:\n",
    "            return True\n",
    "        delta = utils__Delta((Q, R, T), (Q_prev, R_prev, T_prev), gamma_k)\n",
    "        return delta > tol\n",
    "\n",
    "    while (k < max_iter and not_converged(k, Q, R, T, Q_prev, R_prev, T_prev, gamma_k)):\n",
    "        if convergence_criterion:\n",
    "            Q_prev, R_prev, T_prev = Q, R, T\n",
    "\n",
    "        if k % 25 == 0:\n",
    "            print(f'Iteration: {k}')\n",
    "\n",
    "        gradQ, gradR, gamma_k = gd__compute_grad_A(C, Q, R, Lambda, gamma,\n",
    "                                                   semiRelaxedLeft, semiRelaxedRight,\n",
    "                                                   Wasserstein=Wasserstein, A=A, B=B,\n",
    "                                                   FGW=FGW, alpha=alpha,\n",
    "                                                   unbalanced=unbalanced, full_grad=full_grad)\n",
    "\n",
    "        logQ = jnp.log(Q)\n",
    "        logR = jnp.log(R)\n",
    "\n",
    "        # Gestion explicite des modes de relaxation\n",
    "        if semiRelaxedLeft:\n",
    "            balanced_Q, unbalanced_Q = False, True\n",
    "            balanced_R, unbalanced_R = False, False\n",
    "        elif semiRelaxedRight:\n",
    "            balanced_Q, unbalanced_Q = False, False\n",
    "            balanced_R, unbalanced_R = False, True\n",
    "        elif unbalanced:\n",
    "            balanced_Q, unbalanced_Q = False, True\n",
    "            balanced_R, unbalanced_R = False, True\n",
    "        else:\n",
    "            balanced_Q, unbalanced_Q = True, False\n",
    "            balanced_R, unbalanced_R = True, False\n",
    "\n",
    "        Q = ott_log_sinkhorn(gradQ - (1 / gamma_k) * logQ, a, gQ, gamma_k,\n",
    "                             max_iter=max_inneriters_relaxed,\n",
    "                             balanced=balanced_Q, unbalanced=unbalanced_Q,\n",
    "                             tau=tau_out, tau2=tau_in)\n",
    "\n",
    "        R = ott_log_sinkhorn(gradR - (1 / gamma_k) * logR, b, gR, gamma_k,\n",
    "                             max_iter=max_inneriters_relaxed,\n",
    "                             balanced=balanced_R, unbalanced=unbalanced_R,\n",
    "                             tau=tau_out, tau2=tau_in)\n",
    "\n",
    "        gQ = Q.T @ one_N1\n",
    "        gR = R.T @ one_N2\n",
    "\n",
    "        gradT, gamma_T = gd__compute_grad_B(C, Q, R, Lambda, gQ, gR,\n",
    "                                            gamma, Wasserstein=Wasserstein,\n",
    "                                            A=A, B=B, FGW=FGW, alpha=alpha)\n",
    "\n",
    "        T = ott_log_sinkhorn(gradT - (1 / gamma_T) * jnp.log(T), gQ, gR, gamma_T,\n",
    "                             max_iter=max_inneriters_balanced,\n",
    "                             balanced=True, unbalanced=False)\n",
    "\n",
    "        Lambda = jnp.diag(1 / gQ) @ T @ jnp.diag(1 / gR)\n",
    "        k += 1\n",
    "\n",
    "    if returnFull:\n",
    "        P = Q @ Lambda @ R.T\n",
    "        return P, errs\n",
    "    else:\n",
    "        if diagonalize_return:\n",
    "            Q = Q @ jnp.diag(1 / gQ) @ T\n",
    "            gR = R.T @ one_N2\n",
    "            T = jnp.diag(gR)\n",
    "        return Q, R, T, errs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def FRLC_compute_OT_cost(X, Y, C = None, Monge_clusters = None, sq_Euclidean = True):\n",
    "    \"\"\"\n",
    "    Compute the optimal transport cost in linear space and time (without coupling), in JAX.\n",
    "    Supports squared Euclidean cost via OTT cost object.\n",
    "    \"\"\"\n",
    "    if Monge_clusters is None or len(Monge_clusters) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    def compute_pair_cost(pair):\n",
    "        idx1, idx2 = pair\n",
    "        if C is not None:\n",
    "            return C[idx1, idx2]\n",
    "        else:\n",
    "            diff = X[idx1] - Y[idx2]\n",
    "            if sq_Euclidean:\n",
    "                return jnp.sum(diff**2)\n",
    "            else:\n",
    "                return jnp.linalg.norm(diff)\n",
    "\n",
    "    pair_costs = jax.vmap(compute_pair_cost)(jnp.array(Monge_clusters))\n",
    "    total_cost = jnp.sum(pair_costs)\n",
    "    return total_cost / len(Monge_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b05f2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:2154\u001b[0m, in \u001b[0;36m_lower_jaxpr_to_fun_cached\u001b[1;34m(ctx, fn_name, call_jaxpr, effects, name_stack, arg_names, result_names)\u001b[0m\n\u001b[0;32m   2153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2154\u001b[0m   func_op \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mcached_primitive_lowerings[key]\n\u001b[0;32m   2155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: (None, let _where = { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:bool[40]\u001b[39m b\u001b[35m:f32[40]\u001b[39m c\u001b[35m:i32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n    \u001b[39m\u001b[22m\u001b[22md\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=False] c\n    e\u001b[35m:f32[40]\u001b[39m = broadcast_in_dim[\n      broadcast_dimensions=()\n      shape=(40,)\n      sharding=None\n    ] d\n    f\u001b[35m:f32[40]\u001b[39m = select_n a e b\n  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(f,) } in\nlet _where1 = { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; g\u001b[35m:bool[40]\u001b[39m h\u001b[35m:f32[40]\u001b[39m i\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n    \u001b[39m\u001b[22m\u001b[22mj\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=False] i\n    k\u001b[35m:f32[40]\u001b[39m = broadcast_in_dim[\n      broadcast_dimensions=()\n      shape=(40,)\n      sharding=None\n    ] j\n    l\u001b[35m:f32[40]\u001b[39m = select_n g k h\n  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(l,) } in\n{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; m\u001b[35m:f32[40]\u001b[39m n\u001b[35m:f32[]\u001b[39m o\u001b[35m:f32[40,40]\u001b[39m p\u001b[35m:f32[40]\u001b[39m q\u001b[35m:i32[1]\u001b[39m r\u001b[35m:i32[]\u001b[39m s\u001b[35m:f32[40]\u001b[39m t\u001b[35m:f32[40]\u001b[39m\n    u\u001b[35m:f32[30,1]\u001b[39m v\u001b[35m:bool[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n    \u001b[39m\u001b[22m\u001b[22mw\u001b[35m:f32[40]\u001b[39m = log m\n    _\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=True] r\n    x\u001b[35m:f32[]\u001b[39m = pow 1.0 r\n    y\u001b[35m:f32[]\u001b[39m = mul 1.0 x\n    z\u001b[35m:f32[]\u001b[39m = max y 1.0\n    ba\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=False] z\n    bb\u001b[35m:f32[]\u001b[39m = mul ba n\n    bc\u001b[35m:f32[40,1]\u001b[39m = broadcast_in_dim[\n      broadcast_dimensions=(0,)\n      shape=(40, 1)\n      sharding=None\n    ] s\n    bd\u001b[35m:f32[1,40]\u001b[39m = broadcast_in_dim[\n      broadcast_dimensions=(1,)\n      shape=(1, 40)\n      sharding=None\n    ] t\n    be\u001b[35m:f32[40,40]\u001b[39m = add bc bd\n    _\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=True] 1.0\n    bf\u001b[35m:f32[40,40]\u001b[39m = mul o 1.0\n    bg\u001b[35m:f32[40,40]\u001b[39m = sub be bf\n    bh\u001b[35m:f32[40,40]\u001b[39m = div bg bb\n    bi\u001b[35m:f32[40]\u001b[39m = custom_jvp_call[\n      call_jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; bj\u001b[35m:f32[40,40]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n          \u001b[39m\u001b[22m\u001b[22mbk\u001b[35m:f32[40]\u001b[39m = reduce_max[axes=(0,)] bj\n          bl\u001b[35m:f32[40]\u001b[39m = max -inf bk\n          bm\u001b[35m:bool[40]\u001b[39m = is_finite bl\n          bn\u001b[35m:f32[40]\u001b[39m = broadcast_in_dim[\n            broadcast_dimensions=()\n            shape=(40,)\n            sharding=None\n          ] 0.0\n          bo\u001b[35m:f32[40]\u001b[39m = select_n bm bn bl\n          bp\u001b[35m:f32[40]\u001b[39m = stop_gradient bo\n          bq\u001b[35m:f32[1,40]\u001b[39m = broadcast_in_dim[\n            broadcast_dimensions=(1,)\n            shape=(1, 40)\n            sharding=None\n          ] bp\n          br\u001b[35m:f32[40,40]\u001b[39m = sub bj bq\n          bs\u001b[35m:f32[40,40]\u001b[39m = exp br\n          bt\u001b[35m:f32[40]\u001b[39m = reduce_sum[axes=(0,)] bs\n          _\u001b[35m:f32[40]\u001b[39m = sign bt\n          bu\u001b[35m:f32[40]\u001b[39m = abs bt\n          bv\u001b[35m:f32[40]\u001b[39m = log bu\n          bw\u001b[35m:f32[40]\u001b[39m = add bv bp\n        \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(bw,) }\n      jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x000001B7C09C1080>\n      num_consts=0\n      symbolic_zeros=False\n    ] bh\n    bx\u001b[35m:f32[40]\u001b[39m = mul bb bi\n    by\u001b[35m:bool[40]\u001b[39m = is_finite t\n    bz\u001b[35m:f32[40]\u001b[39m = pjit[name=_where jaxpr=_where] by t 0\n    ca\u001b[35m:f32[40]\u001b[39m = sub bx bz\n    cb\u001b[35m:f32[40]\u001b[39m = mul bb w\n    cc\u001b[35m:bool[40]\u001b[39m = is_finite ca\n    cd\u001b[35m:f32[40]\u001b[39m = pjit[name=_where jaxpr=_where] cc ca 0\n    ce\u001b[35m:f32[40]\u001b[39m = sub cb cd\n    cf\u001b[35m:f32[40]\u001b[39m = mul 1.0 ce\n    cg\u001b[35m:bool[40]\u001b[39m = is_finite t\n    ch\u001b[35m:f32[40]\u001b[39m = pjit[name=_where jaxpr=_where1] cg t 0.0\n    ci\u001b[35m:f32[40]\u001b[39m = mul 0.0 ch\n    cj\u001b[35m:f32[40]\u001b[39m = mul 1.0 cf\n    ck\u001b[35m:f32[40]\u001b[39m = add ci cj\n    cl\u001b[35m:f32[40]\u001b[39m = log p\n    _\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=True] r\n    cm\u001b[35m:f32[]\u001b[39m = pow 1.0 r\n    cn\u001b[35m:f32[]\u001b[39m = mul 1.0 cm\n    co\u001b[35m:f32[]\u001b[39m = max cn 1.0\n    cp\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=False] co\n    cq\u001b[35m:f32[]\u001b[39m = mul cp n\n    cr\u001b[35m:f32[40,1]\u001b[39m = broadcast_in_dim[\n      broadcast_dimensions=(0,)\n      shape=(40, 1)\n      sharding=None\n    ] s\n    cs\u001b[35m:f32[1,40]\u001b[39m = broadcast_in_dim[\n      broadcast_dimensions=(1,)\n      shape=(1, 40)\n      sharding=None\n    ] ck\n    ct\u001b[35m:f32[40,40]\u001b[39m = add cr cs\n    _\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=True] 1.0\n    cu\u001b[35m:f32[40,40]\u001b[39m = mul o 1.0\n    cv\u001b[35m:f32[40,40]\u001b[39m = sub ct cu\n    cw\u001b[35m:f32[40,40]\u001b[39m = div cv cq\n    cx\u001b[35m:f32[40]\u001b[39m = custom_jvp_call[\n      call_jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; cy\u001b[35m:f32[40,40]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n          \u001b[39m\u001b[22m\u001b[22mcz\u001b[35m:f32[40]\u001b[39m = reduce_max[axes=(1,)] cy\n          da\u001b[35m:f32[40]\u001b[39m = max -inf cz\n          db\u001b[35m:bool[40]\u001b[39m = is_finite da\n          dc\u001b[35m:f32[40]\u001b[39m = broadcast_in_dim[\n            broadcast_dimensions=()\n            shape=(40,)\n            sharding=None\n          ] 0.0\n          dd\u001b[35m:f32[40]\u001b[39m = select_n db dc da\n          de\u001b[35m:f32[40]\u001b[39m = stop_gradient dd\n          df\u001b[35m:f32[40,1]\u001b[39m = broadcast_in_dim[\n            broadcast_dimensions=(0,)\n            shape=(40, 1)\n            sharding=None\n          ] de\n          dg\u001b[35m:f32[40,40]\u001b[39m = sub cy df\n          dh\u001b[35m:f32[40,40]\u001b[39m = exp dg\n          di\u001b[35m:f32[40]\u001b[39m = reduce_sum[axes=(1,)] dh\n          _\u001b[35m:f32[40]\u001b[39m = sign di\n          dj\u001b[35m:f32[40]\u001b[39m = abs di\n          dk\u001b[35m:f32[40]\u001b[39m = log dj\n          dl\u001b[35m:f32[40]\u001b[39m = add dk de\n        \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(dl,) }\n      jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x000001B7C09C1300>\n      num_consts=0\n      symbolic_zeros=False\n    ] cw\n    dm\u001b[35m:f32[40]\u001b[39m = mul cq cx\n    dn\u001b[35m:bool[40]\u001b[39m = is_finite s\n    do\u001b[35m:f32[40]\u001b[39m = pjit[name=_where jaxpr=_where] dn s 0\n    dp\u001b[35m:f32[40]\u001b[39m = sub dm do\n    dq\u001b[35m:f32[40]\u001b[39m = mul cq cl\n    dr\u001b[35m:bool[40]\u001b[39m = is_finite dp\n    ds\u001b[35m:f32[40]\u001b[39m = pjit[name=_where jaxpr=_where] dr dp 0\n    dt\u001b[35m:f32[40]\u001b[39m = sub dq ds\n    du\u001b[35m:f32[40]\u001b[39m = mul 1.0 dt\n    dv\u001b[35m:bool[40]\u001b[39m = is_finite s\n    dw\u001b[35m:f32[40]\u001b[39m = pjit[name=_where jaxpr=_where1] dv s 0.0\n    dx\u001b[35m:f32[40]\u001b[39m = mul 0.0 dw\n    dy\u001b[35m:f32[40]\u001b[39m = mul 1.0 du\n    dz\u001b[35m:f32[40]\u001b[39m = add dx dy\n    ea\u001b[35m:bool[]\u001b[39m = eq r 299\n    eb\u001b[35m:bool[]\u001b[39m = ge r 0\n    ec\u001b[35m:bool[]\u001b[39m = convert_element_type[new_dtype=bool weak_type=False] eb\n    ed\u001b[35m:bool[]\u001b[39m = and v ec\n    ee\u001b[35m:bool[]\u001b[39m = convert_element_type[new_dtype=bool weak_type=False] ea\n    ef\u001b[35m:bool[]\u001b[39m = or ee ed\n    eg\u001b[35m:i32[]\u001b[39m = convert_element_type[new_dtype=int32 weak_type=False] ef\n    eh\u001b[35m:f32[]\u001b[39m = cond[\n      branches=(\n        { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; ei_\u001b[35m:i32[1]\u001b[39m ej\u001b[35m:f32[40]\u001b[39m ek\u001b[35m:f32[40]\u001b[39m el\u001b[35m:f32[30,1]\u001b[39m em\u001b[35m:f32[40,40]\u001b[39m en\u001b[35m:f32[]\u001b[39m\n            eo\u001b[35m:f32[40]\u001b[39m ep\u001b[35m:f32[40]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n            \n          in \u001b[39m\u001b[22m\u001b[22m(inf,) }\n        { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; eq\u001b[35m:i32[1]\u001b[39m er\u001b[35m:f32[40]\u001b[39m es\u001b[35m:f32[40]\u001b[39m et\u001b[35m:f32[30,1]\u001b[39m eu\u001b[35m:f32[40,40]\u001b[39m ev\u001b[35m:f32[]\u001b[39m\n            ew\u001b[35m:f32[40]\u001b[39m ex\u001b[35m:f32[40]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n            \u001b[39m\u001b[22m\u001b[22mey\u001b[35m:f32[40,1]\u001b[39m = broadcast_in_dim[\n              broadcast_dimensions=(0,)\n              shape=(40, 1)\n              sharding=None\n            ] er\n            ez\u001b[35m:f32[1,40]\u001b[39m = broadcast_in_dim[\n              broadcast_dimensions=(1,)\n              shape=(1, 40)\n              sharding=None\n            ] es\n            fa\u001b[35m:f32[40,40]\u001b[39m = add ey ez\n            _\u001b[35m:f32[]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=True] 1.0\n            fb\u001b[35m:f32[40,40]\u001b[39m = mul eu 1.0\n            fc\u001b[35m:f32[40,40]\u001b[39m = sub fa fb\n            fd\u001b[35m:f32[40,40]\u001b[39m = div fc ev\n            fe\u001b[35m:f32[40]\u001b[39m = custom_jvp_call[\n              call_jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; ff\u001b[35m:f32[40,40]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n                  \u001b[39m\u001b[22m\u001b[22mfg\u001b[35m:f32[40]\u001b[39m = reduce_max[axes=(0,)] ff\n                  fh\u001b[35m:f32[40]\u001b[39m = max -inf fg\n                  fi\u001b[35m:bool[40]\u001b[39m = is_finite fh\n                  fj\u001b[35m:f32[40]\u001b[39m = broadcast_in_dim[\n                    broadcast_dimensions=()\n                    shape=(40,)\n                    sharding=None\n                  ] 0.0\n                  fk\u001b[35m:f32[40]\u001b[39m = select_n fi fj fh\n                  fl\u001b[35m:f32[40]\u001b[39m = stop_gradient fk\n                  fm\u001b[35m:f32[1,40]\u001b[39m = broadcast_in_dim[\n                    broadcast_dimensions=(1,)\n                    shape=(1, 40)\n                    sharding=None\n                  ] fl\n                  fn\u001b[35m:f32[40,40]\u001b[39m = sub ff fm\n                  fo\u001b[35m:f32[40,40]\u001b[39m = exp fn\n                  fp\u001b[35m:f32[40]\u001b[39m = reduce_sum[axes=(0,)] fo\n                  _\u001b[35m:f32[40]\u001b[39m = sign fp\n                  fq\u001b[35m:f32[40]\u001b[39m = abs fp\n                  fr\u001b[35m:f32[40]\u001b[39m = log fq\n                  fs\u001b[35m:f32[40]\u001b[39m = add fr fl\n                \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(fs,) }\n              jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x000001B7C09C1580>\n              num_consts=0\n              symbolic_zeros=False\n            ] fd\n            ft\u001b[35m:f32[40]\u001b[39m = mul ev fe\n            fu\u001b[35m:bool[40]\u001b[39m = is_finite es\n            fv\u001b[35m:f32[40]\u001b[39m = pjit[name=_where jaxpr=_where] fu es 0\n            fw\u001b[35m:f32[40]\u001b[39m = sub ft fv\n            fx\u001b[35m:f32[40]\u001b[39m = add fw es\n            fy\u001b[35m:f32[40]\u001b[39m = div fx ev\n            fz\u001b[35m:f32[40]\u001b[39m = exp fy\n            ga\u001b[35m:f32[40]\u001b[39m = sub fz ex\n            gb\u001b[35m:f32[40]\u001b[39m = abs ga\n            gc\u001b[35m:i32[1,1]\u001b[39m = broadcast_in_dim[\n              broadcast_dimensions=(0,)\n              shape=(1, 1)\n              sharding=None\n            ] eq\n            gd\u001b[35m:f32[1,40]\u001b[39m = broadcast_in_dim[\n              broadcast_dimensions=(1,)\n              shape=(1, 40)\n              sharding=None\n            ] gb\n            _\u001b[35m:f32[1,1]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=False] gc\n            ge\u001b[35m:f32[1,40]\u001b[39m = pow gd gc\n            gf\u001b[35m:f32[1]\u001b[39m = reduce_sum[axes=(1,)] ge\n            gg\u001b[35m:f32[1]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=True] eq\n            gh\u001b[35m:f32[1]\u001b[39m = div 1.0 gg\n            gi\u001b[35m:f32[1]\u001b[39m = convert_element_type[new_dtype=float32 weak_type=False] gh\n            gj\u001b[35m:f32[1]\u001b[39m = pow gf gi\n            gk\u001b[35m:f32[1]\u001b[39m = slice[\n              limit_indices=(1,)\n              start_indices=(0,)\n              strides=None\n            ] gj\n            gl\u001b[35m:f32[]\u001b[39m = squeeze[dimensions=(0,)] gk\n          \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(gl,) }\n      )\n    ] eg q dz ck u o n p m\n    gm\u001b[35m:i32[]\u001b[39m = pjit[\n      name=floor_divide\n      jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; gn\u001b[35m:i32[]\u001b[39m go\u001b[35m:i32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n          \u001b[39m\u001b[22m\u001b[22mgp\u001b[35m:i32[]\u001b[39m = div gn go\n          gq\u001b[35m:i32[]\u001b[39m = sign gn\n          gr\u001b[35m:i32[]\u001b[39m = sign go\n          gs\u001b[35m:bool[]\u001b[39m = ne gq gr\n          gt\u001b[35m:i32[]\u001b[39m = rem gn go\n          gu\u001b[35m:bool[]\u001b[39m = ne gt 0\n          gv\u001b[35m:bool[]\u001b[39m = convert_element_type[new_dtype=bool weak_type=False] gs\n          gw\u001b[35m:bool[]\u001b[39m = convert_element_type[new_dtype=bool weak_type=False] gu\n          gx\u001b[35m:bool[]\u001b[39m = and gv gw\n          gy\u001b[35m:i32[]\u001b[39m = sub gp 1\n          gz\u001b[35m:i32[]\u001b[39m = pjit[\n            name=_where\n            jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; ha\u001b[35m:bool[]\u001b[39m hb\u001b[35m:i32[]\u001b[39m hc\u001b[35m:i32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n                \u001b[39m\u001b[22m\u001b[22mhd\u001b[35m:i32[]\u001b[39m = select_n ha hc hb\n              \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(hd,) }\n          ] gx gy gp\n        \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(gz,) }\n    ] r 10\n    he\u001b[35m:bool[]\u001b[39m = lt gm 0\n    hf\u001b[35m:i32[]\u001b[39m = add gm 30\n    hg\u001b[35m:i32[]\u001b[39m = select_n he gm hf\n    hh\u001b[35m:i32[]\u001b[39m = convert_element_type[new_dtype=int32 weak_type=False] hg\n    hi\u001b[35m:i32[1]\u001b[39m = broadcast_in_dim[\n      broadcast_dimensions=()\n      shape=(1,)\n      sharding=None\n    ] hh\n    hj\u001b[35m:f32[1]\u001b[39m = broadcast_in_dim[\n      broadcast_dimensions=()\n      shape=(1,)\n      sharding=None\n    ] eh\n    hk\u001b[35m:f32[30,1]\u001b[39m = scatter[\n      dimension_numbers=ScatterDimensionNumbers(update_window_dims=(0,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,), operand_batching_dims=(), scatter_indices_batching_dims=())\n      indices_are_sorted=True\n      mode=GatherScatterMode.FILL_OR_DROP\n      unique_indices=True\n      update_consts=()\n      update_jaxpr=None\n    ] u hi hj\n    hl\u001b[35m:i32[]\u001b[39m = add r 1\n  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(hl, dz, ck, hk) }, ())",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m C \u001b[38;5;241m=\u001b[39m cdist_jax(X, Y)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# 2. Appel à FRLC_opt (on passe dtype=jnp.float32)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     Q, R, T, errs \u001b[38;5;241m=\u001b[39m FRLC_opt(\n\u001b[0;32m     14\u001b[0m         C\u001b[38;5;241m=\u001b[39mC,\n\u001b[0;32m     15\u001b[0m         gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m     16\u001b[0m         r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m,\n\u001b[0;32m     17\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     18\u001b[0m         tau_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# 3. Calcul de la matrice de couplage P complète\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     inv_sum_Q \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m jnp\u001b[38;5;241m.\u001b[39msum(Q, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape (r,)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 103\u001b[0m, in \u001b[0;36mFRLC_opt\u001b[1;34m(C, a, b, A, B, tau_in, tau_out, gamma, r, r2, max_iter, semiRelaxedLeft, semiRelaxedRight, Wasserstein, returnFull, FGW, alpha, unbalanced, initialization, init_args, full_grad, convergence_criterion, tol, min_iter, min_iterGW, max_iterGW, max_inneriters_balanced, max_inneriters_relaxed, diagonalize_return)\u001b[0m\n\u001b[0;32m     97\u001b[0m gR \u001b[38;5;241m=\u001b[39m R\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m one_N2\n\u001b[0;32m     99\u001b[0m gradT, gamma_T \u001b[38;5;241m=\u001b[39m gd__compute_grad_B(C, Q, R, Lambda, gQ, gR,\n\u001b[0;32m    100\u001b[0m                                     gamma, Wasserstein\u001b[38;5;241m=\u001b[39mWasserstein,\n\u001b[0;32m    101\u001b[0m                                     A\u001b[38;5;241m=\u001b[39mA, B\u001b[38;5;241m=\u001b[39mB, FGW\u001b[38;5;241m=\u001b[39mFGW, alpha\u001b[38;5;241m=\u001b[39malpha)\n\u001b[1;32m--> 103\u001b[0m T \u001b[38;5;241m=\u001b[39m ott_log_sinkhorn(gradT \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m gamma_T) \u001b[38;5;241m*\u001b[39m jnp\u001b[38;5;241m.\u001b[39mlog(T), gQ, gR, gamma_T,\n\u001b[0;32m    104\u001b[0m                      max_iter\u001b[38;5;241m=\u001b[39mmax_inneriters_balanced,\n\u001b[0;32m    105\u001b[0m                      balanced\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, unbalanced\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    107\u001b[0m Lambda \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mdiag(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m gQ) \u001b[38;5;241m@\u001b[39m T \u001b[38;5;241m@\u001b[39m jnp\u001b[38;5;241m.\u001b[39mdiag(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m gR)\n\u001b[0;32m    108\u001b[0m k \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m, in \u001b[0;36mott_log_sinkhorn\u001b[1;34m(grad, a, b, gamma_k, max_iter, balanced, unbalanced, tau, tau2)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Solveur Sinkhorn\u001b[39;00m\n\u001b[0;32m     40\u001b[0m solver \u001b[38;5;241m=\u001b[39m sinkhorn\u001b[38;5;241m.\u001b[39mSinkhorn(max_iterations\u001b[38;5;241m=\u001b[39mmax_iter)\n\u001b[1;32m---> 41\u001b[0m out \u001b[38;5;241m=\u001b[39m solver(prob)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39mmatrix\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\ott\\solvers\\linear\\sinkhorn.py:756\u001b[0m, in \u001b[0;36mSinkhorn.__call__\u001b[1;34m(self, ot_prob, init, **kwargs)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m   init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitializer(ot_prob, lse_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlse_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 756\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run(ot_prob, \u001b[38;5;28mself\u001b[39m, init)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\ott\\solvers\\linear\\sinkhorn.py:1013\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(ot_prob, solver, init)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run loop of the solver, outputting a state upgraded to an output.\"\"\"\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m iter_fun \u001b[38;5;241m=\u001b[39m _iterations_implicit \u001b[38;5;28;01mif\u001b[39;00m solver\u001b[38;5;241m.\u001b[39mimplicit_diff \u001b[38;5;28;01melse\u001b[39;00m iterations\n\u001b[1;32m-> 1013\u001b[0m out \u001b[38;5;241m=\u001b[39m iter_fun(ot_prob, solver, init)\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;66;03m# Be careful here, the geom and the cost are injected at the end, where it\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# does not interfere with the implicit differentiation.\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mset_cost(ot_prob, solver\u001b[38;5;241m.\u001b[39mlse_mode, solver\u001b[38;5;241m.\u001b[39muse_danskin)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\custom_derivatives.py:615\u001b[0m, in \u001b[0;36mcustom_vjp.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    612\u001b[0m flat_fwd, out_trees \u001b[38;5;241m=\u001b[39m _flatten_fwd(fwd_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_zeros, primal_name,\n\u001b[0;32m    613\u001b[0m                                    fwd_name, in_tree, out_type)\n\u001b[0;32m    614\u001b[0m flat_bwd \u001b[38;5;241m=\u001b[39m _flatten_bwd(bwd, in_tree, in_avals, out_trees)\u001b[38;5;241m.\u001b[39mcall_wrapped\n\u001b[1;32m--> 615\u001b[0m out_flat \u001b[38;5;241m=\u001b[39m custom_vjp_call_p\u001b[38;5;241m.\u001b[39mbind(flat_fun, flat_fwd, flat_bwd,\n\u001b[0;32m    616\u001b[0m                                   \u001b[38;5;241m*\u001b[39margs_flat, out_trees\u001b[38;5;241m=\u001b[39mout_trees,\n\u001b[0;32m    617\u001b[0m                                   symbolic_zeros\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_zeros)\n\u001b[0;32m    618\u001b[0m _, (out_tree, _) \u001b[38;5;241m=\u001b[39m lu\u001b[38;5;241m.\u001b[39mmerge_linear_aux(out_type, out_trees)\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree, out_flat)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\core.py:463\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m    461\u001b[0m trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(eval_trace)\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind_with_trace(prev_trace, args, params)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m   trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(prev_trace)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\custom_derivatives.py:800\u001b[0m, in \u001b[0;36mCustomVJPCallPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m    799\u001b[0m   fun, fwd, bwd, tracers \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m], args[\u001b[38;5;241m2\u001b[39m], args[\u001b[38;5;241m3\u001b[39m:]\n\u001b[1;32m--> 800\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mprocess_custom_vjp_call(\u001b[38;5;28mself\u001b[39m, fun, fwd, bwd, tracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\core.py:962\u001b[0m, in \u001b[0;36mEvalTrace.process_custom_vjp_call\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_custom_vjp_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, fun, fwd, bwd, tracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_):  \u001b[38;5;66;03m# pytype: disable=signature-mismatch\u001b[39;00m\n\u001b[0;32m    961\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m primitive, fwd, bwd, _  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m--> 962\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun\u001b[38;5;241m.\u001b[39mcall_wrapped(\u001b[38;5;241m*\u001b[39mtracers)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\linear_util.py:187\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    186\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_transformed(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\custom_derivatives.py:81\u001b[0m, in \u001b[0;36m_flatten_fun_nokwargs\u001b[1;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flatten_fun_nokwargs\u001b[39m(f, store, in_tree, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[0;32m     80\u001b[0m   py_args \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[1;32m---> 81\u001b[0m   ans \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39mpy_args)\n\u001b[0;32m     82\u001b[0m   ans_flat, ans_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[0;32m     83\u001b[0m   ans_avals \u001b[38;5;241m=\u001b[39m [core\u001b[38;5;241m.\u001b[39mget_aval(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ans_flat]\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\ott\\solvers\\linear\\sinkhorn.py:1050\u001b[0m, in \u001b[0;36miterations\u001b[1;34m(ot_prob, solver, init)\u001b[0m\n\u001b[0;32m   1048\u001b[0m const \u001b[38;5;241m=\u001b[39m ot_prob, solver\n\u001b[0;32m   1049\u001b[0m state \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39minit_state(ot_prob, init)\n\u001b[1;32m-> 1050\u001b[0m state \u001b[38;5;241m=\u001b[39m fix_point(\n\u001b[0;32m   1051\u001b[0m     cond_fn, body_fn, solver\u001b[38;5;241m.\u001b[39mmin_iterations, solver\u001b[38;5;241m.\u001b[39mmax_iterations,\n\u001b[0;32m   1052\u001b[0m     solver\u001b[38;5;241m.\u001b[39minner_iterations, const, state\n\u001b[0;32m   1053\u001b[0m )\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solver\u001b[38;5;241m.\u001b[39moutput_from_state(ot_prob, state)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\ott\\math\\fixed_point_loop.py:92\u001b[0m, in \u001b[0;36mfixpoint_iter\u001b[1;34m(cond_fn, body_fn, min_iterations, max_iterations, inner_iterations, constants, state)\u001b[0m\n\u001b[0;32m     86\u001b[0m   (_, state), _ \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mscan(\n\u001b[0;32m     87\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m carry, x: unrolled_body_fn(carry), (\u001b[38;5;241m0\u001b[39m, state),\n\u001b[0;32m     88\u001b[0m       \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     89\u001b[0m       length\u001b[38;5;241m=\u001b[39mmax_iterations \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m inner_iterations\n\u001b[0;32m     90\u001b[0m   )\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   _, state \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mwhile_loop(max_cond_fn, unrolled_body_fn, (\u001b[38;5;241m0\u001b[39m, state))\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\lax\\control_flow\\loops.py:1364\u001b[0m, in \u001b[0;36mwhile_loop\u001b[1;34m(cond_fun, body_fun, init_val)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disallowed_effects:\n\u001b[0;32m   1362\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1363\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEffects not supported in `while`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisallowed_effects\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1364\u001b[0m outs \u001b[38;5;241m=\u001b[39m while_p\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39mcond_consts, \u001b[38;5;241m*\u001b[39mbody_consts, \u001b[38;5;241m*\u001b[39minit_vals,\n\u001b[0;32m   1365\u001b[0m                     cond_nconsts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(cond_consts), cond_jaxpr\u001b[38;5;241m=\u001b[39mcond_jaxpr,\n\u001b[0;32m   1366\u001b[0m                     body_nconsts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(body_consts), body_jaxpr\u001b[38;5;241m=\u001b[39mbody_jaxpr)\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(body_tree, outs)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\core.py:463\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m    461\u001b[0m trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(eval_trace)\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind_with_trace(prev_trace, args, params)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m   trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(prev_trace)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\core.py:468\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m--> 468\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mprocess_primitive(\u001b[38;5;28mself\u001b[39m, args, params)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\core.py:941\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[1;34m(self, primitive, args, params)\u001b[0m\n\u001b[0;32m    939\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mbind_with_trace(arg\u001b[38;5;241m.\u001b[39m_trace, args, params)\n\u001b[0;32m    940\u001b[0m check_eval_args(args)\n\u001b[1;32m--> 941\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\dispatch.py:90\u001b[0m, in \u001b[0;36mapply_primitive\u001b[1;34m(prim, *args, **params)\u001b[0m\n\u001b[0;32m     88\u001b[0m prev \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m   outs \u001b[38;5;241m=\u001b[39m fun(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m   lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(prev)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\pjit.py:337\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mno_tracing\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m    333\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mre-tracing function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjit_info\u001b[38;5;241m.\u001b[39mfun_sourceinfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`jit`, but \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_tracing\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    336\u001b[0m (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, executable,\n\u001b[1;32m--> 337\u001b[0m  pgle_profiler) \u001b[38;5;241m=\u001b[39m _python_pjit_helper(fun, jit_info, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    339\u001b[0m maybe_fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[0;32m    340\u001b[0m     executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr\u001b[38;5;241m.\u001b[39meffects,\n\u001b[0;32m    341\u001b[0m     jaxpr\u001b[38;5;241m.\u001b[39mconsts, jit_info\u001b[38;5;241m.\u001b[39mabstracted_axes,\n\u001b[0;32m    342\u001b[0m     pgle_profiler)\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs, maybe_fastpath_data, _need_to_rebuild_with_fdo(pgle_profiler)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\pjit.py:195\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[1;34m(fun, jit_info, *args, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m   args_flat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(core\u001b[38;5;241m.\u001b[39mfull_lower, args_flat)\n\u001b[0;32m    194\u001b[0m   core\u001b[38;5;241m.\u001b[39mcheck_eval_args(args_flat)\n\u001b[1;32m--> 195\u001b[0m   out_flat, compiled, profiler \u001b[38;5;241m=\u001b[39m _pjit_call_impl_python(\u001b[38;5;241m*\u001b[39margs_flat, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m pjit_p\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs_flat, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\pjit.py:1663\u001b[0m, in \u001b[0;36m_pjit_call_impl_python\u001b[1;34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, compiler_options_kvs, *args)\u001b[0m\n\u001b[0;32m   1660\u001b[0m compiler_options_kvs \u001b[38;5;241m=\u001b[39m compiler_options_kvs \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(pgle_compile_options\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;66;03m# Passing mutable PGLE profile here since it should be extracted by JAXPR to\u001b[39;00m\n\u001b[0;32m   1662\u001b[0m \u001b[38;5;66;03m# initialize the fdo_profile compile option.\u001b[39;00m\n\u001b[1;32m-> 1663\u001b[0m compiled \u001b[38;5;241m=\u001b[39m _resolve_and_lower(\n\u001b[0;32m   1664\u001b[0m     args, jaxpr\u001b[38;5;241m=\u001b[39mjaxpr, in_shardings\u001b[38;5;241m=\u001b[39min_shardings,\n\u001b[0;32m   1665\u001b[0m     out_shardings\u001b[38;5;241m=\u001b[39mout_shardings, in_layouts\u001b[38;5;241m=\u001b[39min_layouts,\n\u001b[0;32m   1666\u001b[0m     out_layouts\u001b[38;5;241m=\u001b[39mout_layouts, resource_env\u001b[38;5;241m=\u001b[39mresource_env,\n\u001b[0;32m   1667\u001b[0m     donated_invars\u001b[38;5;241m=\u001b[39mdonated_invars, name\u001b[38;5;241m=\u001b[39mname, keep_unused\u001b[38;5;241m=\u001b[39mkeep_unused,\n\u001b[0;32m   1668\u001b[0m     inline\u001b[38;5;241m=\u001b[39minline, lowering_platforms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1669\u001b[0m     lowering_parameters\u001b[38;5;241m=\u001b[39mmlir\u001b[38;5;241m.\u001b[39mLoweringParameters(),\n\u001b[0;32m   1670\u001b[0m     pgle_profiler\u001b[38;5;241m=\u001b[39mpgle_profiler,\n\u001b[0;32m   1671\u001b[0m     compiler_options_kvs\u001b[38;5;241m=\u001b[39mcompiler_options_kvs,\n\u001b[0;32m   1672\u001b[0m )\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[0;32m   1674\u001b[0m \u001b[38;5;66;03m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n\u001b[0;32m   1675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compiled\u001b[38;5;241m.\u001b[39m_auto_spmd_lowering \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39menable_checks\u001b[38;5;241m.\u001b[39mvalue:\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\pjit.py:1630\u001b[0m, in \u001b[0;36m_resolve_and_lower\u001b[1;34m(args, jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, lowering_platforms, lowering_parameters, pgle_profiler, compiler_options_kvs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m in_shardings \u001b[38;5;241m=\u001b[39m _resolve_in_shardings(args, in_shardings)\n\u001b[0;32m   1628\u001b[0m in_layouts \u001b[38;5;241m=\u001b[39m _resolve_in_layouts(args, in_layouts, in_shardings,\n\u001b[0;32m   1629\u001b[0m                                  jaxpr\u001b[38;5;241m.\u001b[39min_avals)\n\u001b[1;32m-> 1630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _pjit_lower(\n\u001b[0;32m   1631\u001b[0m     jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env,\n\u001b[0;32m   1632\u001b[0m     donated_invars, name, keep_unused, inline, compiler_options_kvs,\n\u001b[0;32m   1633\u001b[0m     lowering_platforms\u001b[38;5;241m=\u001b[39mlowering_platforms,\n\u001b[0;32m   1634\u001b[0m     lowering_parameters\u001b[38;5;241m=\u001b[39mlowering_parameters,\n\u001b[0;32m   1635\u001b[0m     pgle_profiler\u001b[38;5;241m=\u001b[39mpgle_profiler)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\pjit.py:1795\u001b[0m, in \u001b[0;36m_pjit_lower\u001b[1;34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, compiler_options_kvs, lowering_platforms, lowering_parameters, pgle_profiler)\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1793\u001b[0m   mesh, api_name \u001b[38;5;241m=\u001b[39m ((resource_env\u001b[38;5;241m.\u001b[39mphysical_mesh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpjit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1794\u001b[0m                     \u001b[38;5;28;01mif\u001b[39;00m resource_env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m-> 1795\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pxla\u001b[38;5;241m.\u001b[39mlower_sharding_computation(\n\u001b[0;32m   1796\u001b[0m     jaxpr, api_name, name, in_shardings, out_shardings,\n\u001b[0;32m   1797\u001b[0m     in_layouts, out_layouts, \u001b[38;5;28mtuple\u001b[39m(donated_invars),\n\u001b[0;32m   1798\u001b[0m     keep_unused\u001b[38;5;241m=\u001b[39mkeep_unused, context_mesh\u001b[38;5;241m=\u001b[39mmesh,\n\u001b[0;32m   1799\u001b[0m     compiler_options_kvs\u001b[38;5;241m=\u001b[39mcompiler_options_kvs,\n\u001b[0;32m   1800\u001b[0m     lowering_platforms\u001b[38;5;241m=\u001b[39mlowering_platforms,\n\u001b[0;32m   1801\u001b[0m     lowering_parameters\u001b[38;5;241m=\u001b[39mlowering_parameters,\n\u001b[0;32m   1802\u001b[0m     pgle_profiler\u001b[38;5;241m=\u001b[39mpgle_profiler)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\profiler.py:333\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    332\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[1;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\pxla.py:2323\u001b[0m, in \u001b[0;36mlower_sharding_computation\u001b[1;34m(closed_jaxpr, api_name, fun_name, in_shardings, out_shardings, in_layouts, out_layouts, donated_invars, keep_unused, context_mesh, compiler_options_kvs, lowering_platforms, lowering_parameters, pgle_profiler)\u001b[0m\n\u001b[0;32m   2317\u001b[0m semantic_in_shardings \u001b[38;5;241m=\u001b[39m SemanticallyEqualShardings(\n\u001b[0;32m   2318\u001b[0m     in_shardings, global_in_avals)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2319\u001b[0m semantic_out_shardings \u001b[38;5;241m=\u001b[39m SemanticallyEqualShardings(\n\u001b[0;32m   2320\u001b[0m     out_shardings, global_out_avals)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2322\u001b[0m (module, keepalive, host_callbacks, unordered_effects, ordered_effects,\n\u001b[1;32m-> 2323\u001b[0m  nreps, tuple_args, shape_poly_state) \u001b[38;5;241m=\u001b[39m _cached_lowering_to_hlo(\n\u001b[0;32m   2324\u001b[0m      closed_jaxpr, api_name, fun_name, backend, semantic_in_shardings,\n\u001b[0;32m   2325\u001b[0m      semantic_out_shardings, in_layouts, out_layouts, num_devices,\n\u001b[0;32m   2326\u001b[0m      \u001b[38;5;28mtuple\u001b[39m(da_object) \u001b[38;5;28;01mif\u001b[39;00m prim_requires_devices \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, donated_invars,\n\u001b[0;32m   2327\u001b[0m      name_stack, all_default_mem_kind, inout_aliases,\n\u001b[0;32m   2328\u001b[0m      propagated_out_mem_kinds, platforms,\n\u001b[0;32m   2329\u001b[0m      lowering_parameters\u001b[38;5;241m=\u001b[39mlowering_parameters,\n\u001b[0;32m   2330\u001b[0m      abstract_mesh\u001b[38;5;241m=\u001b[39mabstract_mesh)\n\u001b[0;32m   2332\u001b[0m \u001b[38;5;66;03m# backend and device_assignment is passed through to MeshExecutable because\u001b[39;00m\n\u001b[0;32m   2333\u001b[0m \u001b[38;5;66;03m# if keep_unused=False and all in_shardings are pruned, then there is no way\u001b[39;00m\n\u001b[0;32m   2334\u001b[0m \u001b[38;5;66;03m# to get the device_assignment and backend. So pass it to MeshExecutable\u001b[39;00m\n\u001b[0;32m   2335\u001b[0m \u001b[38;5;66;03m# because we calculate the device_assignment and backend before in_shardings,\u001b[39;00m\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;66;03m# etc are pruned.\u001b[39;00m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MeshComputation(\n\u001b[0;32m   2338\u001b[0m     \u001b[38;5;28mstr\u001b[39m(name_stack),\n\u001b[0;32m   2339\u001b[0m     module,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2369\u001b[0m     intermediate_shardings\u001b[38;5;241m=\u001b[39munique_intermediate_shardings,\n\u001b[0;32m   2370\u001b[0m     context_mesh\u001b[38;5;241m=\u001b[39mcontext_mesh)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\pxla.py:1953\u001b[0m, in \u001b[0;36m_cached_lowering_to_hlo\u001b[1;34m(closed_jaxpr, api_name, fun_name, backend, semantic_in_shardings, semantic_out_shardings, in_layouts, out_layouts, num_devices, device_assignment, donated_invars, name_stack, all_default_mem_kind, inout_aliases, propagated_out_mem_kinds, platforms, lowering_parameters, abstract_mesh)\u001b[0m\n\u001b[0;32m   1949\u001b[0m ordered_effects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(effects\u001b[38;5;241m.\u001b[39mordered_effects\u001b[38;5;241m.\u001b[39mfilter_in(closed_jaxpr\u001b[38;5;241m.\u001b[39meffects))\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mlog_elapsed_time(\n\u001b[0;32m   1951\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished jaxpr to MLIR module conversion \u001b[39m\u001b[38;5;132;01m{fun_name}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{elapsed_time:.9f}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1952\u001b[0m       fun_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(name_stack), event\u001b[38;5;241m=\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mJAXPR_TO_MLIR_MODULE_EVENT):\n\u001b[1;32m-> 1953\u001b[0m   lowering_result \u001b[38;5;241m=\u001b[39m mlir\u001b[38;5;241m.\u001b[39mlower_jaxpr_to_module(\n\u001b[0;32m   1954\u001b[0m       module_name,\n\u001b[0;32m   1955\u001b[0m       closed_jaxpr,\n\u001b[0;32m   1956\u001b[0m       ordered_effects\u001b[38;5;241m=\u001b[39mordered_effects,\n\u001b[0;32m   1957\u001b[0m       backend_or_name\u001b[38;5;241m=\u001b[39mbackend,\n\u001b[0;32m   1958\u001b[0m       platforms\u001b[38;5;241m=\u001b[39mplatforms,\n\u001b[0;32m   1959\u001b[0m       axis_context\u001b[38;5;241m=\u001b[39maxis_ctx,\n\u001b[0;32m   1960\u001b[0m       name_stack\u001b[38;5;241m=\u001b[39mname_stack,\n\u001b[0;32m   1961\u001b[0m       donated_args\u001b[38;5;241m=\u001b[39mdonated_invars,\n\u001b[0;32m   1962\u001b[0m       replicated_args\u001b[38;5;241m=\u001b[39mreplicated_args,\n\u001b[0;32m   1963\u001b[0m       arg_shardings\u001b[38;5;241m=\u001b[39min_mlir_shardings,\n\u001b[0;32m   1964\u001b[0m       result_shardings\u001b[38;5;241m=\u001b[39mout_mlir_shardings,\n\u001b[0;32m   1965\u001b[0m       in_layouts\u001b[38;5;241m=\u001b[39min_layouts,\n\u001b[0;32m   1966\u001b[0m       out_layouts\u001b[38;5;241m=\u001b[39mout_layouts,\n\u001b[0;32m   1967\u001b[0m       arg_names\u001b[38;5;241m=\u001b[39mjaxpr\u001b[38;5;241m.\u001b[39mdebug_info \u001b[38;5;129;01mand\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39mdebug_info\u001b[38;5;241m.\u001b[39marg_names,\n\u001b[0;32m   1968\u001b[0m       result_names\u001b[38;5;241m=\u001b[39mjaxpr\u001b[38;5;241m.\u001b[39mdebug_info \u001b[38;5;129;01mand\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39mdebug_info\u001b[38;5;241m.\u001b[39mresult_paths,\n\u001b[0;32m   1969\u001b[0m       num_replicas\u001b[38;5;241m=\u001b[39mnreps,\n\u001b[0;32m   1970\u001b[0m       num_partitions\u001b[38;5;241m=\u001b[39mnum_partitions,\n\u001b[0;32m   1971\u001b[0m       all_default_mem_kind\u001b[38;5;241m=\u001b[39mall_default_mem_kind,\n\u001b[0;32m   1972\u001b[0m       input_output_aliases\u001b[38;5;241m=\u001b[39minout_aliases,\n\u001b[0;32m   1973\u001b[0m       propagated_out_mem_kinds\u001b[38;5;241m=\u001b[39mpropagated_out_mem_kinds,\n\u001b[0;32m   1974\u001b[0m       lowering_parameters\u001b[38;5;241m=\u001b[39mlowering_parameters)\n\u001b[0;32m   1975\u001b[0m tuple_args \u001b[38;5;241m=\u001b[39m dispatch\u001b[38;5;241m.\u001b[39mshould_tuple_args(\u001b[38;5;28mlen\u001b[39m(global_in_avals), backend\u001b[38;5;241m.\u001b[39mplatform)\n\u001b[0;32m   1976\u001b[0m unordered_effects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   1977\u001b[0m     effects\u001b[38;5;241m.\u001b[39mordered_effects\u001b[38;5;241m.\u001b[39mfilter_not_in(closed_jaxpr\u001b[38;5;241m.\u001b[39meffects))\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:1171\u001b[0m, in \u001b[0;36mlower_jaxpr_to_module\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1169\u001b[0m attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmhlo.num_replicas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m i32_attr(num_replicas)\n\u001b[0;32m   1170\u001b[0m attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmhlo.num_partitions\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m i32_attr(num_partitions)\n\u001b[1;32m-> 1171\u001b[0m lower_jaxpr_to_fun(\n\u001b[0;32m   1172\u001b[0m     ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m, jaxpr, ordered_effects,\n\u001b[0;32m   1173\u001b[0m     name_stack\u001b[38;5;241m=\u001b[39mname_stack,\n\u001b[0;32m   1174\u001b[0m     public\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1175\u001b[0m     replicated_args\u001b[38;5;241m=\u001b[39mreplicated_args,\n\u001b[0;32m   1176\u001b[0m     arg_shardings\u001b[38;5;241m=\u001b[39marg_shardings,\n\u001b[0;32m   1177\u001b[0m     result_shardings\u001b[38;5;241m=\u001b[39mresult_shardings,\n\u001b[0;32m   1178\u001b[0m     input_output_aliases\u001b[38;5;241m=\u001b[39minput_output_aliases,\n\u001b[0;32m   1179\u001b[0m     xla_donated_args\u001b[38;5;241m=\u001b[39mxla_donated_args,\n\u001b[0;32m   1180\u001b[0m     arg_names\u001b[38;5;241m=\u001b[39marg_names,\n\u001b[0;32m   1181\u001b[0m     result_names\u001b[38;5;241m=\u001b[39mresult_names,\n\u001b[0;32m   1182\u001b[0m     arg_memory_kinds\u001b[38;5;241m=\u001b[39marg_memory_kinds,\n\u001b[0;32m   1183\u001b[0m     result_memory_kinds\u001b[38;5;241m=\u001b[39mresult_memory_kinds,\n\u001b[0;32m   1184\u001b[0m     arg_layouts\u001b[38;5;241m=\u001b[39min_layouts,\n\u001b[0;32m   1185\u001b[0m     result_layouts\u001b[38;5;241m=\u001b[39mout_layouts,\n\u001b[0;32m   1186\u001b[0m     propagated_out_mem_kinds\u001b[38;5;241m=\u001b[39mpropagated_out_mem_kinds)\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39muse_shardy_partitioner\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m   1188\u001b[0m   pipeline \u001b[38;5;241m=\u001b[39m passmanager\u001b[38;5;241m.\u001b[39mPassManager\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m   1189\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuiltin.module(sdy-lift-inlined-meshes)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:1646\u001b[0m, in \u001b[0;36mlower_jaxpr_to_fun\u001b[1;34m(ctx, name, jaxpr, effects, name_stack, public, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, xla_donated_args, api_name, arg_names, result_names, arg_memory_kinds, result_memory_kinds, arg_layouts, result_layouts, propagated_out_mem_kinds)\u001b[0m\n\u001b[0;32m   1644\u001b[0m   callee_name_stack \u001b[38;5;241m=\u001b[39m name_stack\n\u001b[0;32m   1645\u001b[0m consts \u001b[38;5;241m=\u001b[39m [ir_constant(xla\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39mconsts]\n\u001b[1;32m-> 1646\u001b[0m out_vals, tokens_out \u001b[38;5;241m=\u001b[39m jaxpr_subcomp(\n\u001b[0;32m   1647\u001b[0m     ctx, jaxpr\u001b[38;5;241m.\u001b[39mjaxpr, callee_name_stack, tokens_in,\n\u001b[0;32m   1648\u001b[0m     consts, \u001b[38;5;241m*\u001b[39margs, dim_var_values\u001b[38;5;241m=\u001b[39mdim_var_values)\n\u001b[0;32m   1649\u001b[0m outs: \u001b[38;5;28mlist\u001b[39m[IrValues] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1650\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eff \u001b[38;5;129;01min\u001b[39;00m effects:\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:1905\u001b[0m, in \u001b[0;36mjaxpr_subcomp\u001b[1;34m(ctx, jaxpr, name_stack, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[0;32m   1902\u001b[0m   rule_ctx \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mreplace(axis_size_env\u001b[38;5;241m=\u001b[39maxis_size_env)\n\u001b[0;32m   1904\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_ir_values(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m in_nodes), (eqn, in_nodes)\n\u001b[1;32m-> 1905\u001b[0m ans \u001b[38;5;241m=\u001b[39m lower_per_platform(rule_ctx, \u001b[38;5;28mstr\u001b[39m(eqn\u001b[38;5;241m.\u001b[39mprimitive),\n\u001b[0;32m   1906\u001b[0m                          platform_rules, default_rule,\n\u001b[0;32m   1907\u001b[0m                          eqn\u001b[38;5;241m.\u001b[39meffects,\n\u001b[0;32m   1908\u001b[0m                          \u001b[38;5;241m*\u001b[39min_nodes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meqn\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m   1910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effects:\n\u001b[0;32m   1911\u001b[0m   \u001b[38;5;66;03m# If there were ordered effects in the primitive, there should be output\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m   \u001b[38;5;66;03m# tokens we need for subsequent ordered effects.\u001b[39;00m\n\u001b[0;32m   1913\u001b[0m   tokens_out \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mtokens_out\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:2023\u001b[0m, in \u001b[0;36mlower_per_platform\u001b[1;34m(ctx, description, platform_rules, default_rule, effects, *rule_args, **rule_kwargs)\u001b[0m\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;66;03m# If there is a single rule left just apply the rule, without conditionals.\u001b[39;00m\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kept_rules) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 2023\u001b[0m   output \u001b[38;5;241m=\u001b[39m kept_rules[\u001b[38;5;241m0\u001b[39m](ctx, \u001b[38;5;241m*\u001b[39mrule_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrule_kwargs)\n\u001b[0;32m   2024\u001b[0m   \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m   2025\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m o: wrap_compute_type_in_place(ctx, o\u001b[38;5;241m.\u001b[39mowner),\n\u001b[0;32m   2026\u001b[0m       \u001b[38;5;28mfilter\u001b[39m(_is_not_block_argument, flatten_ir_values(output)),\n\u001b[0;32m   2027\u001b[0m   )\n\u001b[0;32m   2028\u001b[0m   \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m   2029\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m o: wrap_xla_metadata_in_place(ctx, o\u001b[38;5;241m.\u001b[39mowner),\n\u001b[0;32m   2030\u001b[0m       flatten_ir_values(output),\n\u001b[0;32m   2031\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\lax\\control_flow\\loops.py:1787\u001b[0m, in \u001b[0;36m_while_lowering\u001b[1;34m(ctx, cond_jaxpr, body_jaxpr, cond_nconsts, body_nconsts, *args)\u001b[0m\n\u001b[0;32m   1784\u001b[0m body_name_stack \u001b[38;5;241m=\u001b[39m name_stack\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1785\u001b[0m body_consts \u001b[38;5;241m=\u001b[39m [mlir\u001b[38;5;241m.\u001b[39mir_constant(xla\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(x))\n\u001b[0;32m   1786\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m body_jaxpr\u001b[38;5;241m.\u001b[39mconsts]\n\u001b[1;32m-> 1787\u001b[0m new_z, tokens_out \u001b[38;5;241m=\u001b[39m mlir\u001b[38;5;241m.\u001b[39mjaxpr_subcomp(\n\u001b[0;32m   1788\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mmodule_context, body_jaxpr\u001b[38;5;241m.\u001b[39mjaxpr, body_name_stack,\n\u001b[0;32m   1789\u001b[0m     tokens_in, body_consts, \u001b[38;5;241m*\u001b[39m(y \u001b[38;5;241m+\u001b[39m z), dim_var_values\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mdim_var_values)\n\u001b[0;32m   1790\u001b[0m out_tokens \u001b[38;5;241m=\u001b[39m [tokens_out\u001b[38;5;241m.\u001b[39mget(eff) \u001b[38;5;28;01mfor\u001b[39;00m eff \u001b[38;5;129;01min\u001b[39;00m body_effects]\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:1905\u001b[0m, in \u001b[0;36mjaxpr_subcomp\u001b[1;34m(ctx, jaxpr, name_stack, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[0;32m   1902\u001b[0m   rule_ctx \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mreplace(axis_size_env\u001b[38;5;241m=\u001b[39maxis_size_env)\n\u001b[0;32m   1904\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_ir_values(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m in_nodes), (eqn, in_nodes)\n\u001b[1;32m-> 1905\u001b[0m ans \u001b[38;5;241m=\u001b[39m lower_per_platform(rule_ctx, \u001b[38;5;28mstr\u001b[39m(eqn\u001b[38;5;241m.\u001b[39mprimitive),\n\u001b[0;32m   1906\u001b[0m                          platform_rules, default_rule,\n\u001b[0;32m   1907\u001b[0m                          eqn\u001b[38;5;241m.\u001b[39meffects,\n\u001b[0;32m   1908\u001b[0m                          \u001b[38;5;241m*\u001b[39min_nodes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meqn\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m   1910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effects:\n\u001b[0;32m   1911\u001b[0m   \u001b[38;5;66;03m# If there were ordered effects in the primitive, there should be output\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m   \u001b[38;5;66;03m# tokens we need for subsequent ordered effects.\u001b[39;00m\n\u001b[0;32m   1913\u001b[0m   tokens_out \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mtokens_out\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:2023\u001b[0m, in \u001b[0;36mlower_per_platform\u001b[1;34m(ctx, description, platform_rules, default_rule, effects, *rule_args, **rule_kwargs)\u001b[0m\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;66;03m# If there is a single rule left just apply the rule, without conditionals.\u001b[39;00m\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kept_rules) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 2023\u001b[0m   output \u001b[38;5;241m=\u001b[39m kept_rules[\u001b[38;5;241m0\u001b[39m](ctx, \u001b[38;5;241m*\u001b[39mrule_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrule_kwargs)\n\u001b[0;32m   2024\u001b[0m   \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m   2025\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m o: wrap_compute_type_in_place(ctx, o\u001b[38;5;241m.\u001b[39mowner),\n\u001b[0;32m   2026\u001b[0m       \u001b[38;5;28mfilter\u001b[39m(_is_not_block_argument, flatten_ir_values(output)),\n\u001b[0;32m   2027\u001b[0m   )\n\u001b[0;32m   2028\u001b[0m   \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m   2029\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m o: wrap_xla_metadata_in_place(ctx, o\u001b[38;5;241m.\u001b[39mowner),\n\u001b[0;32m   2030\u001b[0m       flatten_ir_values(output),\n\u001b[0;32m   2031\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:2138\u001b[0m, in \u001b[0;36mlower_fun.<locals>.f_lowered\u001b[1;34m(ctx, *args, **params)\u001b[0m\n\u001b[0;32m   2136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2137\u001b[0m   sub_context \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mmodule_context\n\u001b[1;32m-> 2138\u001b[0m out, tokens \u001b[38;5;241m=\u001b[39m jaxpr_subcomp(\n\u001b[0;32m   2139\u001b[0m     sub_context, jaxpr, ctx\u001b[38;5;241m.\u001b[39mname_stack, ctx\u001b[38;5;241m.\u001b[39mtokens_in,\n\u001b[0;32m   2140\u001b[0m     _ir_consts(consts), \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   2141\u001b[0m     dim_var_values\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mdim_var_values)\n\u001b[0;32m   2142\u001b[0m ctx\u001b[38;5;241m.\u001b[39mset_tokens_out(tokens)\n\u001b[0;32m   2143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:1905\u001b[0m, in \u001b[0;36mjaxpr_subcomp\u001b[1;34m(ctx, jaxpr, name_stack, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[0;32m   1902\u001b[0m   rule_ctx \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mreplace(axis_size_env\u001b[38;5;241m=\u001b[39maxis_size_env)\n\u001b[0;32m   1904\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_ir_values(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m in_nodes), (eqn, in_nodes)\n\u001b[1;32m-> 1905\u001b[0m ans \u001b[38;5;241m=\u001b[39m lower_per_platform(rule_ctx, \u001b[38;5;28mstr\u001b[39m(eqn\u001b[38;5;241m.\u001b[39mprimitive),\n\u001b[0;32m   1906\u001b[0m                          platform_rules, default_rule,\n\u001b[0;32m   1907\u001b[0m                          eqn\u001b[38;5;241m.\u001b[39meffects,\n\u001b[0;32m   1908\u001b[0m                          \u001b[38;5;241m*\u001b[39min_nodes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meqn\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m   1910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effects:\n\u001b[0;32m   1911\u001b[0m   \u001b[38;5;66;03m# If there were ordered effects in the primitive, there should be output\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m   \u001b[38;5;66;03m# tokens we need for subsequent ordered effects.\u001b[39;00m\n\u001b[0;32m   1913\u001b[0m   tokens_out \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mtokens_out\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:2023\u001b[0m, in \u001b[0;36mlower_per_platform\u001b[1;34m(ctx, description, platform_rules, default_rule, effects, *rule_args, **rule_kwargs)\u001b[0m\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;66;03m# If there is a single rule left just apply the rule, without conditionals.\u001b[39;00m\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kept_rules) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 2023\u001b[0m   output \u001b[38;5;241m=\u001b[39m kept_rules[\u001b[38;5;241m0\u001b[39m](ctx, \u001b[38;5;241m*\u001b[39mrule_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrule_kwargs)\n\u001b[0;32m   2024\u001b[0m   \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m   2025\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m o: wrap_compute_type_in_place(ctx, o\u001b[38;5;241m.\u001b[39mowner),\n\u001b[0;32m   2026\u001b[0m       \u001b[38;5;28mfilter\u001b[39m(_is_not_block_argument, flatten_ir_values(output)),\n\u001b[0;32m   2027\u001b[0m   )\n\u001b[0;32m   2028\u001b[0m   \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m   2029\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m o: wrap_xla_metadata_in_place(ctx, o\u001b[38;5;241m.\u001b[39mowner),\n\u001b[0;32m   2030\u001b[0m       flatten_ir_values(output),\n\u001b[0;32m   2031\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\lax\\control_flow\\loops.py:1787\u001b[0m, in \u001b[0;36m_while_lowering\u001b[1;34m(ctx, cond_jaxpr, body_jaxpr, cond_nconsts, body_nconsts, *args)\u001b[0m\n\u001b[0;32m   1784\u001b[0m body_name_stack \u001b[38;5;241m=\u001b[39m name_stack\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1785\u001b[0m body_consts \u001b[38;5;241m=\u001b[39m [mlir\u001b[38;5;241m.\u001b[39mir_constant(xla\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(x))\n\u001b[0;32m   1786\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m body_jaxpr\u001b[38;5;241m.\u001b[39mconsts]\n\u001b[1;32m-> 1787\u001b[0m new_z, tokens_out \u001b[38;5;241m=\u001b[39m mlir\u001b[38;5;241m.\u001b[39mjaxpr_subcomp(\n\u001b[0;32m   1788\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mmodule_context, body_jaxpr\u001b[38;5;241m.\u001b[39mjaxpr, body_name_stack,\n\u001b[0;32m   1789\u001b[0m     tokens_in, body_consts, \u001b[38;5;241m*\u001b[39m(y \u001b[38;5;241m+\u001b[39m z), dim_var_values\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mdim_var_values)\n\u001b[0;32m   1790\u001b[0m out_tokens \u001b[38;5;241m=\u001b[39m [tokens_out\u001b[38;5;241m.\u001b[39mget(eff) \u001b[38;5;28;01mfor\u001b[39;00m eff \u001b[38;5;129;01min\u001b[39;00m body_effects]\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:1905\u001b[0m, in \u001b[0;36mjaxpr_subcomp\u001b[1;34m(ctx, jaxpr, name_stack, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[0;32m   1902\u001b[0m   rule_ctx \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mreplace(axis_size_env\u001b[38;5;241m=\u001b[39maxis_size_env)\n\u001b[0;32m   1904\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_ir_values(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m in_nodes), (eqn, in_nodes)\n\u001b[1;32m-> 1905\u001b[0m ans \u001b[38;5;241m=\u001b[39m lower_per_platform(rule_ctx, \u001b[38;5;28mstr\u001b[39m(eqn\u001b[38;5;241m.\u001b[39mprimitive),\n\u001b[0;32m   1906\u001b[0m                          platform_rules, default_rule,\n\u001b[0;32m   1907\u001b[0m                          eqn\u001b[38;5;241m.\u001b[39meffects,\n\u001b[0;32m   1908\u001b[0m                          \u001b[38;5;241m*\u001b[39min_nodes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meqn\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m   1910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effects:\n\u001b[0;32m   1911\u001b[0m   \u001b[38;5;66;03m# If there were ordered effects in the primitive, there should be output\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m   \u001b[38;5;66;03m# tokens we need for subsequent ordered effects.\u001b[39;00m\n\u001b[0;32m   1913\u001b[0m   tokens_out \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mtokens_out\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:2023\u001b[0m, in \u001b[0;36mlower_per_platform\u001b[1;34m(ctx, description, platform_rules, default_rule, effects, *rule_args, **rule_kwargs)\u001b[0m\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;66;03m# If there is a single rule left just apply the rule, without conditionals.\u001b[39;00m\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kept_rules) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 2023\u001b[0m   output \u001b[38;5;241m=\u001b[39m kept_rules[\u001b[38;5;241m0\u001b[39m](ctx, \u001b[38;5;241m*\u001b[39mrule_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrule_kwargs)\n\u001b[0;32m   2024\u001b[0m   \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m   2025\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m o: wrap_compute_type_in_place(ctx, o\u001b[38;5;241m.\u001b[39mowner),\n\u001b[0;32m   2026\u001b[0m       \u001b[38;5;28mfilter\u001b[39m(_is_not_block_argument, flatten_ir_values(output)),\n\u001b[0;32m   2027\u001b[0m   )\n\u001b[0;32m   2028\u001b[0m   \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m   2029\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m o: wrap_xla_metadata_in_place(ctx, o\u001b[38;5;241m.\u001b[39mowner),\n\u001b[0;32m   2030\u001b[0m       flatten_ir_values(output),\n\u001b[0;32m   2031\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:2212\u001b[0m, in \u001b[0;36mcore_call_lowering\u001b[1;34m(ctx, name, backend, call_jaxpr, *args)\u001b[0m\n\u001b[0;32m   2210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcore_call_lowering\u001b[39m(ctx: LoweringRuleContext,\n\u001b[0;32m   2211\u001b[0m                        \u001b[38;5;241m*\u001b[39margs, name, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, call_jaxpr):\n\u001b[1;32m-> 2212\u001b[0m   out_nodes, tokens \u001b[38;5;241m=\u001b[39m call_lowering(\n\u001b[0;32m   2213\u001b[0m       name, ctx\u001b[38;5;241m.\u001b[39mname_stack, call_jaxpr, backend, ctx\u001b[38;5;241m.\u001b[39mmodule_context,\n\u001b[0;32m   2214\u001b[0m       ctx\u001b[38;5;241m.\u001b[39mavals_in, ctx\u001b[38;5;241m.\u001b[39mavals_out, ctx\u001b[38;5;241m.\u001b[39mtokens_in, \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   2215\u001b[0m       dim_var_values\u001b[38;5;241m=\u001b[39mctx\u001b[38;5;241m.\u001b[39mdim_var_values)\n\u001b[0;32m   2216\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mset_tokens_out(tokens)\n\u001b[0;32m   2217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out_nodes\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:2197\u001b[0m, in \u001b[0;36mcall_lowering\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2195\u001b[0m output_types \u001b[38;5;241m=\u001b[39m [token_type()] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(effects) \u001b[38;5;241m+\u001b[39m output_types\n\u001b[0;32m   2196\u001b[0m flat_output_types \u001b[38;5;241m=\u001b[39m flatten_ir_types(output_types)\n\u001b[1;32m-> 2197\u001b[0m symbol_name \u001b[38;5;241m=\u001b[39m _lower_jaxpr_to_fun_cached(\n\u001b[0;32m   2198\u001b[0m     ctx, fn_name, call_jaxpr, effects, name_stack, arg_names\u001b[38;5;241m=\u001b[39marg_names,\n\u001b[0;32m   2199\u001b[0m     result_names\u001b[38;5;241m=\u001b[39mresult_names)\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m   2200\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [tokens_in\u001b[38;5;241m.\u001b[39mget(eff) \u001b[38;5;28;01mfor\u001b[39;00m eff \u001b[38;5;129;01min\u001b[39;00m effects]\n\u001b[0;32m   2201\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39mdim_var_values, \u001b[38;5;241m*\u001b[39mtokens, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:2156\u001b[0m, in \u001b[0;36m_lower_jaxpr_to_fun_cached\u001b[1;34m(ctx, fn_name, call_jaxpr, effects, name_stack, arg_names, result_names)\u001b[0m\n\u001b[0;32m   2154\u001b[0m     func_op \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mcached_primitive_lowerings[key]\n\u001b[0;32m   2155\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m-> 2156\u001b[0m     func_op \u001b[38;5;241m=\u001b[39m lower_jaxpr_to_fun(\n\u001b[0;32m   2157\u001b[0m         ctx, fn_name, call_jaxpr, effects, name_stack, arg_names\u001b[38;5;241m=\u001b[39marg_names,\n\u001b[0;32m   2158\u001b[0m         result_names\u001b[38;5;241m=\u001b[39mresult_names)\n\u001b[0;32m   2159\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mcached_primitive_lowerings[key] \u001b[38;5;241m=\u001b[39m func_op\n\u001b[0;32m   2160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:1646\u001b[0m, in \u001b[0;36mlower_jaxpr_to_fun\u001b[1;34m(ctx, name, jaxpr, effects, name_stack, public, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, xla_donated_args, api_name, arg_names, result_names, arg_memory_kinds, result_memory_kinds, arg_layouts, result_layouts, propagated_out_mem_kinds)\u001b[0m\n\u001b[0;32m   1644\u001b[0m   callee_name_stack \u001b[38;5;241m=\u001b[39m name_stack\n\u001b[0;32m   1645\u001b[0m consts \u001b[38;5;241m=\u001b[39m [ir_constant(xla\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39mconsts]\n\u001b[1;32m-> 1646\u001b[0m out_vals, tokens_out \u001b[38;5;241m=\u001b[39m jaxpr_subcomp(\n\u001b[0;32m   1647\u001b[0m     ctx, jaxpr\u001b[38;5;241m.\u001b[39mjaxpr, callee_name_stack, tokens_in,\n\u001b[0;32m   1648\u001b[0m     consts, \u001b[38;5;241m*\u001b[39margs, dim_var_values\u001b[38;5;241m=\u001b[39mdim_var_values)\n\u001b[0;32m   1649\u001b[0m outs: \u001b[38;5;28mlist\u001b[39m[IrValues] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1650\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eff \u001b[38;5;129;01min\u001b[39;00m effects:\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:1905\u001b[0m, in \u001b[0;36mjaxpr_subcomp\u001b[1;34m(ctx, jaxpr, name_stack, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[0;32m   1902\u001b[0m   rule_ctx \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mreplace(axis_size_env\u001b[38;5;241m=\u001b[39maxis_size_env)\n\u001b[0;32m   1904\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_ir_values(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m in_nodes), (eqn, in_nodes)\n\u001b[1;32m-> 1905\u001b[0m ans \u001b[38;5;241m=\u001b[39m lower_per_platform(rule_ctx, \u001b[38;5;28mstr\u001b[39m(eqn\u001b[38;5;241m.\u001b[39mprimitive),\n\u001b[0;32m   1906\u001b[0m                          platform_rules, default_rule,\n\u001b[0;32m   1907\u001b[0m                          eqn\u001b[38;5;241m.\u001b[39meffects,\n\u001b[0;32m   1908\u001b[0m                          \u001b[38;5;241m*\u001b[39min_nodes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meqn\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m   1910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effects:\n\u001b[0;32m   1911\u001b[0m   \u001b[38;5;66;03m# If there were ordered effects in the primitive, there should be output\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m   \u001b[38;5;66;03m# tokens we need for subsequent ordered effects.\u001b[39;00m\n\u001b[0;32m   1913\u001b[0m   tokens_out \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mtokens_out\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\mlir.py:2023\u001b[0m, in \u001b[0;36mlower_per_platform\u001b[1;34m(ctx, description, platform_rules, default_rule, effects, *rule_args, **rule_kwargs)\u001b[0m\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;66;03m# If there is a single rule left just apply the rule, without conditionals.\u001b[39;00m\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kept_rules) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 2023\u001b[0m   output \u001b[38;5;241m=\u001b[39m kept_rules[\u001b[38;5;241m0\u001b[39m](ctx, \u001b[38;5;241m*\u001b[39mrule_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrule_kwargs)\n\u001b[0;32m   2024\u001b[0m   \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m   2025\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m o: wrap_compute_type_in_place(ctx, o\u001b[38;5;241m.\u001b[39mowner),\n\u001b[0;32m   2026\u001b[0m       \u001b[38;5;28mfilter\u001b[39m(_is_not_block_argument, flatten_ir_values(output)),\n\u001b[0;32m   2027\u001b[0m   )\n\u001b[0;32m   2028\u001b[0m   \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m   2029\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m o: wrap_xla_metadata_in_place(ctx, o\u001b[38;5;241m.\u001b[39mowner),\n\u001b[0;32m   2030\u001b[0m       flatten_ir_values(output),\n\u001b[0;32m   2031\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\pjit.py:1950\u001b[0m, in \u001b[0;36m_pjit_lowering\u001b[1;34m(ctx, name, jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, keep_unused, inline, compiler_options_kvs, *args)\u001b[0m\n\u001b[0;32m   1947\u001b[0m output_types \u001b[38;5;241m=\u001b[39m [mlir\u001b[38;5;241m.\u001b[39mtoken_type()] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(effects) \u001b[38;5;241m+\u001b[39m output_types\n\u001b[0;32m   1948\u001b[0m flat_output_types \u001b[38;5;241m=\u001b[39m mlir\u001b[38;5;241m.\u001b[39mflatten_ir_types(output_types)\n\u001b[1;32m-> 1950\u001b[0m func \u001b[38;5;241m=\u001b[39m _pjit_cached_lower_jaxpr_to_fun(\n\u001b[0;32m   1951\u001b[0m     ctx, name, jaxpr, \u001b[38;5;28mtuple\u001b[39m(effects), in_shardings,\n\u001b[0;32m   1952\u001b[0m     out_shardings, in_layouts, out_layouts,\n\u001b[0;32m   1953\u001b[0m     api_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resource_env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpjit\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1955\u001b[0m tokens_in \u001b[38;5;241m=\u001b[39m [ctx\u001b[38;5;241m.\u001b[39mtokens_in\u001b[38;5;241m.\u001b[39mget(eff) \u001b[38;5;28;01mfor\u001b[39;00m eff \u001b[38;5;129;01min\u001b[39;00m effects]\n\u001b[0;32m   1956\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39mctx\u001b[38;5;241m.\u001b[39mdim_var_values, \u001b[38;5;241m*\u001b[39mtokens_in, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\pjit.py:1922\u001b[0m, in \u001b[0;36m_pjit_cached_lower_jaxpr_to_fun\u001b[1;34m(ctx, name, jaxpr, effects, in_shardings, out_shardings, in_layouts, out_layouts, api_name)\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(axis_ctx, sharding_impls\u001b[38;5;241m.\u001b[39mSPMDAxisContext):\n\u001b[0;32m   1920\u001b[0m   num_devices \u001b[38;5;241m=\u001b[39m axis_ctx\u001b[38;5;241m.\u001b[39mmesh\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m   1921\u001b[0m key \u001b[38;5;241m=\u001b[39m (pjit_p, name, jaxpr, effects, num_devices,\n\u001b[1;32m-> 1922\u001b[0m        pxla\u001b[38;5;241m.\u001b[39mSemanticallyEqualShardings(in_shardings, jaxpr\u001b[38;5;241m.\u001b[39min_avals),\n\u001b[0;32m   1923\u001b[0m        pxla\u001b[38;5;241m.\u001b[39mSemanticallyEqualShardings(out_shardings, jaxpr\u001b[38;5;241m.\u001b[39mout_avals),\n\u001b[0;32m   1924\u001b[0m        in_layouts, out_layouts, api_name)\n\u001b[0;32m   1926\u001b[0m func \u001b[38;5;241m=\u001b[39m mod_ctx\u001b[38;5;241m.\u001b[39mcached_primitive_lowerings\u001b[38;5;241m.\u001b[39mget(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\interpreters\\pxla.py:1838\u001b[0m, in \u001b[0;36mSemanticallyEqualShardings.__init__\u001b[1;34m(self, shardings, avals)\u001b[0m\n\u001b[0;32m   1835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, shardings: \u001b[38;5;28mtuple\u001b[39m[GSPMDSharding \u001b[38;5;241m|\u001b[39m UnspecifiedValue, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[0;32m   1836\u001b[0m              avals: \u001b[38;5;28mtuple\u001b[39m[core\u001b[38;5;241m.\u001b[39mAbstractValue]):\n\u001b[0;32m   1837\u001b[0m   gspmd_shardings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 1838\u001b[0m       s \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(s, (UnspecifiedValue, AUTO)) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1839\u001b[0m             (\u001b[38;5;28misinstance\u001b[39m(s, NamedSharding) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s\u001b[38;5;241m.\u001b[39mmesh, AbstractMesh)))\n\u001b[0;32m   1840\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m to_gspmd_sharding(s, a\u001b[38;5;241m.\u001b[39mndim)  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m   1841\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m s, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(shardings, avals)]\n\u001b[0;32m   1842\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gspmd_shardings \u001b[38;5;241m=\u001b[39m gspmd_shardings\n\u001b[0;32m   1843\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshardings \u001b[38;5;241m=\u001b[39m shardings\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. Calcul de la matrice des coûts (distance euclidienne)\n",
    "def cdist_jax(X, Y):\n",
    "    # ||x - y||^2 = ||x||^2 + ||y||^2 - 2<x, y>\n",
    "    X_norm = jnp.sum(X ** 2, axis=1)[:, None]\n",
    "    Y_norm = jnp.sum(Y ** 2, axis=1)[None, :]\n",
    "    C = jnp.sqrt(jnp.maximum(X_norm + Y_norm - 2 * jnp.dot(X, Y.T), 0.0))\n",
    "    return C\n",
    "\n",
    "C = cdist_jax(X, Y)\n",
    "\n",
    "try:\n",
    "    # 2. Appel à FRLC_opt (on passe dtype=jnp.float32)\n",
    "    Q, R, T, errs = FRLC_opt(\n",
    "        C=C,\n",
    "        gamma=30,\n",
    "        r=40,\n",
    "        max_iter=100,\n",
    "        tau_in=100000\n",
    "    )\n",
    "\n",
    "    # 3. Calcul de la matrice de couplage P complète\n",
    "    inv_sum_Q = 1.0 / jnp.sum(Q, axis=0)  # shape (r,)\n",
    "    inv_sum_R = 1.0 / jnp.sum(R, axis=0)  # shape (r,)\n",
    "    P = (Q\n",
    "         @ jnp.diag(inv_sum_Q)\n",
    "         @ T\n",
    "         @ jnp.diag(inv_sum_R)\n",
    "         @ R.T)  # shape (n_X, n_Y)\n",
    "\n",
    "    # 4. Extraction des paires (i,j) où P[i,j] > 0\n",
    "    ij = jnp.argwhere(P > 0)  # shape (num_pairs, 2)\n",
    "    Monge_clusters = [(int(i), int(j)) for i, j in ij]\n",
    "\n",
    "    # 5. Calcul du coût OT via la fonction JAXisée\n",
    "    cost_frlc = FRLC_compute_OT_cost(\n",
    "        X, Y,\n",
    "        C=C,\n",
    "        Monge_clusters=Monge_clusters,\n",
    "        sq_Euclidean=True\n",
    "    )\n",
    "\n",
    "    print(f'FRLC cost: {cost_frlc}')\n",
    "\n",
    "    # 6. Approximation du couplage pour l'extraction de correspondances\n",
    "    P_approx = Q @ T @ R.T  # shape (n_X, n_Y)\n",
    "    matches_Y = jnp.argmax(P_approx, axis=1)  # shape (n_X,)\n",
    "\n",
    "    # 7. Construction de la liste F de paires indices\n",
    "    F = [\n",
    "        (jnp.array([i], dtype=jnp.int32),\n",
    "         jnp.array([int(matches_Y[i])], dtype=jnp.int32))\n",
    "        for i in range(X.shape[0])\n",
    "    ]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'FRLC failed for sample size {X.shape[0]}: {e}')\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1158f",
   "metadata": {},
   "source": [
    "# 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4f4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "--------------\n",
    "Code for gradients assuming low-rank distance matrices C, A, B\n",
    "--------------\n",
    "'''\n",
    "\n",
    "def gd__compute_grad_A_LR(C_factors, A_factors, B_factors, Q, R, Lambda, gamma, alpha=0.0, full_grad=False):\n",
    "    \n",
    "    N1, N2 = C_factors[0].shape[0], C_factors[1].shape[1]\n",
    "\n",
    "    if A_factors is not None and B_factors is not None:\n",
    "        A1, A2 = A_factors\n",
    "        B1, B2 = B_factors\n",
    "\n",
    "        # GW gradients\n",
    "        gradQ = -4 * (A1 @ (A2 @ (Q @ Lambda @ ((R.T @ B1) @ (B2 @ R)) @ Lambda.T)))\n",
    "        gradR = -4 * (B1 @ (B2 @ (R @ (Lambda.T @ ((Q.T @ A1) @ (A2 @ Q)) @ Lambda))))\n",
    "\n",
    "        one_N1 = jnp.ones((N1,), dtype=Q.dtype)\n",
    "        one_N2 = jnp.ones((N2,), dtype=R.dtype)\n",
    "\n",
    "        if full_grad:\n",
    "            gQ = Q.T @ one_N1\n",
    "            gR = R.T @ one_N2\n",
    "\n",
    "            MR = (Lambda.T @ ((Q.T @ A1) @ (A2 @ Q)) @ Lambda\n",
    "                  @ ((R.T @ B1) @ (B2 @ R)) @ jnp.diag(1.0 / gR))\n",
    "            MQ = (Lambda @ ((R.T @ B1) @ (B2 @ R)) @ Lambda.T\n",
    "                  @ ((Q.T @ A1) @ (A2 @ Q)) @ jnp.diag(1.0 / gQ))\n",
    "\n",
    "            gradQ += 4 * jnp.outer(one_N1, jnp.diag(MQ))\n",
    "            gradR += 4 * jnp.outer(one_N2, jnp.diag(MR))\n",
    "    else:\n",
    "        gradQ = jnp.zeros_like(Q)\n",
    "        gradR = jnp.zeros_like(R)\n",
    "\n",
    "    # Appel à une version jaxifiée de gd__Wasserstein_Grad_LR\n",
    "    gradQW, gradRW = gd__Wasserstein_Grad_LR(C_factors, Q, R, Lambda, full_grad=full_grad)\n",
    "\n",
    "    gradQ = (1 - alpha) * gradQW + (alpha / 2.0) * gradQ\n",
    "    gradR = (1 - alpha) * gradRW + (alpha / 2.0) * gradR\n",
    "\n",
    "    normalizer = jnp.maximum(jnp.max(jnp.abs(gradQ)), jnp.max(jnp.abs(gradR)))\n",
    "    gamma_k = gamma / normalizer\n",
    "\n",
    "    return gradQ, gradR, gamma_k\n",
    "\n",
    "def gd__compute_grad_B_LR(C_factors, A_factors, B_factors, Q, R, Lambda, gQ, gR, gamma, alpha=0.0):\n",
    "    \"\"\"\n",
    "    Low-rank gradient computation in JAX for Wasserstein / Gromov-Wasserstein.\n",
    "    \"\"\"\n",
    "    C1, C2 = C_factors  # (N1, rC), (rC, N2)\n",
    "    gradLambda = 0.0\n",
    "\n",
    "    if A_factors is not None and B_factors is not None:\n",
    "        A1, A2 = A_factors  # (N1, rA), (rA, N1)\n",
    "        B1, B2 = B_factors  # (N2, rB), (rB, N2)\n",
    "        term_A = (Q.T @ A1) @ (A2 @ Q)         # shape: (r, r)\n",
    "        term_B = (R.T @ B1) @ (B2 @ R)         # shape: (r, r)\n",
    "        gradLambda = -4.0 * term_A @ Lambda @ term_B\n",
    "\n",
    "    term_C = (Q.T @ C1) @ (C2 @ R)             # shape: (r, r)\n",
    "    gradLambda = (1 - alpha) * term_C + (alpha / 2.0) * gradLambda\n",
    "\n",
    "    gradT = jnp.diag(1.0 / gQ) @ gradLambda @ jnp.diag(1.0 / gR)\n",
    "    gamma_T = gamma / jnp.max(jnp.abs(gradT))\n",
    "    return gradT, gamma_T\n",
    "\n",
    "def gd__Wasserstein_Grad_LR(C_factors, Q, R, Lambda, full_grad=True):\n",
    "    \"\"\"\n",
    "    JAX version of Wasserstein gradient with low-rank cost approximation:\n",
    "    C ≈ C1 @ C2.T\n",
    "    \"\"\"\n",
    "    C1, C2 = C_factors\n",
    "\n",
    "    gradQ = C1 @ ((C2 @ R) @ Lambda.T)\n",
    "    if full_grad:\n",
    "        N1 = Q.shape[0]\n",
    "        one_N1 = jnp.ones((N1,), dtype=Q.dtype)\n",
    "        gQ = Q.T @ one_N1\n",
    "        w1 = jnp.diag((gradQ.T @ Q) @ jnp.diag(1.0 / gQ))\n",
    "        gradQ = gradQ - jnp.outer(one_N1, w1)\n",
    "\n",
    "    gradR = C2.T @ ((C1.T @ Q) @ Lambda)\n",
    "    if full_grad:\n",
    "        N2 = R.shape[0]\n",
    "        one_N2 = jnp.ones((N2,), dtype=R.dtype)\n",
    "        gR = R.T @ one_N2\n",
    "        w2 = jnp.diag(jnp.diag(1.0 / gR) @ (R.T @ gradR))\n",
    "        gradR = gradR - jnp.outer(one_N2, w2)\n",
    "\n",
    "    return gradQ, gradR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fe4033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:76: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:76: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\VONG\\AppData\\Local\\Temp\\ipykernel_17452\\427638459.py:15: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  \"\"\"\n",
      "C:\\Users\\VONG\\AppData\\Local\\Temp\\ipykernel_17452\\427638459.py:23: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  \"\"\"\n",
      "C:\\Users\\VONG\\AppData\\Local\\Temp\\ipykernel_17452\\427638459.py:76: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def rank_annealing__factors(n):\n",
    "    \"\"\"\n",
    "    Return list of all factors of an integer\n",
    "    \"\"\"\n",
    "    n = int(n)  # Conversion pour compatibilité avec jnp.arange\n",
    "    candidates = jnp.arange(1, jnp.floor(jnp.sqrt(n)) + 1).astype(int)\n",
    "    divisible = (n % candidates) == 0\n",
    "    factors1 = candidates[divisible]\n",
    "    factors2 = n // factors1\n",
    "    all_factors = jnp.concatenate([factors1, factors2])\n",
    "    unique_factors = jnp.unique(all_factors)\n",
    "    return unique_factors\n",
    "\n",
    "def rank_annealing__max_factor_lX(n, max_X):\n",
    "    \"\"\"\n",
    "    Find max factor of n , such that max_factor \\leq max_X\n",
    "    \"\"\"\n",
    "    factor_lst = rank_annealing__factors(n)\n",
    "    factors_leq_max = factor_lst[factor_lst <= max_X]\n",
    "    return jnp.max(factors_leq_max)\n",
    "\n",
    "def rank_annealing__min_sum_partial_products_with_factors(n, k, C):\n",
    "    \"\"\"\n",
    "    Dynamic program to compute the rank-schedule, subject to a constraint of intermediates being \\leq C\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        The dataset size to be factored into a rank-scheduler. Assumed to be non-prime.\n",
    "    k: int\n",
    "        The depth of the hierarchy.\n",
    "    C: int\n",
    "        A constraint on the maximal intermediate rank across the hierarchy.\n",
    "    \n",
    "    \"\"\"\n",
    "    INF = 1e10  # Large constant instead of float('inf') for JAX compatibility\n",
    "\n",
    "    dp = jnp.full((n+1, k+1), INF)\n",
    "    choice = jnp.full((n+1, k+1), -1)\n",
    "\n",
    "    def init_base_case(dp, choice):\n",
    "        d = jnp.arange(1, n+1)\n",
    "        mask = d <= C\n",
    "        dp = dp.at[d[mask], 1].set(d[mask])\n",
    "        choice = choice.at[d[mask], 1].set(d[mask])\n",
    "        return dp, choice\n",
    "\n",
    "    dp, choice = init_base_case(dp, choice)\n",
    "\n",
    "    for t in range(2, k+1):\n",
    "        for d in range(1, n+1):\n",
    "            if dp[d, t-1] >= INF:\n",
    "                continue\n",
    "            for r in range(1, min(C, d)+1):\n",
    "                if d % r == 0:\n",
    "                    candidate = r + r * dp[d // r, t-1]\n",
    "                    if candidate < dp[d, t]:\n",
    "                        dp = dp.at[d, t].set(candidate)\n",
    "                        choice = choice.at[d, t].set(r)\n",
    "\n",
    "    if dp[n, k] >= INF:\n",
    "        return None, []\n",
    "\n",
    "    # Backtracking\n",
    "    factors = []\n",
    "    d_cur, t_cur = n, k\n",
    "    while t_cur > 0:\n",
    "        r_cur = int(choice[d_cur, t_cur])\n",
    "        factors.append(r_cur)\n",
    "        d_cur //= r_cur\n",
    "        t_cur -= 1\n",
    "\n",
    "    return dp[n, k], factors\n",
    "\n",
    "def rank_annealing__optimal_rank_schedule(n, hierarchy_depth=6, max_Q=int(2**10), max_rank=16):\n",
    "    \"\"\"\n",
    "    A function to compute the optimal rank-scheduler of refinement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Size of the input dataset -- cannot be a prime number\n",
    "    hierarchy_depth: int\n",
    "        Maximal permissible depth of the multi-scale hierarchy\n",
    "    max_Q: int\n",
    "        Maximal rank at terminal base case (before reducing the \\leq max_Q rank coupling to a 1-1 alignment)\n",
    "    max_rank: int\n",
    "        Maximal rank at the intermediate steps of the rank-schedule\n",
    "        \n",
    "    \"\"\"\n",
    "    Q = int(rank_annealing__max_factor_lX(n, max_Q))\n",
    "    ndivQ = int(n // Q)\n",
    "\n",
    "    _, rank_schedule = rank_annealing__min_sum_partial_products_with_factors(ndivQ, hierarchy_depth, max_rank)\n",
    "    rank_schedule = sorted(rank_schedule)\n",
    "    rank_schedule.append(Q)\n",
    "    rank_schedule = [x for x in rank_schedule if x != 1]\n",
    "\n",
    "    print(f'Optimized rank-annealing schedule: {rank_schedule}')\n",
    "\n",
    "    assert functools.reduce(operator.mul, rank_schedule, 1) == n, \"Error! Rank-schedule does not factorize n!\"\n",
    "\n",
    "    return rank_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa9fe3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils__low_rank_distance_factorization(X1, X2, r, eps, key=jax.random.PRNGKey(0)):\n",
    "    n = X1.shape[0]\n",
    "    m = X2.shape[0]\n",
    "    t = int(r / eps)\n",
    "\n",
    "    key1, key2, key3, key4 = jax.random.split(key, 4)\n",
    "    i_star = jax.random.randint(key1, (), 0, n)\n",
    "    j_star = jax.random.randint(key2, (), 0, m)\n",
    "\n",
    "    x1_i = X1[i_star]\n",
    "    x2_j = X2[j_star]\n",
    "\n",
    "    # Compute p\n",
    "    cd1 = jnp.linalg.norm(X1 - x2_j[None, :], axis=1) ** 2\n",
    "    cd2 = jnp.linalg.norm(X2 - x1_i[None, :], axis=1) ** 2\n",
    "    cd3 = jnp.mean(jnp.linalg.norm(X2 - x1_i[None, :], axis=1))\n",
    "\n",
    "    p = (cd1 + jnp.linalg.norm(x1_i - x2_j) ** 2 + cd3) ** 2\n",
    "    p = p / jnp.sum(p)\n",
    "\n",
    "    indices_p = jax.random.choice(key3, n, shape=(t,), p=p)\n",
    "    X1_t = X1[indices_p]\n",
    "    P_t = jnp.sqrt(p[indices_p] * t)\n",
    "\n",
    "    S = jnp.linalg.norm(X1_t[:, None, :] - X2[None, :, :], axis=2) / P_t[:, None]  # shape: (t, m)\n",
    "\n",
    "    # Compute q\n",
    "    S_norm = jnp.linalg.norm(S)\n",
    "    q = jnp.linalg.norm(S, axis=0) ** 2 / (S_norm ** 2)\n",
    "    q = q / jnp.sum(q)\n",
    "\n",
    "    indices_q = jax.random.choice(key4, m, shape=(t,), p=q)\n",
    "    S_t = S[:, indices_q]\n",
    "    Q_t = jnp.sqrt(q[indices_q] * t)\n",
    "    W = S_t / Q_t[None, :]\n",
    "\n",
    "    # SVD\n",
    "    U, Sig, Vh = jnp.linalg.svd(W, full_matrices=False)\n",
    "    F = U[:, :r]\n",
    "\n",
    "    # Compute U_t\n",
    "    W_F = W.T @ F\n",
    "    norm_WF = jnp.linalg.norm(W_F)\n",
    "    U_t = (S.T @ F) / norm_WF\n",
    "\n",
    "    # Chen & Price 2017 step\n",
    "    key5 = jax.random.PRNGKey(42)  # For deterministic behavior\n",
    "    indices = jax.random.choice(key5, m, shape=(t,))\n",
    "    X2_t = X2[indices]\n",
    "    D_t = jnp.linalg.norm(X1[:, None, :] - X2_t[None, :, :], axis=2) / jnp.sqrt(t)\n",
    "\n",
    "    Q = U_t.T @ U_t\n",
    "    UQ, SigQ, VhQ = jnp.linalg.svd(Q)\n",
    "    UQ = UQ / SigQ\n",
    "    U_tSub = U_t[indices].T\n",
    "    B = (UQ.T @ U_tSub) / jnp.sqrt(t)\n",
    "    A = jnp.linalg.inv(B @ B.T)\n",
    "    Z = (A @ B) @ D_t.T\n",
    "    V = Z.T @ UQ\n",
    "\n",
    "    return V.astype(jnp.float64), U_t.T.astype(jnp.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b79b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils__hadamard_square_lr(A1, A2):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        A1: jax.numpy array, low-rank subcoupling of shape (n, r)\n",
    "        A2: jax.numpy array, low-rank subcoupling of shape (n, r)\n",
    "                ( such that A ≈ A1 @ A2.T )\n",
    "\n",
    "    Output\n",
    "        A1_tilde: jax.numpy array, low-rank subcoupling of shape (n, r**2)\n",
    "        A2_tilde: jax.numpy array, low-rank subcoupling of shape (n, r**2)\n",
    "               ( such that A * A ≈ A1_tilde @ A2_tilde.T )\n",
    "    \"\"\"\n",
    "    n, r = A1.shape\n",
    "    A1_tilde = jnp.einsum(\"ij,ik->ijk\", A1, A1).reshape(n, r * r)\n",
    "    A2_tilde = jnp.einsum(\"ij,ik->ijk\", A2, A2).reshape(n, r * r)\n",
    "\n",
    "    return A1_tilde, A2_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6235124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FRLC_LR_opt(\n",
    "    C_factors, A_factors, B_factors, a=None, b=None,\n",
    "    tau_in=50, tau_out=50, gamma=90, r=10, r2=None,\n",
    "    max_iter=200, printCost=True, returnFull=False, alpha=0.0,\n",
    "    initialization='Full', init_args=None, full_grad=True,\n",
    "    convergence_criterion=True, tol=5e-6, min_iter=25,\n",
    "    max_inneriters_balanced=300, max_inneriters_relaxed=50,\n",
    "    diagonalize_return=False\n",
    "):\n",
    "    N1, N2 = C_factors[0].shape[0], C_factors[1].shape[1]\n",
    "    k = 0\n",
    "    stationarity_gap = jnp.inf\n",
    "\n",
    "    one_N1 = jnp.ones((N1,))\n",
    "    one_N2 = jnp.ones((N2,))\n",
    "\n",
    "    if a is None:\n",
    "        a = one_N1 / N1\n",
    "    if b is None:\n",
    "        b = one_N2 / N2\n",
    "    if r2 is None:\n",
    "        r2 = r\n",
    "\n",
    "    one_r = jnp.ones((r,))\n",
    "    one_r2 = jnp.ones((r2,))\n",
    "\n",
    "    gQ = one_r / r\n",
    "    gR = one_r2 / r2\n",
    "\n",
    "    full_rank = initialization == 'Full'\n",
    "    \n",
    "    if initialization not in ['Full', 'Rank-2']:\n",
    "        print('Initialization must be either \"Full\" or \"Rank-2\", defaulting to \"Full\".')\n",
    "        full_rank = True\n",
    "\n",
    "    if init_args is None:\n",
    "        Q, R, T, Lambda = utils__initialize_couplings(a, b, gQ, gR, gamma, full_rank=full_rank, max_iter=max_inneriters_balanced)\n",
    "    else:\n",
    "        Q, R, T = init_args\n",
    "        if Q is not None:\n",
    "            gQ = Q.T @ one_N1\n",
    "        if R is not None:\n",
    "            gR = R.T @ one_N2\n",
    "        if Q is None or R is None or T is None:\n",
    "            _Q, _R, _T, Lambda = utils__initialize_couplings(a, b, gQ, gR, gamma, full_rank=full_rank, max_iter=max_inneriters_balanced)\n",
    "            Q = Q if Q is not None else _Q\n",
    "            R = R if R is not None else _R\n",
    "            T = T if T is not None else _T\n",
    "\n",
    "        Lambda = jnp.diag(1 / (Q.T @ one_N1)) @ T @ jnp.diag(1 / (R.T @ one_N2))\n",
    "\n",
    "    errs = {'total_cost': [], 'W_cost': [], 'GW_cost': []}\n",
    "    gamma_k = gamma\n",
    "    Q_prev, R_prev, T_prev = None, None, None\n",
    "\n",
    "    while k < max_iter and (not convergence_criterion or (k < min_iter or utils__Delta((Q, R, T), (Q_prev, R_prev, T_prev), gamma_k) > tol)):\n",
    "        if convergence_criterion:\n",
    "            Q_prev, R_prev, T_prev = Q, R, T\n",
    "\n",
    "        if k % 25 == 0:\n",
    "            print(f\"Iteration: {k}\")\n",
    "\n",
    "        gradQ, gradR, gamma_k = gd__compute_grad_A_LR(C_factors, A_factors, B_factors, Q, R, Lambda, gamma, alpha=alpha, full_grad=full_grad)\n",
    "\n",
    "        R = ott_log_sinkhorn(gradR - (1 / gamma_k) * jnp.log(R), b, gR, gamma_k, max_iter=max_inneriters_relaxed, tau=tau_in)\n",
    "        Q = ott_log_sinkhorn(gradQ - (1 / gamma_k) * jnp.log(Q), a, gQ, gamma_k, max_iter=max_inneriters_relaxed, tau=tau_in)\n",
    "\n",
    "        gQ, gR = Q.T @ one_N1, R.T @ one_N2\n",
    "\n",
    "        gradT, gamma_T = gd__compute_grad_B_LR(C_factors, A_factors, B_factors, Q, R, Lambda, gQ, gR, gamma, alpha=alpha)\n",
    "        T = ott_log_sinkhorn(gradT - (1 / gamma_T) * jnp.log(T), gQ, gR, gamma_T, max_iter=max_inneriters_balanced)\n",
    "\n",
    "        Lambda = jnp.diag(1 / gQ) @ T @ jnp.diag(1 / gR)\n",
    "\n",
    "        if printCost:\n",
    "            primal_cost = jnp.trace(((Q.T @ C_factors[0]) @ (C_factors[1] @ R)) @ Lambda.T)\n",
    "            errs['W_cost'].append(primal_cost)\n",
    "            if A_factors is not None and B_factors is not None:\n",
    "                X = R @ ((Lambda.T @ ((Q.T @ A_factors[0]) @ (A_factors[1] @ Q)) @ Lambda) @ (R.T @ B_factors[0])) @ B_factors[1]\n",
    "                GW_cost = -2 * jnp.trace(X)\n",
    "                A1_tild, A2_tild = utils__hadamard_square_lr(A_factors[0], A_factors[1].T)\n",
    "                GW_cost += jnp.dot(A1_tild.T @ (Q @ one_r), A2_tild.T @ (Q @ one_r))\n",
    "                B1_tild, B2_tild = utils__hadamard_square_lr(B_factors[0], B_factors[1].T)\n",
    "                GW_cost += jnp.dot(B1_tild.T @ (R @ one_r2), B2_tild.T @ (R @ one_r2))\n",
    "                errs['GW_cost'].append(GW_cost)\n",
    "                errs['total_cost'].append((1 - alpha) * primal_cost + alpha * GW_cost)\n",
    "            else:\n",
    "                errs['GW_cost'].append(0)\n",
    "                errs['total_cost'].append(primal_cost)\n",
    "        k += 1\n",
    "\n",
    "    if printCost:\n",
    "        print(f\"Initial Wasserstein cost: {errs['W_cost'][0]}, GW-cost: {errs['GW_cost'][0]}, Total cost: {errs['total_cost'][0]}\")\n",
    "        print(f\"Final Wasserstein cost: {errs['W_cost'][-1]}, GW-cost: {errs['GW_cost'][-1]}, Total cost: {errs['total_cost'][-1]}\")\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.plot(errs['total_cost'])\n",
    "        plt.show()\n",
    "\n",
    "    if returnFull:\n",
    "        P = Q @ Lambda @ R.T\n",
    "        return P, errs\n",
    "    else:\n",
    "        if diagonalize_return:\n",
    "            Q = Q @ (jnp.diag(1 / gQ) @ T)\n",
    "            gR = R.T @ one_N2\n",
    "            T = jnp.diag(gR)\n",
    "        return Q, R, T, errs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f4e86dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FRLC_opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mHierarchicalRefinementOT\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Classe pour effectuer le raffinage hiérarchique OT en JAX.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m      6\u001b[0m                  C: jnp\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m      7\u001b[0m                  rank_schedule: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m                  num_processes: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;66;03m# Matrice de coût et paramètres initiaux\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m, in \u001b[0;36mHierarchicalRefinementOT\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mHierarchicalRefinementOT\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Classe pour effectuer le raffinage hiérarchique OT en JAX.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m      6\u001b[0m                  C: jnp\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m      7\u001b[0m                  rank_schedule: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m----> 8\u001b[0m                  solver: Callable \u001b[38;5;241m=\u001b[39m FRLC_opt,\n\u001b[0;32m      9\u001b[0m                  solver_params: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m                  device: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m                  base_rank: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     12\u001b[0m                  clustering_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m                  plot_clusterings: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m                  parallel: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m                  num_processes: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;66;03m# Matrice de coût et paramètres initiaux\u001b[39;00m\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(C)                     \u001b[38;5;66;03m# Coût en tant que jnp.array\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank_schedule \u001b[38;5;241m=\u001b[39m rank_schedule\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FRLC_opt' is not defined"
     ]
    }
   ],
   "source": [
    "class HierarchicalRefinementOT:\n",
    "    \"\"\"\n",
    "    Classe pour effectuer le raffinage hiérarchique OT en JAX.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 C: jnp.ndarray,\n",
    "                 rank_schedule: List[int],\n",
    "                 solver: Callable = FRLC_opt,\n",
    "                 solver_params: Union[Dict[str, Any], None] = None,\n",
    "                 device: str = 'cpu',\n",
    "                 base_rank: int = 1,\n",
    "                 clustering_type: str = 'soft',\n",
    "                 plot_clusterings: bool = False,\n",
    "                 parallel: bool = False,\n",
    "                 num_processes: Union[int, None] = None):\n",
    "        # Matrice de coût et paramètres initiaux\n",
    "        self.C = jnp.array(C)                     # Coût en tant que jnp.array\n",
    "        self.rank_schedule = rank_schedule\n",
    "        self.solver = solver\n",
    "        self.device = device\n",
    "        self.base_rank = base_rank\n",
    "        self.clustering_type = clustering_type\n",
    "        self.plot_clusterings = plot_clusterings\n",
    "        self.parallel = parallel\n",
    "        self.num_processes = num_processes\n",
    "\n",
    "        self.X, self.Y = None, None\n",
    "        self.N = self.C.shape[0]\n",
    "        self.Monge_clusters = None\n",
    "\n",
    "        # Paramètres par défaut du solveur FRLC\n",
    "        default_solver_params = {\n",
    "            'gamma': 30,\n",
    "            'max_iter': 60,\n",
    "            'min_iter': 25,\n",
    "            'max_inneriters_balanced': 100,\n",
    "            'max_inneriters_relaxed': 40,\n",
    "            'printCost': False,\n",
    "            'tau_in': 100000\n",
    "        }\n",
    "        if solver_params is not None:\n",
    "            default_solver_params.update(solver_params)\n",
    "        self.solver_params = default_solver_params\n",
    "\n",
    "        assert self.C.shape[0] == self.C.shape[1], \\\n",
    "            \"La matrice de coût doit être carrée (|X| = |Y| = N)\"\n",
    "\n",
    "    @classmethod\n",
    "    def init_from_point_clouds(cls,\n",
    "                               X: jnp.ndarray,\n",
    "                               Y: jnp.ndarray,\n",
    "                               rank_schedule: List[int],\n",
    "                               distance_rank_schedule: Union[List[int], None] = None,\n",
    "                               solver: Callable = FRLC_LR_opt,\n",
    "                               solver_params: Union[Dict[str, Any], None] = None,\n",
    "                               device: str = 'cpu',\n",
    "                               base_rank: int = 1,\n",
    "                               clustering_type: str = 'soft',\n",
    "                               plot_clusterings: bool = False,\n",
    "                               parallel: bool = False,\n",
    "                               num_processes: Union[int, None] = None,\n",
    "                               sq_Euclidean: bool = False):\n",
    "        \"\"\"\n",
    "        Constructeur à partir de nuages de points X, Y.\n",
    "        \"\"\"\n",
    "        obj = cls.__new__(cls)\n",
    "        obj.X = jnp.array(X)\n",
    "        obj.Y = jnp.array(Y)\n",
    "        obj.rank_schedule = rank_schedule\n",
    "        obj.distance_rank_schedule = rank_schedule if distance_rank_schedule is None else distance_rank_schedule\n",
    "        obj.solver = solver\n",
    "        obj.device = device\n",
    "        obj.base_rank = base_rank\n",
    "        obj.clustering_type = clustering_type\n",
    "        obj.plot_clusterings = plot_clusterings\n",
    "        obj.parallel = parallel\n",
    "        obj.num_processes = num_processes\n",
    "        obj.N = X.shape[0]\n",
    "        obj.C = None\n",
    "        obj.Monge_clusters = None\n",
    "        obj.sq_Euclidean = sq_Euclidean\n",
    "\n",
    "        default_solver_params = {\n",
    "            'gamma': 30,\n",
    "            'max_iter': 60,\n",
    "            'min_iter': 25,\n",
    "            'max_inneriters_balanced': 100,\n",
    "            'max_inneriters_relaxed': 40,\n",
    "            'printCost': False,\n",
    "            'tau_in': 100000\n",
    "        }\n",
    "        if solver_params is not None:\n",
    "            default_solver_params.update(solver_params)\n",
    "        obj.solver_params = default_solver_params\n",
    "\n",
    "        assert X.shape[0] == Y.shape[0], \"Assume |X| = |Y| = N\"\n",
    "        return obj\n",
    "\n",
    "    def run(self, return_as_coupling: bool = False):\n",
    "        \"\"\"\n",
    "        Lance le raffinage hiérarchique (série ou parallèle).\n",
    "        \"\"\"\n",
    "        if self.parallel:\n",
    "            return self._hierarchical_refinement_parallelized(return_as_coupling=return_as_coupling)\n",
    "        else:\n",
    "            return self._hierarchical_refinement(return_as_coupling=return_as_coupling)\n",
    "\n",
    "    def _hierarchical_refinement(self, return_as_coupling: bool = False):\n",
    "        \"\"\"\n",
    "        Raffinement hiérarchique mono-processus.\n",
    "        \"\"\"\n",
    "        # Partition initiale (tous les points dans un seul cluster)\n",
    "        F_t = [(jnp.arange(self.N), jnp.arange(self.N))]\n",
    "        for i, rank_level in enumerate(self.rank_schedule):\n",
    "            F_tp1 = []\n",
    "            is_last = (i == len(self.rank_schedule) - 1)\n",
    "            if is_last:\n",
    "                fin_iters = int(self.N) // int(jnp.prod(jnp.array(self.rank_schedule[:i+1])))\n",
    "                print(f'Last level, chunk-size {rank_level}, {fin_iters} itérations.')\n",
    "\n",
    "            j = 0\n",
    "            for (idxX, idxY) in F_t:\n",
    "                if is_last:\n",
    "                    print(f'{j}/{fin_iters} itérations finalistes')\n",
    "                    j += 1\n",
    "\n",
    "                # Si cluster arrivé à la taille base_rank, on le conserve tel quel\n",
    "                if len(idxX) <= self.base_rank or len(idxY) <= self.base_rank:\n",
    "                    F_tp1.append((idxX, idxY))\n",
    "                    continue\n",
    "\n",
    "                # Résoudre sous-problème d'OT (coût explicite ou low-rank sur distance)\n",
    "                if self.C is not None:\n",
    "                    Q, R = self._solve_prob(idxX, idxY, rank_level)\n",
    "                else:\n",
    "                    rank_D = self.distance_rank_schedule[i]\n",
    "                    Q, R = self._solve_LR_prob(idxX, idxY, rank_level, rank_D)\n",
    "\n",
    "                # Calcul de la nouvelle taille de cluster (capacités)\n",
    "                capacity = int(self.N) // int(jnp.prod(jnp.array(self.rank_schedule[:i+1])))\n",
    "                idx_seenX = jnp.arange(Q.shape[0])\n",
    "                idx_seenY = jnp.arange(R.shape[0])\n",
    "\n",
    "                # Clustering \"soft\" ou \"hard\"\n",
    "                if self.clustering_type == 'soft':\n",
    "                    for z in range(rank_level):\n",
    "                        # top-k sur les colonnes de Q et R\n",
    "                        _, topk_X = jax.lax.top_k(Q[idx_seenX, z], capacity)\n",
    "                        idxX_z = idxX[idx_seenX[topk_X]]\n",
    "                        _, topk_Y = jax.lax.top_k(R[idx_seenY, z], capacity)\n",
    "                        idxY_z = idxY[idx_seenY[topk_Y]]\n",
    "                        F_tp1.append((idxX_z, idxY_z))\n",
    "                        # Retirer ces indices pour la suite\n",
    "                        idx_seenX = idx_seenX[~jnp.isin(idx_seenX, idx_seenX[topk_X])]\n",
    "                        idx_seenY = idx_seenY[~jnp.isin(idx_seenY, idx_seenY[topk_Y])]\n",
    "\n",
    "                elif self.clustering_type == 'hard':\n",
    "                    # Assignations par argmax\n",
    "                    zX = jnp.argmax(Q, axis=1)\n",
    "                    zY = jnp.argmax(R, axis=1)\n",
    "                    for z in range(rank_level):\n",
    "                        idxX_z = idxX[zX == z]\n",
    "                        idxY_z = idxY[zY == z]\n",
    "                        # On s’assure que c’est effectivement un hard-clustering\n",
    "                        assert len(idxX_z) == len(idxY_z) == capacity, \\\n",
    "                            \"Cluster déséquilibre ou pas du hard-clustering!\"\n",
    "                        F_tp1.append((idxX_z, idxY_z))\n",
    "\n",
    "            F_t = F_tp1\n",
    "\n",
    "        self.Monge_clusters = F_t\n",
    "        if return_as_coupling:\n",
    "            return self._compute_coupling_from_Ft()\n",
    "        else:\n",
    "            return self.Monge_clusters\n",
    "\n",
    "    def _hierarchical_refinement_parallelized(self, return_as_coupling: bool = False):\n",
    "        # Non implémenté dans cette classe\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _solve_LR_prob(self, idxX, idxY, rank_level, rankD, eps=0.04):\n",
    "        \"\"\"\n",
    "        Solve sub-problème OT en utilisant la factorisation low-rank de la distance.\n",
    "        \"\"\"\n",
    "        _x0 = self.X[idxX]    # Extrait les points X\n",
    "        _x1 = self.Y[idxY]    # Extrait les points Y\n",
    "        if rankD < _x0.shape[0]:\n",
    "            # Calcul des facteurs de la matrice de distance\n",
    "            C_factors, A_factors, B_factors = self.get_dist_mats(_x0, _x1, rankD, eps, self.sq_Euclidean)\n",
    "            Q, R, _, _ = self.solver(\n",
    "                C_factors, A_factors, B_factors,\n",
    "                gamma=self.solver_params['gamma'],\n",
    "                r=rank_level,\n",
    "                max_iter=self.solver_params['max_iter'],\n",
    "                min_iter=self.solver_params['min_iter'],\n",
    "                max_inneriters_balanced=self.solver_params['max_inneriters_balanced'],\n",
    "                max_inneriters_relaxed=self.solver_params['max_inneriters_relaxed'],\n",
    "                diagonalize_return=True,\n",
    "                printCost=False,\n",
    "                tau_in=self.solver_params['tau_in']\n",
    "            )\n",
    "        else:\n",
    "            # Cas final (sous-cluster) : calcul direct des distances\n",
    "            if self.sq_Euclidean:\n",
    "                # Distance euclidienne au carré\n",
    "                C_XY = jnp.linalg.norm(_x0[:, None, :] - _x1[None, :, :], axis=2)**2\n",
    "            else:\n",
    "                # Distance euclidienne normale\n",
    "                C_XY = jnp.linalg.norm(_x0[:, None, :] - _x1[None, :, :], axis=2)\n",
    "            Q, R, _, _ = FRLC_opt(\n",
    "                C_XY,\n",
    "                gamma=self.solver_params['gamma'],\n",
    "                r=rank_level,\n",
    "                max_iter=self.solver_params['max_iter'],\n",
    "                min_iter=self.solver_params['min_iter'],\n",
    "                max_inneriters_balanced=self.solver_params['max_inneriters_balanced'],\n",
    "                max_inneriters_relaxed=self.solver_params['max_inneriters_relaxed'],\n",
    "                diagonalize_return=True,\n",
    "                printCost=False,\n",
    "                tau_in=self.solver_params['tau_in']\n",
    "            )\n",
    "        return Q, R\n",
    "\n",
    "    def _solve_prob(self, idxX, idxY, rank_level):\n",
    "        \"\"\"\n",
    "        Solve sous-problème OT en indexant la sous-matrice de coût explicite.\n",
    "        \"\"\"\n",
    "        C_sub = self.C[idxX][:, idxY]\n",
    "        Q, R, _, _ = self.solver(\n",
    "            C_sub,\n",
    "            gamma=self.solver_params['gamma'],\n",
    "            r=rank_level,\n",
    "            max_iter=self.solver_params['max_iter'],\n",
    "            device=self.device,\n",
    "            min_iter=self.solver_params['min_iter'],\n",
    "            max_inneriters_balanced=self.solver_params['max_inneriters_balanced'],\n",
    "            max_inneriters_relaxed=self.solver_params['max_inneriters_relaxed'],\n",
    "            diagonalize_return=True,\n",
    "            printCost=False,\n",
    "            tau_in=self.solver_params['tau_in'],\n",
    "            dtype=C_sub.dtype\n",
    "        )\n",
    "        return Q, R\n",
    "\n",
    "    def _compute_coupling_from_Ft(self):\n",
    "        \"\"\"\n",
    "        Construit la matrice de couplage dense à partir des clusters Monge map.\n",
    "        \"\"\"\n",
    "        size = (self.N, self.N)\n",
    "        P = jnp.zeros(size)\n",
    "        for idx1, idx2 in self.Monge_clusters:\n",
    "            for i in range(idx1.shape[0]):\n",
    "                P = P.at[idx1[i], idx2[i]].set(1)\n",
    "        # On normalise par N (masse uniformément répartie)\n",
    "        return P / self.N\n",
    "\n",
    "    def compute_OT_cost(self):\n",
    "        \"\"\"\n",
    "        Calcule le coût OT associé aux clusters Monge (sans construire explicitement le couplage).\n",
    "        \"\"\"\n",
    "        cost = 0.0\n",
    "        for idx1, idx2 in self.Monge_clusters:\n",
    "            if self.C is not None:\n",
    "                cost += jnp.sum(self.C[idx1, idx2])\n",
    "            else:\n",
    "                if self.sq_Euclidean:\n",
    "                    cost += jnp.sum((self.X[idx1] - self.Y[idx2])**2)\n",
    "                else:\n",
    "                    cost += jnp.linalg.norm(self.X[idx1] - self.Y[idx2])\n",
    "        return cost / self.N\n",
    "\n",
    "    def get_dist_mats(self, _x0, _x1, rankD, eps, sq_Euclidean):\n",
    "        \"\"\"\n",
    "        Retourne les facteurs de la matrice de distance low-rank.\n",
    "        \"\"\"\n",
    "        if sq_Euclidean:\n",
    "            # Facteurs pour une distance euclidienne au carré\n",
    "            C_factors = compute_lr_sqeuclidean_matrix(_x0, _x1, True)\n",
    "            A_factors = None\n",
    "            B_factors = None\n",
    "        else:\n",
    "            # Low-rank factorisation pour distance standard\n",
    "            C_factors = self.ret_normalized_cost(_x0, _x1, rankD, eps)\n",
    "            A_factors = None\n",
    "            B_factors = None\n",
    "        return C_factors, A_factors, B_factors\n",
    "\n",
    "    def ret_normalized_cost(self, X, Y, rankD, eps):\n",
    "        \"\"\"\n",
    "        Facteur de coût normalisé via factorisation low-rank de distance.\n",
    "        \"\"\"\n",
    "        C1, C2 = utils__low_rank_distance_factorization(\n",
    "            X, Y, r=rankD, eps=eps\n",
    "        )\n",
    "        c = (jnp.max(C1)**0.5) * (jnp.max(C2)**0.5)\n",
    "        C1 = (C1 / c).astype(X.dtype)\n",
    "        C2 = (C2 / c).astype(X.dtype)\n",
    "        return C1, C2\n",
    "\n",
    "def compute_lr_sqeuclidean_matrix(X_s, X_t, rescale_cost, device=None, dtype=None):\n",
    "    \"\"\"\n",
    "    Calcul de la factorisation low-rank de la distance euclidienne au carré.\n",
    "    \"\"\"\n",
    "    dtype = X_s.dtype\n",
    "    ns, _ = X_s.shape\n",
    "    nt, _ = X_t.shape\n",
    "\n",
    "    sum_Xs_sq = jnp.sum(X_s ** 2, axis=1).reshape(ns, 1)\n",
    "    ones_ns = jnp.ones((ns, 1), dtype=dtype)\n",
    "    neg_two_Xs = -2 * X_s\n",
    "    M1 = jnp.concatenate([sum_Xs_sq, ones_ns, neg_two_Xs], axis=1)\n",
    "\n",
    "    ones_nt = jnp.ones((nt, 1), dtype=dtype)\n",
    "    sum_Xt_sq = jnp.sum(X_t ** 2, axis=1).reshape(nt, 1)\n",
    "    M2 = jnp.concatenate([ones_nt, sum_Xt_sq, X_t], axis=1)\n",
    "\n",
    "    if rescale_cost:\n",
    "        max_M1 = jnp.max(M1)\n",
    "        max_M2 = jnp.max(M2)\n",
    "        if max_M1 > 0:\n",
    "            M1 = M1 / jnp.sqrt(max_M1)\n",
    "        if max_M2 > 0:\n",
    "            M2 = M2 / jnp.sqrt(max_M2)\n",
    "\n",
    "    return (M1, M2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc0dfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized rank-annealing schedule: [2, 1250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:118: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(self, dtype, copy=copy, device=device)\n",
      "c:\\Users\\VONG\\anaconda3\\envs\\lsf\\Lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:118: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(self, dtype, copy=copy, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Last level, chunk-size 1250, 1 itérations.\n",
      "0/1 itérations finalistes\n",
      "HROT-LR failed for sample size: FRLC_opt() got an unexpected keyword argument 'device'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "FRLC_opt() got an unexpected keyword argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHROT-LR failed for sample size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     hrot_lr \u001b[38;5;241m=\u001b[39m HierarchicalRefinementOT\u001b[38;5;241m.\u001b[39minit_from_point_clouds(X, Y, rank_schedule, base_rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     F \u001b[38;5;241m=\u001b[39m hrot_lr\u001b[38;5;241m.\u001b[39mrun(return_as_coupling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m     cost_hrot_lr \u001b[38;5;241m=\u001b[39m hrot_lr\u001b[38;5;241m.\u001b[39mcompute_OT_cost()\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHR-OT cost: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcost_hrot_lr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 106\u001b[0m, in \u001b[0;36mHierarchicalRefinementOT.run\u001b[1;34m(self, return_as_coupling)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hierarchical_refinement_parallelized(return_as_coupling\u001b[38;5;241m=\u001b[39mreturn_as_coupling)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hierarchical_refinement(return_as_coupling\u001b[38;5;241m=\u001b[39mreturn_as_coupling)\n",
      "Cell \u001b[1;32mIn[14], line 137\u001b[0m, in \u001b[0;36mHierarchicalRefinementOT._hierarchical_refinement\u001b[1;34m(self, return_as_coupling)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     rank_D \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance_rank_schedule[i]\n\u001b[1;32m--> 137\u001b[0m     Q, R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solve_LR_prob(idxX, idxY, rank_level, rank_D)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# Calcul de la nouvelle taille de cluster (capacités)\u001b[39;00m\n\u001b[0;32m    140\u001b[0m capacity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mint\u001b[39m(jnp\u001b[38;5;241m.\u001b[39mprod(jnp\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank_schedule[:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])))\n",
      "Cell \u001b[1;32mIn[14], line 210\u001b[0m, in \u001b[0;36mHierarchicalRefinementOT._solve_LR_prob\u001b[1;34m(self, idxX, idxY, rank_level, rankD, eps)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;66;03m# Distance euclidienne normale\u001b[39;00m\n\u001b[0;32m    209\u001b[0m         C_XY \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(_x0[:, \u001b[38;5;28;01mNone\u001b[39;00m, :] \u001b[38;5;241m-\u001b[39m _x1[\u001b[38;5;28;01mNone\u001b[39;00m, :, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 210\u001b[0m     Q, R, _, _ \u001b[38;5;241m=\u001b[39m FRLC_opt(\n\u001b[0;32m    211\u001b[0m         C_XY,\n\u001b[0;32m    212\u001b[0m         gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    213\u001b[0m         r\u001b[38;5;241m=\u001b[39mrank_level,\n\u001b[0;32m    214\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    215\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[0;32m    216\u001b[0m         min_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_iter\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    217\u001b[0m         max_inneriters_balanced\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_inneriters_balanced\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    218\u001b[0m         max_inneriters_relaxed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_inneriters_relaxed\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    219\u001b[0m         diagonalize_return\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    220\u001b[0m         printCost\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m         tau_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtau_in\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    222\u001b[0m     )\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Q, R\n",
      "\u001b[1;31mTypeError\u001b[0m: FRLC_opt() got an unexpected keyword argument 'device'"
     ]
    }
   ],
   "source": [
    "rank_schedule = rank_annealing__optimal_rank_schedule( X.shape[0] , hierarchy_depth = 6, max_Q = int(2**11), max_rank = 64 )\n",
    "\n",
    "try:\n",
    "    hrot_lr = HierarchicalRefinementOT.init_from_point_clouds(X, Y, rank_schedule, base_rank=1)\n",
    "    F = hrot_lr.run(return_as_coupling=False)\n",
    "    cost_hrot_lr = hrot_lr.compute_OT_cost()\n",
    "    print(f'HR-OT cost: {cost_hrot_lr}')\n",
    "except Exception as e:\n",
    "    print(f'HROT-LR failed for sample size: {e}')\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
