{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945f7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable, Union, Dict, Any\n",
    "import random\n",
    "import operator\n",
    "import functools\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "#import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from ott.geometry import costs, pointcloud\n",
    "from ott.tools import sinkhorn_divergence, progot\n",
    "from ott.problems.linear import linear_problem\n",
    "from ott.solvers.linear import sinkhorn\n",
    "#import torchvision.transforms as transforms\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "#import torch\n",
    "#import torchvision.models as models\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from ott.geometry import geometry\n",
    "from ott.problems.linear import linear_problem\n",
    "from ott.solvers.linear import sinkhorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cae2dc",
   "metadata": {},
   "source": [
    "# 1. Load images & model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8173d8ca",
   "metadata": {},
   "source": [
    "You can also directly go to part 3 if you want to start directly from the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d50b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        # Liste tous les fichiers .jpg\n",
    "        self.image_paths = [os.path.join(root_dir, fname)\n",
    "                            for fname in os.listdir(root_dir)\n",
    "                            if fname.endswith('.jpg')]\n",
    "        # Si le nombre d'images est impair, enlever la dernière\n",
    "        if len(self.image_paths) % 2 != 0:\n",
    "            self.image_paths = self.image_paths[:-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')  # Toujours convertir en RGB\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image  # Pas d'étiquette ici, juste l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1d362e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000 images from ImageNet!\n"
     ]
    }
   ],
   "source": [
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images for CNN input\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load COCO dataset from extracted path\n",
    "imagenet_dataset = CustomImageDataset(root_dir='images', transform=transform)\n",
    "\n",
    "\n",
    "# Create DataLoader for batching\n",
    "imagenet_loader = DataLoader(imagenet_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Loaded {len(imagenet_dataset)} images from ImageNet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "280953f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VONG\\AppData\\Local\\Temp\\ipykernel_11692\\1851330435.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.expanduser(\"resnet50-0676ba61.pth\")\n",
    "\n",
    "# Load pretrained ResNet model\n",
    "model = models.resnet50()\n",
    "model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "model.fc = torch.nn.Identity()  # Remove classification layer to extract features\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f1229",
   "metadata": {},
   "source": [
    "# 2. Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6001bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting embeddings!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 157/157 [00:57<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_features(dataloader, model):\n",
    "    \"\"\"\n",
    "    Compute embeddings\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for idx, images in tqdm(enumerate(dataloader), desc=\"Extracting features\", total=len(dataloader)):\n",
    "            images = images.to(device)\n",
    "            features = model(images)\n",
    "            embeddings.append(jnp.array(features.detach().cpu().numpy()))  \n",
    "    return jnp.vstack(embeddings)  # Stack all embeddings\n",
    "\n",
    "print('extracting embeddings!')\n",
    "embeddings = extract_features(imagenet_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0dbe4e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved successfully to embeddings/embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "with open('embeddings/embeddings.pkl', \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "print(\"Embeddings saved successfully to embeddings/embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb07d8",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde20a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded successfully! Shape: (5000, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings from the pickle file\n",
    "with open('embeddings/embeddings.pkl', \"rb\") as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "print(f\"Embeddings loaded successfully! Shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "155a4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2500, 2048), Y shape: (2500, 2048)\n"
     ]
    }
   ],
   "source": [
    "num_samples = embeddings.shape[0]\n",
    "\n",
    "# Shuffle indices\n",
    "key = jax.random.PRNGKey(42)\n",
    "indices = jax.random.permutation(key, num_samples)\n",
    "\n",
    "# Split into two tensors\n",
    "X = embeddings[indices[:num_samples // 2]]\n",
    "Y = embeddings[indices[num_samples // 2:]]\n",
    "\n",
    "print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa4c1e",
   "metadata": {},
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e92a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ott_log_sinkhorn(grad,\n",
    "                     a,\n",
    "                     b,\n",
    "                     gamma_k,\n",
    "                     max_iter = 50,\n",
    "                     balanced = True,\n",
    "                     unbalanced = False,\n",
    "                     tau = None,\n",
    "                     tau2 = None):\n",
    "    \"\"\"\n",
    "    grad: cost matrix (n, m)\n",
    "    a: source histogram (n,)\n",
    "    b: target histogram (m,)\n",
    "    gamma_k: régularisation inverse (1/epsilon)\n",
    "    \"\"\"\n",
    "    epsilon = 1.0 / gamma_k\n",
    "\n",
    "    # Choix des tau pour marges\n",
    "    if balanced and not unbalanced:\n",
    "        tau_a, tau_b = 1.0, 1.0\n",
    "    elif not balanced and unbalanced:\n",
    "        tau_a = tau / (tau + epsilon)\n",
    "        tau_b = tau2 / (tau2 + epsilon) if tau2 is not None else tau_a\n",
    "    else:  # semi-relaxed\n",
    "        tau_a, tau_b = 1.0, tau / (tau + epsilon)\n",
    "\n",
    "    # Géométrie entropique sur la matrice de coût\n",
    "    geom = geometry.Geometry(cost_matrix=grad, epsilon=epsilon)\n",
    "\n",
    "    # Construction du problème linéaire\n",
    "    prob = linear_problem.LinearProblem(\n",
    "        geom,\n",
    "        a=a,\n",
    "        b=b,\n",
    "        tau_a=tau_a,\n",
    "        tau_b=tau_b\n",
    "    )\n",
    "\n",
    "    # Solveur Sinkhorn\n",
    "    solver = sinkhorn.Sinkhorn(max_iterations=max_iter)\n",
    "    out = solver(prob)\n",
    "\n",
    "    return out.matrix\n",
    "\n",
    "def utils__Delta(vark, varkm1, gamma_k):\n",
    "    return (gamma_k**-2) * (jnp.linalg.norm(vark[0] - varkm1[0]) + jnp.linalg.norm(vark[1] - varkm1[1]) + jnp.linalg.norm(vark[2] - varkm1[2]))\n",
    "\n",
    "def utils__random_simplex_sample(key, N, dtype = jnp.float64):\n",
    "    \"\"\"\n",
    "    Draws a random point from the (N-1)-simplex using normalized exponentiated Gaussian variates.\n",
    "\n",
    "    Args:\n",
    "        key: PRNGKey for random number generation.\n",
    "        N: Dimensionality of the simplex (vector length).\n",
    "        dtype: Desired floating-point type of the output.\n",
    "\n",
    "    Returns:\n",
    "        A 1D array of shape (N,) with non-negative entries summing to 1.\n",
    "    \"\"\"\n",
    "    # Sample N independent standard normals\n",
    "    z = jax.random.normal(key, shape=(N,), dtype=dtype)\n",
    "    # Exponentiate\n",
    "    e = jnp.exp(z)\n",
    "    # Normalize to sum to 1\n",
    "    return e / jnp.sum(e)\n",
    "\n",
    "def utils__initialize_couplings(a, b, gQ, gR, gamma, full_rank = True, key = jax.random.PRNGKey(0), dtype = float, rank2_random = False, max_iter = 50):\n",
    "    \"\"\"\n",
    "    Initialize coupling factors in JAX.\n",
    "    \"\"\"\n",
    "    N1 = a.shape[0]\n",
    "    N2 = b.shape[0]\n",
    "    r = gQ.shape[0]\n",
    "    r2 = gR.shape[0]\n",
    "\n",
    "    one_N1 = jnp.ones((N1,), dtype=dtype)\n",
    "    one_N2 = jnp.ones((N2,), dtype=dtype)\n",
    "\n",
    "    if full_rank:\n",
    "        # Full-rank initialization via log-Sinkhorn\n",
    "        key, subkey = jax.random.split(key)\n",
    "        C_random = jax.random.uniform(subkey, (N1, r), dtype=dtype)\n",
    "        Q = ott_log_sinkhorn(C_random, a, gQ, gamma,\n",
    "                                max_iter=max_iter,\n",
    "                                balanced=True)\n",
    "\n",
    "        key, subkey = jax.random.split(key)\n",
    "        C_random = jax.random.uniform(subkey, (N2, r2), dtype=dtype)\n",
    "        R = ott_log_sinkhorn(C_random, b, gR, gamma,\n",
    "                                max_iter=max_iter,\n",
    "                                balanced=True)\n",
    "\n",
    "        # Compute updated inner marginals\n",
    "        gR_new = R.T @ one_N2\n",
    "        gQ_new = Q.T @ one_N1\n",
    "\n",
    "        key, subkey = jax.random.split(key)\n",
    "        C_random = jax.random.uniform(subkey, (r, r2), dtype=dtype)\n",
    "        T = ott_log_sinkhorn(C_random, gQ_new, gR_new, gamma,\n",
    "                                max_iter=max_iter,\n",
    "                                balanced=True)\n",
    "\n",
    "        # Inner inverse coupling\n",
    "        if r == r2:\n",
    "            Lambda = jnp.linalg.inv(T)\n",
    "        else:\n",
    "            Lambda = jnp.diag(1.0 / gQ_new) @ T @ jnp.diag(1.0 / gR_new)\n",
    "\n",
    "    else:\n",
    "        # Rank-2 initialization (Scetbon et al. 2021)\n",
    "        if r != r2:\n",
    "            raise ValueError(\"Rank-2 init requires equal inner ranks.\")\n",
    "        g = gQ\n",
    "        lambd = jnp.minimum(jnp.min(a), jnp.min(b))\n",
    "        lambd = jnp.minimum(lambd, jnp.min(g)) / 2.0\n",
    "\n",
    "        # Sample or deterministic\n",
    "        if rank2_random:\n",
    "            key, *splits = random.split(key, 4)\n",
    "            a1 = utils__random_simplex_sample(N1, splits[0], dtype)\n",
    "            b1 = utils__random_simplex_sample(N2, splits[1], dtype)\n",
    "            g1 = utils__random_simplex_sample(r, splits[2], dtype)\n",
    "        else:\n",
    "            g1 = jnp.arange(1, r + 1, dtype=dtype)\n",
    "            g1 = g1 / jnp.sum(g1)\n",
    "            a1 = jnp.arange(1, N1 + 1, dtype=dtype)\n",
    "            a1 = a1 / jnp.sum(a1)\n",
    "            b1 = jnp.arange(1, N2 + 1, dtype=dtype)\n",
    "            b1 = b1 / jnp.sum(b1)\n",
    "\n",
    "        a2 = (a - lambd * a1) / (1 - lambd)\n",
    "        b2 = (b - lambd * b1) / (1 - lambd)\n",
    "        g2 = (g - lambd * g1) / (1 - lambd)\n",
    "\n",
    "        Q = lambd * jnp.outer(a1, g1) + (1 - lambd) * jnp.outer(a2, g2)\n",
    "        R = lambd * jnp.outer(b1, g1) + (1 - lambd) * jnp.outer(b2, g2)\n",
    "\n",
    "        gR_new = R.T @ one_N2\n",
    "        gQ_new = Q.T @ one_N1\n",
    "\n",
    "        T = (1 - lambd) * jnp.diag(g) + lambd * jnp.outer(gR_new, gQ_new)\n",
    "        Lambda = jnp.linalg.inv(T)\n",
    "\n",
    "    return Q, R, T, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "905adddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd__compute_grad_A(C, Q, R, Lambda, gamma,\n",
    "                       semiRelaxedLeft, semiRelaxedRight,\n",
    "                       Wasserstein = True, FGW = False,\n",
    "                       A  = None,\n",
    "                       B = None,\n",
    "                       alpha = 0.0,\n",
    "                       unbalanced = False,\n",
    "                       full_grad = True):\n",
    "    \"\"\"\n",
    "    JAX version of gradient computation for Wasserstein, GW and FGW.\n",
    "    \"\"\"\n",
    "\n",
    "    r = Lambda.shape[0]\n",
    "    one_r = jnp.ones((r,))\n",
    "    One_rr = jnp.outer(one_r, one_r)\n",
    "\n",
    "    if Wasserstein:\n",
    "        gradQ, gradR = gd__Wasserstein_Grad(C, Q, R, Lambda, full_grad=full_grad)  # À adapter avec OTT-JAX\n",
    "    elif A is not None and B is not None:\n",
    "        if not semiRelaxedLeft and not semiRelaxedRight and not unbalanced:\n",
    "            gradQ = -4 * (A @ Q) @ Lambda @ (R.T @ B @ R) @ Lambda.T\n",
    "            gradR = -4 * (B @ R @ Lambda.T) @ (Q.T @ A @ Q) @ Lambda\n",
    "        elif semiRelaxedRight:\n",
    "            gradQ = -4 * (A @ Q) @ Lambda @ (R.T @ B @ R) @ Lambda.T\n",
    "            gradR = 2 * (B @ B) @ R @ One_rr - 4 * (B @ R @ Lambda.T) @ (Q.T @ A @ Q) @ Lambda\n",
    "        elif semiRelaxedLeft:\n",
    "            gradQ = 2 * (A @ A) @ Q @ One_rr - 4 * (A @ Q) @ Lambda @ (R.T @ B @ R) @ Lambda.T\n",
    "            gradR = -4 * (B @ R @ Lambda.T) @ (Q.T @ A @ Q) @ Lambda\n",
    "        elif unbalanced:\n",
    "            gradQ = 2 * (A @ A) @ Q @ One_rr - 4 * (A @ Q) @ Lambda @ (R.T @ B @ R) @ Lambda.T\n",
    "            gradR = 2 * (B @ B) @ R @ One_rr - 4 * (B @ R @ Lambda.T) @ (Q.T @ A @ Q) @ Lambda\n",
    "\n",
    "        if full_grad:\n",
    "            N1, N2 = Q.shape[0], R.shape[0]\n",
    "            one_N1 = jnp.ones((N1,))\n",
    "            one_N2 = jnp.ones((N2,))\n",
    "            gQ = Q.T @ one_N1\n",
    "            gR = R.T @ one_N2\n",
    "            F = Q @ Lambda @ R.T\n",
    "            MR = Lambda.T @ Q.T @ A @ F @ B @ R @ jnp.diag(1. / gR)\n",
    "            MQ = Lambda @ R.T @ B @ F.T @ A @ Q @ jnp.diag(1. / gQ)\n",
    "            gradQ += 4 * jnp.outer(one_N1, jnp.diag(MQ))\n",
    "            gradR += 4 * jnp.outer(one_N2, jnp.diag(MR))\n",
    "\n",
    "        if FGW:\n",
    "            gradQW, gradRW = gd__Wasserstein_Grad(C, Q, R, Lambda, full_grad=full_grad)  # À adapter\n",
    "            gradQ = (1 - alpha) * gradQW + alpha * gradQ\n",
    "            gradR = (1 - alpha) * gradRW + alpha * gradR\n",
    "    else:\n",
    "        raise ValueError(\"Provide either Wasserstein=True or distance matrices A and B for GW problem.\")\n",
    "\n",
    "    normalizer = jnp.max(jnp.array([jnp.max(jnp.abs(gradQ)), jnp.max(jnp.abs(gradR))]))\n",
    "    gamma_k = gamma / normalizer\n",
    "\n",
    "    return gradQ, gradR, gamma_k\n",
    "\n",
    "\n",
    "def gd__compute_grad_B(C, Q, R, Lambda, gQ, gR, gamma, Wasserstein=True,\n",
    "                       FGW=False, A=None, B=None, alpha=0.0):\n",
    "    '''\n",
    "    JAX version of the Wasserstein / GW / FGW gradient w.r.t. the transport plan T.\n",
    "    '''\n",
    "    if Wasserstein:\n",
    "        gradLambda = Q.T @ C @ R\n",
    "    else:\n",
    "        gradLambda = -4 * Q.T @ A @ Q @ Lambda @ R.T @ B @ R\n",
    "        if FGW:\n",
    "            gradLambda = (1 - alpha) * (Q.T @ C @ R) + alpha * gradLambda\n",
    "\n",
    "    gradT = jnp.diag(1.0 / gQ) @ gradLambda @ jnp.diag(1.0 / gR)\n",
    "    gamma_T = gamma / jnp.max(jnp.abs(gradT))\n",
    "    return gradT, gamma_T\n",
    "\n",
    "def gd__Wasserstein_Grad(C, Q, R, Lambda, full_grad=True):\n",
    "    gradQ = (C @ R) @ Lambda.T\n",
    "    if full_grad:\n",
    "        N1 = Q.shape[0]\n",
    "        one_N1 = jnp.ones((N1,), dtype=Q.dtype)\n",
    "        gQ = Q.T @ one_N1\n",
    "        w1 = jnp.diag((gradQ.T @ Q) @ jnp.diag(1.0 / gQ))\n",
    "        gradQ = gradQ - jnp.outer(one_N1, w1)\n",
    "\n",
    "    gradR = (C.T @ Q) @ Lambda\n",
    "    if full_grad:\n",
    "        N2 = R.shape[0]\n",
    "        one_N2 = jnp.ones((N2,), dtype=R.dtype)\n",
    "        gR = R.T @ one_N2\n",
    "        w2 = jnp.diag(jnp.diag(1.0 / gR) @ (R.T @ gradR))\n",
    "        gradR = gradR - jnp.outer(one_N2, w2)\n",
    "\n",
    "    return gradQ, gradR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953000d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FRLC_opt(C, a=None, b=None, A=None, B=None, tau_in=50, tau_out=50,\n",
    "             gamma=90, r=10, r2=None, max_iter=200,\n",
    "             semiRelaxedLeft=False, semiRelaxedRight=False, Wasserstein=True,\n",
    "             returnFull=False, FGW=False, alpha=0.0, unbalanced=False,\n",
    "             initialization='Full', init_args=None, full_grad=True,\n",
    "             convergence_criterion=True, tol=1e-5, min_iter=25,\n",
    "             min_iterGW=500, max_iterGW=1000,\n",
    "             max_inneriters_balanced=300, max_inneriters_relaxed=50,\n",
    "             diagonalize_return=False):\n",
    "\n",
    "    N1, N2 = C.shape\n",
    "    k = 0\n",
    "\n",
    "    one_N1 = jnp.ones((N1,))\n",
    "    one_N2 = jnp.ones((N2,))\n",
    "\n",
    "    if a is None:\n",
    "        a = one_N1 / N1\n",
    "    if b is None:\n",
    "        b = one_N2 / N2\n",
    "    if r2 is None:\n",
    "        r2 = r\n",
    "\n",
    "    one_r = jnp.ones((r,))\n",
    "    one_r2 = jnp.ones((r2,))\n",
    "\n",
    "    gQ = one_r / r\n",
    "    gR = one_r2 / r2\n",
    "\n",
    "    full_rank = initialization == 'Full' or initialization not in ['Full', 'Rank-2']\n",
    "\n",
    "    if init_args is None:\n",
    "        Q, R, T, Lambda = utils__initialize_couplings(a, b, gQ, gR,\n",
    "                                                      gamma, full_rank=full_rank,\n",
    "                                                      max_iter=max_inneriters_balanced)\n",
    "    else:\n",
    "        Q, R, T = init_args\n",
    "        Lambda = jnp.diag(1 / (Q.T @ one_N1)) @ T @ jnp.diag(1 / (R.T @ one_N2))\n",
    "\n",
    "    if not Wasserstein:\n",
    "        min_iter = min_iterGW\n",
    "        max_iter = max_iterGW\n",
    "\n",
    "    errs = []\n",
    "    gamma_k = gamma\n",
    "    Q_prev, R_prev, T_prev = None, None, None\n",
    "\n",
    "    def not_converged(k, Q, R, T, Q_prev, R_prev, T_prev, gamma_k):\n",
    "        if not convergence_criterion:\n",
    "            return True\n",
    "        if k < min_iter:\n",
    "            return True\n",
    "        delta = utils__Delta((Q, R, T), (Q_prev, R_prev, T_prev), gamma_k)\n",
    "        return delta > tol\n",
    "\n",
    "    while (k < max_iter and not_converged(k, Q, R, T, Q_prev, R_prev, T_prev, gamma_k)):\n",
    "        if convergence_criterion:\n",
    "            Q_prev, R_prev, T_prev = Q, R, T\n",
    "\n",
    "        if k % 25 == 0:\n",
    "            print(f'Iteration: {k}')\n",
    "\n",
    "        gradQ, gradR, gamma_k = gd__compute_grad_A(C, Q, R, Lambda, gamma,\n",
    "                                                   semiRelaxedLeft, semiRelaxedRight,\n",
    "                                                   Wasserstein=Wasserstein, A=A, B=B,\n",
    "                                                   FGW=FGW, alpha=alpha,\n",
    "                                                   unbalanced=unbalanced, full_grad=full_grad)\n",
    "\n",
    "        logQ = jnp.log(Q)\n",
    "        logR = jnp.log(R)\n",
    "\n",
    "        # Gestion explicite des modes de relaxation\n",
    "        if semiRelaxedLeft:\n",
    "            balanced_Q, unbalanced_Q = False, True\n",
    "            balanced_R, unbalanced_R = False, False\n",
    "        elif semiRelaxedRight:\n",
    "            balanced_Q, unbalanced_Q = False, False\n",
    "            balanced_R, unbalanced_R = False, True\n",
    "        elif unbalanced:\n",
    "            balanced_Q, unbalanced_Q = False, True\n",
    "            balanced_R, unbalanced_R = False, True\n",
    "        else:\n",
    "            balanced_Q, unbalanced_Q = True, False\n",
    "            balanced_R, unbalanced_R = True, False\n",
    "\n",
    "        Q = ott_log_sinkhorn(gradQ - (1 / gamma_k) * logQ, a, gQ, gamma_k,\n",
    "                             max_iter=max_inneriters_relaxed,\n",
    "                             balanced=balanced_Q, unbalanced=unbalanced_Q,\n",
    "                             tau=tau_out, tau2=tau_in)\n",
    "\n",
    "        R = ott_log_sinkhorn(gradR - (1 / gamma_k) * logR, b, gR, gamma_k,\n",
    "                             max_iter=max_inneriters_relaxed,\n",
    "                             balanced=balanced_R, unbalanced=unbalanced_R,\n",
    "                             tau=tau_out, tau2=tau_in)\n",
    "\n",
    "        gQ = Q.T @ one_N1\n",
    "        gR = R.T @ one_N2\n",
    "\n",
    "        gradT, gamma_T = gd__compute_grad_B(C, Q, R, Lambda, gQ, gR,\n",
    "                                            gamma, Wasserstein=Wasserstein,\n",
    "                                            A=A, B=B, FGW=FGW, alpha=alpha)\n",
    "\n",
    "        T = ott_log_sinkhorn(gradT - (1 / gamma_T) * jnp.log(T), gQ, gR, gamma_T,\n",
    "                             max_iter=max_inneriters_balanced,\n",
    "                             balanced=True, unbalanced=False)\n",
    "\n",
    "        Lambda = jnp.diag(1 / gQ) @ T @ jnp.diag(1 / gR)\n",
    "        k += 1\n",
    "\n",
    "    if returnFull:\n",
    "        P = Q @ Lambda @ R.T\n",
    "        return P, errs\n",
    "    else:\n",
    "        if diagonalize_return:\n",
    "            Q = Q @ jnp.diag(1 / gQ) @ T\n",
    "            gR = R.T @ one_N2\n",
    "            T = jnp.diag(gR)\n",
    "        return Q, R, T, errs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def FRLC_compute_OT_cost(X, Y, C = None, Monge_clusters = None, sq_Euclidean = True):\n",
    "    \"\"\"\n",
    "    Compute the optimal transport cost in linear space and time (without coupling), in JAX.\n",
    "    Supports squared Euclidean cost via OTT cost object.\n",
    "    \"\"\"\n",
    "    if Monge_clusters is None or len(Monge_clusters) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    def compute_pair_cost(pair):\n",
    "        idx1, idx2 = pair\n",
    "        if C is not None:\n",
    "            return C[idx1, idx2]\n",
    "        else:\n",
    "            diff = X[idx1] - Y[idx2]\n",
    "            if sq_Euclidean:\n",
    "                return jnp.sum(diff**2)\n",
    "            else:\n",
    "                return jnp.linalg.norm(diff)\n",
    "\n",
    "    pair_costs = jax.vmap(compute_pair_cost)(jnp.array(Monge_clusters))\n",
    "    total_cost = jnp.sum(pair_costs)\n",
    "    return total_cost / len(Monge_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b05f2e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m C = cdist_jax(X, Y)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# 2. Appel à FRLC_opt (on passe dtype=jnp.float32)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     Q, R, T, errs = \u001b[43mFRLC_opt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mC\u001b[49m\u001b[43m=\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtau_in\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100000\u001b[39;49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# 3. Calcul de la matrice de couplage P complète\u001b[39;00m\n\u001b[32m     22\u001b[39m     inv_sum_Q = \u001b[32m1.0\u001b[39m / jnp.sum(Q, axis=\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# shape (r,)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mFRLC_opt\u001b[39m\u001b[34m(C, a, b, A, B, tau_in, tau_out, gamma, r, r2, max_iter, semiRelaxedLeft, semiRelaxedRight, Wasserstein, returnFull, FGW, alpha, unbalanced, initialization, init_args, full_grad, convergence_criterion, tol, min_iter, min_iterGW, max_iterGW, max_inneriters_balanced, max_inneriters_relaxed, diagonalize_return)\u001b[39m\n\u001b[32m     30\u001b[39m full_rank = initialization == \u001b[33m'\u001b[39m\u001b[33mFull\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m initialization \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mFull\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRank-2\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m init_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     Q, R, T, Lambda = \u001b[43mutils__initialize_couplings\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m                                                  \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_rank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m                                                  \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_inneriters_balanced\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     37\u001b[39m     Q, R, T = init_args\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mutils__initialize_couplings\u001b[39m\u001b[34m(a, b, gQ, gR, gamma, full_rank, key, dtype, rank2_random, max_iter)\u001b[39m\n\u001b[32m     97\u001b[39m key, subkey = jax.random.split(key)\n\u001b[32m     98\u001b[39m C_random = jax.random.uniform(subkey, (r, r2), dtype=dtype)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m T = \u001b[43mott_log_sinkhorn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC_random\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgQ_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgR_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mbalanced\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# Inner inverse coupling\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r == r2:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mott_log_sinkhorn\u001b[39m\u001b[34m(grad, a, b, gamma_k, max_iter, balanced, unbalanced, tau, tau2)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Solveur Sinkhorn\u001b[39;00m\n\u001b[32m     40\u001b[39m solver = sinkhorn.Sinkhorn(max_iterations=max_iter)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m out = \u001b[43msolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out.matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/ott/solvers/linear/sinkhorn.py:756\u001b[39m, in \u001b[36mSinkhorn.__call__\u001b[39m\u001b[34m(self, ot_prob, init, **kwargs)\u001b[39m\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    755\u001b[39m   init = \u001b[38;5;28mself\u001b[39m.initializer(ot_prob, lse_mode=\u001b[38;5;28mself\u001b[39m.lse_mode, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m756\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mot_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/ott/solvers/linear/sinkhorn.py:1013\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(ot_prob, solver, init)\u001b[39m\n\u001b[32m   1011\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run loop of the solver, outputting a state upgraded to an output.\"\"\"\u001b[39;00m\n\u001b[32m   1012\u001b[39m iter_fun = _iterations_implicit \u001b[38;5;28;01mif\u001b[39;00m solver.implicit_diff \u001b[38;5;28;01melse\u001b[39;00m iterations\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m out = \u001b[43miter_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mot_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# Be careful here, the geom and the cost are injected at the end, where it\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# does not interfere with the implicit differentiation.\u001b[39;00m\n\u001b[32m   1016\u001b[39m out = out.set_cost(ot_prob, solver.lse_mode, solver.use_danskin)\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/custom_derivatives.py:698\u001b[39m, in \u001b[36mcustom_vjp.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    694\u001b[39m flat_fwd, out_trees = _flatten_fwd(\n\u001b[32m    695\u001b[39m     fwd_, \u001b[38;5;28mself\u001b[39m.nondiff_argnums, \u001b[38;5;28mself\u001b[39m.symbolic_zeros, debug_fun,\n\u001b[32m    696\u001b[39m     debug_fwd, in_tree, out_type)\n\u001b[32m    697\u001b[39m flat_bwd = _flatten_bwd(bwd, in_tree, in_avals, out_trees)\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m out_flat = \u001b[43mcustom_vjp_call_p\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_fwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_bwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_trees\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_trees\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43msymbolic_zeros\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msymbolic_zeros\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    701\u001b[39m _, (out_tree, _) = lu.merge_linear_aux(out_type, out_trees)\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree, out_flat)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/custom_derivatives.py:928\u001b[39m, in \u001b[36mCustomVJPCallPrimitive.bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **params):\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/core.py:512\u001b[39m, in \u001b[36mPrimitive._true_bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    510\u001b[39m trace_ctx.set_trace(eval_trace)\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    514\u001b[39m   trace_ctx.set_trace(prev_trace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/custom_derivatives.py:932\u001b[39m, in \u001b[36mCustomVJPCallPrimitive.bind_with_trace\u001b[39m\u001b[34m(self, trace, args, params)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[32m    931\u001b[39m   fun, fwd, bwd, tracers = args[\u001b[32m0\u001b[39m], args[\u001b[32m1\u001b[39m], args[\u001b[32m2\u001b[39m], args[\u001b[32m3\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m932\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_custom_vjp_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/core.py:1038\u001b[39m, in \u001b[36mEvalTrace.process_custom_vjp_call\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_custom_vjp_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, fun, fwd, bwd, tracers, **_):  \u001b[38;5;66;03m# pytype: disable=signature-mismatch\u001b[39;00m\n\u001b[32m   1037\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m primitive, fwd, bwd, _  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtracers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/linear_util.py:211\u001b[39m, in \u001b[36mWrappedFun.call_wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    210\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf_transformed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/custom_derivatives.py:87\u001b[39m, in \u001b[36m_flatten_fun_nokwargs\u001b[39m\u001b[34m(f, store, in_tree, *args_flat)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;129m@lu\u001b[39m.transformation_with_aux2\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_flatten_fun_nokwargs\u001b[39m(f: Callable,\n\u001b[32m     84\u001b[39m                           store: lu.Store, in_tree: PyTreeDef,\n\u001b[32m     85\u001b[39m                           *args_flat):\n\u001b[32m     86\u001b[39m   py_args = tree_unflatten(in_tree, args_flat)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m   ans = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpy_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m   ans_flat, ans_tree = tree_flatten(ans)\n\u001b[32m     89\u001b[39m   ans_avals = [core.get_aval(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ans_flat]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/linear_util.py:402\u001b[39m, in \u001b[36m_get_result_paths_thunk\u001b[39m\u001b[34m(_fun, _store, *args, **kwargs)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m   ans = \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m   result_paths = \u001b[38;5;28mtuple\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_clean_keystr_arg_names(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans))\n\u001b[32m    404\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[32m    405\u001b[39m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[32m    406\u001b[39m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/ott/solvers/linear/sinkhorn.py:1050\u001b[39m, in \u001b[36miterations\u001b[39m\u001b[34m(ot_prob, solver, init)\u001b[39m\n\u001b[32m   1048\u001b[39m const = ot_prob, solver\n\u001b[32m   1049\u001b[39m state = solver.init_state(ot_prob, init)\n\u001b[32m-> \u001b[39m\u001b[32m1050\u001b[39m state = \u001b[43mfix_point\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcond_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43minner_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m solver.output_from_state(ot_prob, state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/ott/math/fixed_point_loop.py:92\u001b[39m, in \u001b[36mfixpoint_iter\u001b[39m\u001b[34m(cond_fn, body_fn, min_iterations, max_iterations, inner_iterations, constants, state)\u001b[39m\n\u001b[32m     86\u001b[39m   (_, state), _ = jax.lax.scan(\n\u001b[32m     87\u001b[39m       \u001b[38;5;28;01mlambda\u001b[39;00m carry, x: unrolled_body_fn(carry), (\u001b[32m0\u001b[39m, state),\n\u001b[32m     88\u001b[39m       \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     89\u001b[39m       length=max_iterations // inner_iterations\n\u001b[32m     90\u001b[39m   )\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m   _, state = \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_cond_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munrolled_body_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/lax/control_flow/loops.py:1485\u001b[39m, in \u001b[36mwhile_loop\u001b[39m\u001b[34m(cond_fun, body_fun, init_val)\u001b[39m\n\u001b[32m   1482\u001b[39m   init_vals, new_body_consts = partition_list(move_to_const, init_vals)\n\u001b[32m   1483\u001b[39m   body_consts = [*new_body_consts, *body_consts]\n\u001b[32m-> \u001b[39m\u001b[32m1485\u001b[39m outs = \u001b[43mwhile_p\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcond_consts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mbody_consts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1486\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mcond_nconsts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcond_consts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_jaxpr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcond_jaxpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mbody_nconsts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbody_consts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_jaxpr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_jaxpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1489\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(move_to_const):\n\u001b[32m   1490\u001b[39m   outs = pe.merge_lists(move_to_const, outs, new_body_consts)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/core.py:496\u001b[39m, in \u001b[36mPrimitive.bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **params):\n\u001b[32m    495\u001b[39m   args = args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.skip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/core.py:512\u001b[39m, in \u001b[36mPrimitive._true_bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    510\u001b[39m trace_ctx.set_trace(eval_trace)\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    514\u001b[39m   trace_ctx.set_trace(prev_trace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/core.py:517\u001b[39m, in \u001b[36mPrimitive.bind_with_trace\u001b[39m\u001b[34m(self, trace, args, params)\u001b[39m\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/core.py:1017\u001b[39m, in \u001b[36mEvalTrace.process_primitive\u001b[39m\u001b[34m(self, primitive, args, params)\u001b[39m\n\u001b[32m   1015\u001b[39m args = \u001b[38;5;28mmap\u001b[39m(full_lower, args)\n\u001b[32m   1016\u001b[39m check_eval_args(args)\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/dispatch.py:89\u001b[39m, in \u001b[36mapply_primitive\u001b[39m\u001b[34m(prim, *args, **params)\u001b[39m\n\u001b[32m     87\u001b[39m prev = lib.jax_jit.swap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m   outs = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     91\u001b[39m   lib.jax_jit.swap_thread_local_state_disable_jit(prev)\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/pjit.py:340\u001b[39m, in \u001b[36m_cpp_pjit.<locals>.cache_miss\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.no_tracing.value:\n\u001b[32m    336\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mre-tracing function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjit_info.fun_sourceinfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    337\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33m`jit`, but \u001b[39m\u001b[33m'\u001b[39m\u001b[33mno_tracing\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    339\u001b[39m (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, executable,\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m  pgle_profiler) = \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m maybe_fastpath_data = _get_fastpath_data(\n\u001b[32m    343\u001b[39m     executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr.effects,\n\u001b[32m    344\u001b[39m     jaxpr.consts, jit_info.abstracted_axes,\n\u001b[32m    345\u001b[39m     pgle_profiler)\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outs, maybe_fastpath_data, _need_to_rebuild_with_fdo(pgle_profiler)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/pjit.py:191\u001b[39m, in \u001b[36m_python_pjit_helper\u001b[39m\u001b[34m(fun, jit_info, *args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m   args_flat = \u001b[38;5;28mmap\u001b[39m(core.full_lower, args_flat)\n\u001b[32m    190\u001b[39m   core.check_eval_args(args_flat)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m   out_flat, compiled, profiler = \u001b[43m_pjit_call_impl_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    193\u001b[39m   out_flat = pjit_p.bind(*args_flat, **p.params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/pjit.py:1809\u001b[39m, in \u001b[36m_pjit_call_impl_python\u001b[39m\u001b[34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, donated_invars, ctx_mesh, name, keep_unused, inline, compiler_options_kvs, *args)\u001b[39m\n\u001b[32m   1797\u001b[39m compiler_options_kvs = compiler_options_kvs + \u001b[38;5;28mtuple\u001b[39m(pgle_compile_options.items())\n\u001b[32m   1798\u001b[39m \u001b[38;5;66;03m# Passing mutable PGLE profile here since it should be extracted by JAXPR to\u001b[39;00m\n\u001b[32m   1799\u001b[39m \u001b[38;5;66;03m# initialize the fdo_profile compile option.\u001b[39;00m\n\u001b[32m   1800\u001b[39m compiled = \u001b[43m_resolve_and_lower\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1801\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_layouts\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mctx_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctx_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1805\u001b[39m \u001b[43m    \u001b[49m\u001b[43minline\u001b[49m\u001b[43m=\u001b[49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowering_platforms\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlowering_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlir\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoweringParameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1807\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1808\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1809\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1811\u001b[39m \u001b[38;5;66;03m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n\u001b[32m   1812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compiled._auto_spmd_lowering \u001b[38;5;129;01mand\u001b[39;00m config.enable_checks.value:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2462\u001b[39m, in \u001b[36mMeshComputation.compile\u001b[39m\u001b[34m(self, compiler_options)\u001b[39m\n\u001b[32m   2460\u001b[39m compiler_options_kvs = \u001b[38;5;28mself\u001b[39m._compiler_options_kvs + t_compiler_options\n\u001b[32m   2461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._executable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m compiler_options_kvs:\n\u001b[32m-> \u001b[39m\u001b[32m2462\u001b[39m   executable = \u001b[43mUnloadedMeshExecutable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_hlo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_hlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2465\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compiler_options_kvs:\n\u001b[32m   2466\u001b[39m     \u001b[38;5;28mself\u001b[39m._executable = executable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:3004\u001b[39m, in \u001b[36mUnloadedMeshExecutable.from_hlo\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3001\u001b[39m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   3003\u001b[39m util.test_event(\u001b[33m\"\u001b[39m\u001b[33mpxla_cached_compilation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3004\u001b[39m xla_executable = \u001b[43m_cached_compilation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspmd_lowering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtuple_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_spmd_lowering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_prop_to_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3007\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_prop_to_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmap_nreps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3008\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3010\u001b[39m orig_out_shardings = out_shardings\n\u001b[32m   3012\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m auto_spmd_lowering:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2795\u001b[39m, in \u001b[36m_cached_compilation\u001b[39m\u001b[34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, allow_prop_to_inputs, allow_prop_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_kvs, pgle_profiler)\u001b[39m\n\u001b[32m   2787\u001b[39m compile_options = create_compile_options(\n\u001b[32m   2788\u001b[39m     computation, mesh, spmd_lowering, tuple_args, auto_spmd_lowering,\n\u001b[32m   2789\u001b[39m     allow_prop_to_inputs, allow_prop_to_outputs, backend,\n\u001b[32m   2790\u001b[39m     dev, pmap_nreps, compiler_options)\n\u001b[32m   2792\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dispatch.log_elapsed_time(\n\u001b[32m   2793\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFinished XLA compilation of \u001b[39m\u001b[38;5;132;01m{fun_name}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{elapsed_time:.9f}\u001b[39;00m\u001b[33m sec\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2794\u001b[39m     fun_name=name, event=dispatch.BACKEND_COMPILE_EVENT):\n\u001b[32m-> \u001b[39m\u001b[32m2795\u001b[39m   xla_executable = \u001b[43mcompiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_or_get_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2796\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2797\u001b[39m \u001b[43m      \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2798\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xla_executable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/compiler.py:432\u001b[39m, in \u001b[36mcompile_or_get_cached\u001b[39m\u001b[34m(backend, computation, devices, compile_options, host_callbacks, pgle_profiler)\u001b[39m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    431\u001b[39m   log_persistent_cache_miss(module_name, cache_key)\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_and_write_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m      \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/compiler.py:694\u001b[39m, in \u001b[36m_compile_and_write_cache\u001b[39m\u001b[34m(backend, computation, compile_options, host_callbacks, module_name, cache_key)\u001b[39m\n\u001b[32m    685\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compile_and_write_cache\u001b[39m(\n\u001b[32m    686\u001b[39m     backend: xc.Client,\n\u001b[32m    687\u001b[39m     computation: ir.Module,\n\u001b[32m   (...)\u001b[39m\u001b[32m    691\u001b[39m     cache_key: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    692\u001b[39m ) -> xc.LoadedExecutable:\n\u001b[32m    693\u001b[39m   start_time = time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m   executable = \u001b[43mbackend_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m   compile_time = time.monotonic() - start_time\n\u001b[32m    698\u001b[39m   _cache_write(\n\u001b[32m    699\u001b[39m       cache_key, compile_time, module_name, backend, executable, host_callbacks\n\u001b[32m    700\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/profiler.py:334\u001b[39m, in \u001b[36mannotate_function.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    333\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, **decorator_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/compiler.py:324\u001b[39m, in \u001b[36mbackend_compile\u001b[39m\u001b[34m(backend, module, options, host_callbacks)\u001b[39m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m backend.compile(\n\u001b[32m    319\u001b[39m         built_c, compile_options=options, host_callbacks=host_callbacks\n\u001b[32m    320\u001b[39m     )\n\u001b[32m    321\u001b[39m   \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[32m    322\u001b[39m   \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[32m    323\u001b[39m   \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m xc.XlaRuntimeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    326\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m error_handler \u001b[38;5;129;01min\u001b[39;00m _XLA_RUNTIME_ERROR_HANDLERS:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 1. Calcul de la matrice des coûts (distance euclidienne)\n",
    "def cdist_jax(X, Y):\n",
    "    # ||x - y||^2 = ||x||^2 + ||y||^2 - 2<x, y>\n",
    "    X_norm = jnp.sum(X ** 2, axis=1)[:, None]\n",
    "    Y_norm = jnp.sum(Y ** 2, axis=1)[None, :]\n",
    "    C = jnp.sqrt(jnp.maximum(X_norm + Y_norm - 2 * jnp.dot(X, Y.T), 0.0))\n",
    "    return C\n",
    "\n",
    "C = cdist_jax(X, Y)\n",
    "\n",
    "try:\n",
    "    # 2. Appel à FRLC_opt (on passe dtype=jnp.float32)\n",
    "    Q, R, T, errs = FRLC_opt(\n",
    "        C=C,\n",
    "        gamma=30,\n",
    "        r=40,\n",
    "        max_iter=100,\n",
    "        tau_in=100000\n",
    "    )\n",
    "\n",
    "    # 3. Calcul de la matrice de couplage P complète\n",
    "    inv_sum_Q = 1.0 / jnp.sum(Q, axis=0)  # shape (r,)\n",
    "    inv_sum_R = 1.0 / jnp.sum(R, axis=0)  # shape (r,)\n",
    "    P = (Q\n",
    "         @ jnp.diag(inv_sum_Q)\n",
    "         @ T\n",
    "         @ jnp.diag(inv_sum_R)\n",
    "         @ R.T)  # shape (n_X, n_Y)\n",
    "\n",
    "    # 4. Extraction des paires (i,j) où P[i,j] > 0\n",
    "    ij = jnp.argwhere(P > 0)  # shape (num_pairs, 2)\n",
    "    Monge_clusters = [(int(i), int(j)) for i, j in ij]\n",
    "\n",
    "    # 5. Calcul du coût OT via la fonction JAXisée\n",
    "    cost_frlc = FRLC_compute_OT_cost(\n",
    "        X, Y,\n",
    "        C=C,\n",
    "        Monge_clusters=Monge_clusters,\n",
    "        sq_Euclidean=True\n",
    "    )\n",
    "\n",
    "    print(f'FRLC cost: {cost_frlc}')\n",
    "\n",
    "    # 6. Approximation du couplage pour l'extraction de correspondances\n",
    "    P_approx = Q @ T @ R.T  # shape (n_X, n_Y)\n",
    "    matches_Y = jnp.argmax(P_approx, axis=1)  # shape (n_X,)\n",
    "\n",
    "    # 7. Construction de la liste F de paires indices\n",
    "    F = [\n",
    "        (jnp.array([i], dtype=jnp.int32),\n",
    "         jnp.array([int(matches_Y[i])], dtype=jnp.int32))\n",
    "        for i in range(X.shape[0])\n",
    "    ]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'FRLC failed for sample size {X.shape[0]}: {e}')\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1158f",
   "metadata": {},
   "source": [
    "# 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a4f4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "--------------\n",
    "Code for gradients assuming low-rank distance matrices C, A, B\n",
    "--------------\n",
    "'''\n",
    "\n",
    "def gd__compute_grad_A_LR(C_factors, A_factors, B_factors, Q, R, Lambda, gamma, alpha=0.0, full_grad=False):\n",
    "    \n",
    "    N1, N2 = C_factors[0].shape[0], C_factors[1].shape[1]\n",
    "\n",
    "    if A_factors is not None and B_factors is not None:\n",
    "        A1, A2 = A_factors\n",
    "        B1, B2 = B_factors\n",
    "\n",
    "        # GW gradients\n",
    "        gradQ = -4 * (A1 @ (A2 @ (Q @ Lambda @ ((R.T @ B1) @ (B2 @ R)) @ Lambda.T)))\n",
    "        gradR = -4 * (B1 @ (B2 @ (R @ (Lambda.T @ ((Q.T @ A1) @ (A2 @ Q)) @ Lambda))))\n",
    "\n",
    "        one_N1 = jnp.ones((N1,), dtype=Q.dtype)\n",
    "        one_N2 = jnp.ones((N2,), dtype=R.dtype)\n",
    "\n",
    "        if full_grad:\n",
    "            gQ = Q.T @ one_N1\n",
    "            gR = R.T @ one_N2\n",
    "\n",
    "            MR = (Lambda.T @ ((Q.T @ A1) @ (A2 @ Q)) @ Lambda\n",
    "                  @ ((R.T @ B1) @ (B2 @ R)) @ jnp.diag(1.0 / gR))\n",
    "            MQ = (Lambda @ ((R.T @ B1) @ (B2 @ R)) @ Lambda.T\n",
    "                  @ ((Q.T @ A1) @ (A2 @ Q)) @ jnp.diag(1.0 / gQ))\n",
    "\n",
    "            gradQ += 4 * jnp.outer(one_N1, jnp.diag(MQ))\n",
    "            gradR += 4 * jnp.outer(one_N2, jnp.diag(MR))\n",
    "    else:\n",
    "        gradQ = jnp.zeros_like(Q)\n",
    "        gradR = jnp.zeros_like(R)\n",
    "\n",
    "    # Appel à une version jaxifiée de gd__Wasserstein_Grad_LR\n",
    "    gradQW, gradRW = gd__Wasserstein_Grad_LR(C_factors, Q, R, Lambda, full_grad=full_grad)\n",
    "\n",
    "    gradQ = (1 - alpha) * gradQW + (alpha / 2.0) * gradQ\n",
    "    gradR = (1 - alpha) * gradRW + (alpha / 2.0) * gradR\n",
    "\n",
    "    normalizer = jnp.maximum(jnp.max(jnp.abs(gradQ)), jnp.max(jnp.abs(gradR)))\n",
    "    gamma_k = gamma / normalizer\n",
    "\n",
    "    return gradQ, gradR, gamma_k\n",
    "\n",
    "def gd__compute_grad_B_LR(C_factors, A_factors, B_factors, Q, R, Lambda, gQ, gR, gamma, alpha=0.0):\n",
    "    \"\"\"\n",
    "    Low-rank gradient computation in JAX for Wasserstein / Gromov-Wasserstein.\n",
    "    \"\"\"\n",
    "    C1, C2 = C_factors  # (N1, rC), (rC, N2)\n",
    "    gradLambda = 0.0\n",
    "\n",
    "    if A_factors is not None and B_factors is not None:\n",
    "        A1, A2 = A_factors  # (N1, rA), (rA, N1)\n",
    "        B1, B2 = B_factors  # (N2, rB), (rB, N2)\n",
    "        term_A = (Q.T @ A1) @ (A2 @ Q)         # shape: (r, r)\n",
    "        term_B = (R.T @ B1) @ (B2 @ R)         # shape: (r, r)\n",
    "        gradLambda = -4.0 * term_A @ Lambda @ term_B\n",
    "\n",
    "    term_C = (Q.T @ C1) @ (C2 @ R)             # shape: (r, r)\n",
    "    gradLambda = (1 - alpha) * term_C + (alpha / 2.0) * gradLambda\n",
    "\n",
    "    gradT = jnp.diag(1.0 / gQ) @ gradLambda @ jnp.diag(1.0 / gR)\n",
    "    gamma_T = gamma / jnp.max(jnp.abs(gradT))\n",
    "    return gradT, gamma_T\n",
    "\n",
    "def gd__Wasserstein_Grad_LR(C_factors, Q, R, Lambda, full_grad=True):\n",
    "    \"\"\"\n",
    "    JAX version of Wasserstein gradient with low-rank cost approximation:\n",
    "    C ≈ C1 @ C2.T\n",
    "    \"\"\"\n",
    "    C1, C2 = C_factors\n",
    "\n",
    "    gradQ = C1 @ ((C2 @ R) @ Lambda.T)\n",
    "    if full_grad:\n",
    "        N1 = Q.shape[0]\n",
    "        one_N1 = jnp.ones((N1,), dtype=Q.dtype)\n",
    "        gQ = Q.T @ one_N1\n",
    "        w1 = jnp.diag((gradQ.T @ Q) @ jnp.diag(1.0 / gQ))\n",
    "        gradQ = gradQ - jnp.outer(one_N1, w1)\n",
    "\n",
    "    gradR = C2.T @ ((C1.T @ Q) @ Lambda)\n",
    "    if full_grad:\n",
    "        N2 = R.shape[0]\n",
    "        one_N2 = jnp.ones((N2,), dtype=R.dtype)\n",
    "        gR = R.T @ one_N2\n",
    "        w2 = jnp.diag(jnp.diag(1.0 / gR) @ (R.T @ gradR))\n",
    "        gradR = gradR - jnp.outer(one_N2, w2)\n",
    "\n",
    "    return gradQ, gradR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe4033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:76: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:76: SyntaxWarning: invalid escape sequence '\\l'\n",
      "/tmp/ipykernel_5029/427638459.py:15: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  \"\"\"\n",
      "/tmp/ipykernel_5029/427638459.py:23: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  \"\"\"\n",
      "/tmp/ipykernel_5029/427638459.py:76: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def rank_annealing__factors(n):\n",
    "    \"\"\"\n",
    "    Return list of all factors of an integer\n",
    "    \"\"\"\n",
    "    n = int(n)  # Conversion pour compatibilité avec jnp.arange\n",
    "    candidates = jnp.arange(1, jnp.floor(jnp.sqrt(n)) + 1).astype(int)\n",
    "    divisible = (n % candidates) == 0\n",
    "    factors1 = candidates[divisible]\n",
    "    factors2 = n // factors1\n",
    "    all_factors = jnp.concatenate([factors1, factors2])\n",
    "    unique_factors = jnp.unique(all_factors)\n",
    "    return unique_factors\n",
    "\n",
    "def rank_annealing__max_factor_lX(n, max_X):\n",
    "    \"\"\"\n",
    "    Find max factor of n , such that max_factor \\leq max_X\n",
    "    \"\"\"\n",
    "    factor_lst = rank_annealing__factors(n)\n",
    "    factors_leq_max = factor_lst[factor_lst <= max_X]\n",
    "    return jnp.max(factors_leq_max)\n",
    "\n",
    "def rank_annealing__min_sum_partial_products_with_factors(n, k, C):\n",
    "    \"\"\"\n",
    "    Dynamic program to compute the rank-schedule, subject to a constraint of intermediates being \\leq C\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        The dataset size to be factored into a rank-scheduler. Assumed to be non-prime.\n",
    "    k: int\n",
    "        The depth of the hierarchy.\n",
    "    C: int\n",
    "        A constraint on the maximal intermediate rank across the hierarchy.\n",
    "    \n",
    "    \"\"\"\n",
    "    INF = 1e10  # Large constant instead of float('inf') for JAX compatibility\n",
    "\n",
    "    dp = jnp.full((n+1, k+1), INF)\n",
    "    choice = jnp.full((n+1, k+1), -1)\n",
    "\n",
    "    def init_base_case(dp, choice):\n",
    "        d = jnp.arange(1, n+1)\n",
    "        mask = d <= C\n",
    "        dp = dp.at[d[mask], 1].set(d[mask])\n",
    "        choice = choice.at[d[mask], 1].set(d[mask])\n",
    "        return dp, choice\n",
    "\n",
    "    dp, choice = init_base_case(dp, choice)\n",
    "\n",
    "    for t in range(2, k+1):\n",
    "        for d in range(1, n+1):\n",
    "            if dp[d, t-1] >= INF:\n",
    "                continue\n",
    "            for r in range(1, min(C, d)+1):\n",
    "                if d % r == 0:\n",
    "                    candidate = r + r * dp[d // r, t-1]\n",
    "                    if candidate < dp[d, t]:\n",
    "                        dp = dp.at[d, t].set(candidate)\n",
    "                        choice = choice.at[d, t].set(r)\n",
    "\n",
    "    if dp[n, k] >= INF:\n",
    "        return None, []\n",
    "\n",
    "    # Backtracking\n",
    "    factors = []\n",
    "    d_cur, t_cur = n, k\n",
    "    while t_cur > 0:\n",
    "        r_cur = int(choice[d_cur, t_cur])\n",
    "        factors.append(r_cur)\n",
    "        d_cur //= r_cur\n",
    "        t_cur -= 1\n",
    "\n",
    "    return dp[n, k], factors\n",
    "\n",
    "def rank_annealing__optimal_rank_schedule(n, hierarchy_depth=6, max_Q=int(2**10), max_rank=16):\n",
    "    \"\"\"\n",
    "    A function to compute the optimal rank-scheduler of refinement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Size of the input dataset -- cannot be a prime number\n",
    "    hierarchy_depth: int\n",
    "        Maximal permissible depth of the multi-scale hierarchy\n",
    "    max_Q: int\n",
    "        Maximal rank at terminal base case (before reducing the \\leq max_Q rank coupling to a 1-1 alignment)\n",
    "    max_rank: int\n",
    "        Maximal rank at the intermediate steps of the rank-schedule\n",
    "        \n",
    "    \"\"\"\n",
    "    Q = int(rank_annealing__max_factor_lX(n, max_Q))\n",
    "    ndivQ = int(n // Q)\n",
    "\n",
    "    _, rank_schedule = rank_annealing__min_sum_partial_products_with_factors(ndivQ, hierarchy_depth, max_rank)\n",
    "    rank_schedule = sorted(rank_schedule)\n",
    "    rank_schedule.append(Q)\n",
    "    rank_schedule = [x for x in rank_schedule if x != 1]\n",
    "\n",
    "    print(f'Optimized rank-annealing schedule: {rank_schedule}')\n",
    "\n",
    "    assert functools.reduce(operator.mul, rank_schedule, 1) == n, \"Error! Rank-schedule does not factorize n!\"\n",
    "\n",
    "    return rank_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa9fe3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils__low_rank_distance_factorization(X1, X2, r, eps, key=jax.random.PRNGKey(0)):\n",
    "    n = X1.shape[0]\n",
    "    m = X2.shape[0]\n",
    "    t = int(r / eps)\n",
    "\n",
    "    key1, key2, key3, key4 = jax.random.split(key, 4)\n",
    "    i_star = jax.random.randint(key1, (), 0, n)\n",
    "    j_star = jax.random.randint(key2, (), 0, m)\n",
    "\n",
    "    x1_i = X1[i_star]\n",
    "    x2_j = X2[j_star]\n",
    "\n",
    "    # Compute p\n",
    "    cd1 = jnp.linalg.norm(X1 - x2_j[None, :], axis=1) ** 2\n",
    "    cd2 = jnp.linalg.norm(X2 - x1_i[None, :], axis=1) ** 2\n",
    "    cd3 = jnp.mean(jnp.linalg.norm(X2 - x1_i[None, :], axis=1))\n",
    "\n",
    "    p = (cd1 + jnp.linalg.norm(x1_i - x2_j) ** 2 + cd3) ** 2\n",
    "    p = p / jnp.sum(p)\n",
    "\n",
    "    indices_p = jax.random.choice(key3, n, shape=(t,), p=p)\n",
    "    X1_t = X1[indices_p]\n",
    "    P_t = jnp.sqrt(p[indices_p] * t)\n",
    "\n",
    "    S = jnp.linalg.norm(X1_t[:, None, :] - X2[None, :, :], axis=2) / P_t[:, None]  # shape: (t, m)\n",
    "\n",
    "    # Compute q\n",
    "    S_norm = jnp.linalg.norm(S)\n",
    "    q = jnp.linalg.norm(S, axis=0) ** 2 / (S_norm ** 2)\n",
    "    q = q / jnp.sum(q)\n",
    "\n",
    "    indices_q = jax.random.choice(key4, m, shape=(t,), p=q)\n",
    "    S_t = S[:, indices_q]\n",
    "    Q_t = jnp.sqrt(q[indices_q] * t)\n",
    "    W = S_t / Q_t[None, :]\n",
    "\n",
    "    # SVD\n",
    "    U, Sig, Vh = jnp.linalg.svd(W, full_matrices=False)\n",
    "    F = U[:, :r]\n",
    "\n",
    "    # Compute U_t\n",
    "    W_F = W.T @ F\n",
    "    norm_WF = jnp.linalg.norm(W_F)\n",
    "    U_t = (S.T @ F) / norm_WF\n",
    "\n",
    "    # Chen & Price 2017 step\n",
    "    key5 = jax.random.PRNGKey(42)  # For deterministic behavior\n",
    "    indices = jax.random.choice(key5, m, shape=(t,))\n",
    "    X2_t = X2[indices]\n",
    "    D_t = jnp.linalg.norm(X1[:, None, :] - X2_t[None, :, :], axis=2) / jnp.sqrt(t)\n",
    "\n",
    "    Q = U_t.T @ U_t\n",
    "    UQ, SigQ, VhQ = jnp.linalg.svd(Q)\n",
    "    UQ = UQ / SigQ\n",
    "    U_tSub = U_t[indices].T\n",
    "    B = (UQ.T @ U_tSub) / jnp.sqrt(t)\n",
    "    A = jnp.linalg.inv(B @ B.T)\n",
    "    Z = (A @ B) @ D_t.T\n",
    "    V = Z.T @ UQ\n",
    "\n",
    "    return V.astype(jnp.float64), U_t.T.astype(jnp.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b79b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils__hadamard_square_lr(A1, A2):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        A1: jax.numpy array, low-rank subcoupling of shape (n, r)\n",
    "        A2: jax.numpy array, low-rank subcoupling of shape (n, r)\n",
    "                ( such that A ≈ A1 @ A2.T )\n",
    "\n",
    "    Output\n",
    "        A1_tilde: jax.numpy array, low-rank subcoupling of shape (n, r**2)\n",
    "        A2_tilde: jax.numpy array, low-rank subcoupling of shape (n, r**2)\n",
    "               ( such that A * A ≈ A1_tilde @ A2_tilde.T )\n",
    "    \"\"\"\n",
    "    n, r = A1.shape\n",
    "    A1_tilde = jnp.einsum(\"ij,ik->ijk\", A1, A1).reshape(n, r * r)\n",
    "    A2_tilde = jnp.einsum(\"ij,ik->ijk\", A2, A2).reshape(n, r * r)\n",
    "\n",
    "    return A1_tilde, A2_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6235124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FRLC_LR_opt(\n",
    "    C_factors, A_factors, B_factors, a=None, b=None,\n",
    "    tau_in=50, tau_out=50, gamma=90, r=10, r2=None,\n",
    "    max_iter=200, printCost=True, returnFull=False, alpha=0.0,\n",
    "    initialization='Full', init_args=None, full_grad=True,\n",
    "    convergence_criterion=True, tol=5e-6, min_iter=25,\n",
    "    max_inneriters_balanced=300, max_inneriters_relaxed=50,\n",
    "    diagonalize_return=False\n",
    "):\n",
    "    N1, N2 = C_factors[0].shape[0], C_factors[1].shape[1]\n",
    "    k = 0\n",
    "    stationarity_gap = jnp.inf\n",
    "\n",
    "    one_N1 = jnp.ones((N1,))\n",
    "    one_N2 = jnp.ones((N2,))\n",
    "\n",
    "    if a is None:\n",
    "        a = one_N1 / N1\n",
    "    if b is None:\n",
    "        b = one_N2 / N2\n",
    "    if r2 is None:\n",
    "        r2 = r\n",
    "\n",
    "    one_r = jnp.ones((r,))\n",
    "    one_r2 = jnp.ones((r2,))\n",
    "\n",
    "    gQ = one_r / r\n",
    "    gR = one_r2 / r2\n",
    "\n",
    "    full_rank = initialization == 'Full'\n",
    "    \n",
    "    if initialization not in ['Full', 'Rank-2']:\n",
    "        print('Initialization must be either \"Full\" or \"Rank-2\", defaulting to \"Full\".')\n",
    "        full_rank = True\n",
    "\n",
    "    if init_args is None:\n",
    "        Q, R, T, Lambda = utils__initialize_couplings(a, b, gQ, gR, gamma, full_rank=full_rank, max_iter=max_inneriters_balanced)\n",
    "    else:\n",
    "        Q, R, T = init_args\n",
    "        if Q is not None:\n",
    "            gQ = Q.T @ one_N1\n",
    "        if R is not None:\n",
    "            gR = R.T @ one_N2\n",
    "        if Q is None or R is None or T is None:\n",
    "            _Q, _R, _T, Lambda = utils__initialize_couplings(a, b, gQ, gR, gamma, full_rank=full_rank, max_iter=max_inneriters_balanced)\n",
    "            Q = Q if Q is not None else _Q\n",
    "            R = R if R is not None else _R\n",
    "            T = T if T is not None else _T\n",
    "\n",
    "        Lambda = jnp.diag(1 / (Q.T @ one_N1)) @ T @ jnp.diag(1 / (R.T @ one_N2))\n",
    "\n",
    "    errs = {'total_cost': [], 'W_cost': [], 'GW_cost': []}\n",
    "    gamma_k = gamma\n",
    "    Q_prev, R_prev, T_prev = None, None, None\n",
    "\n",
    "    while k < max_iter and (not convergence_criterion or (k < min_iter or utils__Delta((Q, R, T), (Q_prev, R_prev, T_prev), gamma_k) > tol)):\n",
    "        if convergence_criterion:\n",
    "            Q_prev, R_prev, T_prev = Q, R, T\n",
    "\n",
    "        if k % 25 == 0:\n",
    "            print(f\"Iteration: {k}\")\n",
    "\n",
    "        gradQ, gradR, gamma_k = gd__compute_grad_A_LR(C_factors, A_factors, B_factors, Q, R, Lambda, gamma, alpha=alpha, full_grad=full_grad)\n",
    "\n",
    "        R = ott_log_sinkhorn(gradR - (1 / gamma_k) * jnp.log(R), b, gR, gamma_k, max_iter=max_inneriters_relaxed, tau=tau_in)\n",
    "        Q = ott_log_sinkhorn(gradQ - (1 / gamma_k) * jnp.log(Q), a, gQ, gamma_k, max_iter=max_inneriters_relaxed, tau=tau_in)\n",
    "\n",
    "        gQ, gR = Q.T @ one_N1, R.T @ one_N2\n",
    "\n",
    "        gradT, gamma_T = gd__compute_grad_B_LR(C_factors, A_factors, B_factors, Q, R, Lambda, gQ, gR, gamma, alpha=alpha)\n",
    "        T = ott_log_sinkhorn(gradT - (1 / gamma_T) * jnp.log(T), gQ, gR, gamma_T, max_iter=max_inneriters_balanced)\n",
    "\n",
    "        Lambda = jnp.diag(1 / gQ) @ T @ jnp.diag(1 / gR)\n",
    "\n",
    "        if printCost:\n",
    "            primal_cost = jnp.trace(((Q.T @ C_factors[0]) @ (C_factors[1] @ R)) @ Lambda.T)\n",
    "            errs['W_cost'].append(primal_cost)\n",
    "            if A_factors is not None and B_factors is not None:\n",
    "                X = R @ ((Lambda.T @ ((Q.T @ A_factors[0]) @ (A_factors[1] @ Q)) @ Lambda) @ (R.T @ B_factors[0])) @ B_factors[1]\n",
    "                GW_cost = -2 * jnp.trace(X)\n",
    "                A1_tild, A2_tild = utils__hadamard_square_lr(A_factors[0], A_factors[1].T)\n",
    "                GW_cost += jnp.dot(A1_tild.T @ (Q @ one_r), A2_tild.T @ (Q @ one_r))\n",
    "                B1_tild, B2_tild = utils__hadamard_square_lr(B_factors[0], B_factors[1].T)\n",
    "                GW_cost += jnp.dot(B1_tild.T @ (R @ one_r2), B2_tild.T @ (R @ one_r2))\n",
    "                errs['GW_cost'].append(GW_cost)\n",
    "                errs['total_cost'].append((1 - alpha) * primal_cost + alpha * GW_cost)\n",
    "            else:\n",
    "                errs['GW_cost'].append(0)\n",
    "                errs['total_cost'].append(primal_cost)\n",
    "        k += 1\n",
    "\n",
    "    if printCost:\n",
    "        print(f\"Initial Wasserstein cost: {errs['W_cost'][0]}, GW-cost: {errs['GW_cost'][0]}, Total cost: {errs['total_cost'][0]}\")\n",
    "        print(f\"Final Wasserstein cost: {errs['W_cost'][-1]}, GW-cost: {errs['GW_cost'][-1]}, Total cost: {errs['total_cost'][-1]}\")\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.plot(errs['total_cost'])\n",
    "        plt.show()\n",
    "\n",
    "    if returnFull:\n",
    "        P = Q @ Lambda @ R.T\n",
    "        return P, errs\n",
    "    else:\n",
    "        if diagonalize_return:\n",
    "            Q = Q @ (jnp.diag(1 / gQ) @ T)\n",
    "            gR = R.T @ one_N2\n",
    "            T = jnp.diag(gR)\n",
    "        return Q, R, T, errs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f4e86dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalRefinementOT:\n",
    "    \"\"\"\n",
    "    Classe pour effectuer le raffinage hiérarchique OT en JAX.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 C: jnp.ndarray,\n",
    "                 rank_schedule: List[int],\n",
    "                 solver: Callable = FRLC_opt,\n",
    "                 solver_params: Union[Dict[str, Any], None] = None,\n",
    "                 device: str = 'cpu',\n",
    "                 base_rank: int = 1,\n",
    "                 clustering_type: str = 'soft',\n",
    "                 plot_clusterings: bool = False,\n",
    "                 parallel: bool = False,\n",
    "                 num_processes: Union[int, None] = None):\n",
    "        # Matrice de coût et paramètres initiaux\n",
    "        self.C = jnp.array(C)                     # Coût en tant que jnp.array\n",
    "        self.rank_schedule = rank_schedule\n",
    "        self.solver = solver\n",
    "        self.device = device\n",
    "        self.base_rank = base_rank\n",
    "        self.clustering_type = clustering_type\n",
    "        self.plot_clusterings = plot_clusterings\n",
    "        self.parallel = parallel\n",
    "        self.num_processes = num_processes\n",
    "\n",
    "        self.X, self.Y = None, None\n",
    "        self.N = self.C.shape[0]\n",
    "        self.Monge_clusters = None\n",
    "\n",
    "        # Paramètres par défaut du solveur FRLC\n",
    "        default_solver_params = {\n",
    "            'gamma': 30,\n",
    "            'max_iter': 60,\n",
    "            'min_iter': 25,\n",
    "            'max_inneriters_balanced': 100,\n",
    "            'max_inneriters_relaxed': 40,\n",
    "            'printCost': False,\n",
    "            'tau_in': 100000\n",
    "        }\n",
    "        if solver_params is not None:\n",
    "            default_solver_params.update(solver_params)\n",
    "        self.solver_params = default_solver_params\n",
    "\n",
    "        assert self.C.shape[0] == self.C.shape[1], \\\n",
    "            \"La matrice de coût doit être carrée (|X| = |Y| = N)\"\n",
    "\n",
    "    @classmethod\n",
    "    def init_from_point_clouds(cls,\n",
    "                               X: jnp.ndarray,\n",
    "                               Y: jnp.ndarray,\n",
    "                               rank_schedule: List[int],\n",
    "                               distance_rank_schedule: Union[List[int], None] = None,\n",
    "                               solver: Callable = FRLC_LR_opt,\n",
    "                               solver_params: Union[Dict[str, Any], None] = None,\n",
    "                               device: str = 'cpu',\n",
    "                               base_rank: int = 1,\n",
    "                               clustering_type: str = 'soft',\n",
    "                               plot_clusterings: bool = False,\n",
    "                               parallel: bool = False,\n",
    "                               num_processes: Union[int, None] = None,\n",
    "                               sq_Euclidean: bool = False):\n",
    "        \"\"\"\n",
    "        Constructeur à partir de nuages de points X, Y.\n",
    "        \"\"\"\n",
    "        obj = cls.__new__(cls)\n",
    "        obj.X = jnp.array(X)\n",
    "        obj.Y = jnp.array(Y)\n",
    "        obj.rank_schedule = rank_schedule\n",
    "        obj.distance_rank_schedule = rank_schedule if distance_rank_schedule is None else distance_rank_schedule\n",
    "        obj.solver = solver\n",
    "        obj.device = device\n",
    "        obj.base_rank = base_rank\n",
    "        obj.clustering_type = clustering_type\n",
    "        obj.plot_clusterings = plot_clusterings\n",
    "        obj.parallel = parallel\n",
    "        obj.num_processes = num_processes\n",
    "        obj.N = X.shape[0]\n",
    "        obj.C = None\n",
    "        obj.Monge_clusters = None\n",
    "        obj.sq_Euclidean = sq_Euclidean\n",
    "\n",
    "        default_solver_params = {\n",
    "            'gamma': 30,\n",
    "            'max_iter': 60,\n",
    "            'min_iter': 25,\n",
    "            'max_inneriters_balanced': 100,\n",
    "            'max_inneriters_relaxed': 40,\n",
    "            'printCost': False,\n",
    "            'tau_in': 100000\n",
    "        }\n",
    "        if solver_params is not None:\n",
    "            default_solver_params.update(solver_params)\n",
    "        obj.solver_params = default_solver_params\n",
    "\n",
    "        assert X.shape[0] == Y.shape[0], \"Assume |X| = |Y| = N\"\n",
    "        return obj\n",
    "\n",
    "    def run(self, return_as_coupling: bool = False):\n",
    "        \"\"\"\n",
    "        Lance le raffinage hiérarchique (série ou parallèle).\n",
    "        \"\"\"\n",
    "        if self.parallel:\n",
    "            return self._hierarchical_refinement_parallelized(return_as_coupling=return_as_coupling)\n",
    "        else:\n",
    "            return self._hierarchical_refinement(return_as_coupling=return_as_coupling)\n",
    "\n",
    "    def _hierarchical_refinement(self, return_as_coupling: bool = False):\n",
    "        \"\"\"\n",
    "        Raffinement hiérarchique mono-processus.\n",
    "        \"\"\"\n",
    "        # Partition initiale (tous les points dans un seul cluster)\n",
    "        F_t = [(jnp.arange(self.N), jnp.arange(self.N))]\n",
    "        for i, rank_level in enumerate(self.rank_schedule):\n",
    "            F_tp1 = []\n",
    "            is_last = (i == len(self.rank_schedule) - 1)\n",
    "            if is_last:\n",
    "                fin_iters = int(self.N) // int(jnp.prod(jnp.array(self.rank_schedule[:i+1])))\n",
    "                print(f'Last level, chunk-size {rank_level}, {fin_iters} itérations.')\n",
    "\n",
    "            j = 0\n",
    "            for (idxX, idxY) in F_t:\n",
    "                if is_last:\n",
    "                    print(f'{j}/{fin_iters} itérations finalistes')\n",
    "                    j += 1\n",
    "\n",
    "                # Si cluster arrivé à la taille base_rank, on le conserve tel quel\n",
    "                if len(idxX) <= self.base_rank or len(idxY) <= self.base_rank:\n",
    "                    F_tp1.append((idxX, idxY))\n",
    "                    continue\n",
    "\n",
    "                # Résoudre sous-problème d'OT (coût explicite ou low-rank sur distance)\n",
    "                if self.C is not None:\n",
    "                    Q, R = self._solve_prob(idxX, idxY, rank_level)\n",
    "                else:\n",
    "                    rank_D = self.distance_rank_schedule[i]\n",
    "                    Q, R = self._solve_LR_prob(idxX, idxY, rank_level, rank_D)\n",
    "\n",
    "                # Calcul de la nouvelle taille de cluster (capacités)\n",
    "                capacity = int(self.N) // int(jnp.prod(jnp.array(self.rank_schedule[:i+1])))\n",
    "                idx_seenX = jnp.arange(Q.shape[0])\n",
    "                idx_seenY = jnp.arange(R.shape[0])\n",
    "\n",
    "                # Clustering \"soft\" ou \"hard\"\n",
    "                if self.clustering_type == 'soft':\n",
    "                    for z in range(rank_level):\n",
    "                        # top-k sur les colonnes de Q et R\n",
    "                        _, topk_X = jax.lax.top_k(Q[idx_seenX, z], capacity)\n",
    "                        idxX_z = idxX[idx_seenX[topk_X]]\n",
    "                        _, topk_Y = jax.lax.top_k(R[idx_seenY, z], capacity)\n",
    "                        idxY_z = idxY[idx_seenY[topk_Y]]\n",
    "                        F_tp1.append((idxX_z, idxY_z))\n",
    "                        # Retirer ces indices pour la suite\n",
    "                        idx_seenX = idx_seenX[~jnp.isin(idx_seenX, idx_seenX[topk_X])]\n",
    "                        idx_seenY = idx_seenY[~jnp.isin(idx_seenY, idx_seenY[topk_Y])]\n",
    "\n",
    "                elif self.clustering_type == 'hard':\n",
    "                    # Assignations par argmax\n",
    "                    zX = jnp.argmax(Q, axis=1)\n",
    "                    zY = jnp.argmax(R, axis=1)\n",
    "                    for z in range(rank_level):\n",
    "                        idxX_z = idxX[zX == z]\n",
    "                        idxY_z = idxY[zY == z]\n",
    "                        # On s’assure que c’est effectivement un hard-clustering\n",
    "                        assert len(idxX_z) == len(idxY_z) == capacity, \\\n",
    "                            \"Cluster déséquilibre ou pas du hard-clustering!\"\n",
    "                        F_tp1.append((idxX_z, idxY_z))\n",
    "\n",
    "            F_t = F_tp1\n",
    "\n",
    "        self.Monge_clusters = F_t\n",
    "        if return_as_coupling:\n",
    "            return self._compute_coupling_from_Ft()\n",
    "        else:\n",
    "            return self.Monge_clusters\n",
    "\n",
    "    def _hierarchical_refinement_parallelized(self, return_as_coupling: bool = False):\n",
    "        # Non implémenté dans cette classe\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _solve_LR_prob(self, idxX, idxY, rank_level, rankD, eps=0.04):\n",
    "        \"\"\"\n",
    "        Solve sub-problème OT en utilisant la factorisation low-rank de la distance.\n",
    "        \"\"\"\n",
    "        _x0 = self.X[idxX]    # Extrait les points X\n",
    "        _x1 = self.Y[idxY]    # Extrait les points Y\n",
    "        if rankD < _x0.shape[0]:\n",
    "            # Calcul des facteurs de la matrice de distance\n",
    "            C_factors, A_factors, B_factors = self.get_dist_mats(_x0, _x1, rankD, eps, self.sq_Euclidean)\n",
    "            Q, R, _, _ = self.solver(\n",
    "                C_factors, A_factors, B_factors,\n",
    "                gamma=self.solver_params['gamma'],\n",
    "                r=rank_level,\n",
    "                max_iter=self.solver_params['max_iter'],\n",
    "                min_iter=self.solver_params['min_iter'],\n",
    "                max_inneriters_balanced=self.solver_params['max_inneriters_balanced'],\n",
    "                max_inneriters_relaxed=self.solver_params['max_inneriters_relaxed'],\n",
    "                diagonalize_return=True,\n",
    "                tau_in=self.solver_params['tau_in']\n",
    "            )\n",
    "        else:\n",
    "            # Cas final (sous-cluster) : calcul direct des distances\n",
    "            if self.sq_Euclidean:\n",
    "                # Distance euclidienne au carré\n",
    "                C_XY = jnp.linalg.norm(_x0[:, None, :] - _x1[None, :, :], axis=2)**2\n",
    "            else:\n",
    "                # Distance euclidienne normale\n",
    "                C_XY = jnp.linalg.norm(_x0[:, None, :] - _x1[None, :, :], axis=2)\n",
    "            Q, R, _, _ = FRLC_opt(\n",
    "                C_XY,\n",
    "                gamma=self.solver_params['gamma'],\n",
    "                r=rank_level,\n",
    "                max_iter=self.solver_params['max_iter'],\n",
    "                min_iter=self.solver_params['min_iter'],\n",
    "                max_inneriters_balanced=self.solver_params['max_inneriters_balanced'],\n",
    "                max_inneriters_relaxed=self.solver_params['max_inneriters_relaxed'],\n",
    "                diagonalize_return=True,\n",
    "                tau_in=self.solver_params['tau_in']\n",
    "            )\n",
    "        return Q, R\n",
    "\n",
    "    def _solve_prob(self, idxX, idxY, rank_level):\n",
    "        \"\"\"\n",
    "        Solve sous-problème OT en indexant la sous-matrice de coût explicite.\n",
    "        \"\"\"\n",
    "        C_sub = self.C[idxX][:, idxY]\n",
    "        Q, R, _, _ = self.solver(\n",
    "            C_sub,\n",
    "            gamma=self.solver_params['gamma'],\n",
    "            r=rank_level,\n",
    "            max_iter=self.solver_params['max_iter'],\n",
    "            min_iter=self.solver_params['min_iter'],\n",
    "            max_inneriters_balanced=self.solver_params['max_inneriters_balanced'],\n",
    "            max_inneriters_relaxed=self.solver_params['max_inneriters_relaxed'],\n",
    "            diagonalize_return=True,\n",
    "            tau_in=self.solver_params['tau_in'],\n",
    "            dtype=C_sub.dtype\n",
    "        )\n",
    "        return Q, R\n",
    "\n",
    "    def _compute_coupling_from_Ft(self):\n",
    "        \"\"\"\n",
    "        Construit la matrice de couplage dense à partir des clusters Monge map.\n",
    "        \"\"\"\n",
    "        size = (self.N, self.N)\n",
    "        P = jnp.zeros(size)\n",
    "        for idx1, idx2 in self.Monge_clusters:\n",
    "            for i in range(idx1.shape[0]):\n",
    "                P = P.at[idx1[i], idx2[i]].set(1)\n",
    "        # On normalise par N (masse uniformément répartie)\n",
    "        return P / self.N\n",
    "\n",
    "    def compute_OT_cost(self):\n",
    "        \"\"\"\n",
    "        Calcule le coût OT associé aux clusters Monge (sans construire explicitement le couplage).\n",
    "        \"\"\"\n",
    "        cost = 0.0\n",
    "        for idx1, idx2 in self.Monge_clusters:\n",
    "            if self.C is not None:\n",
    "                cost += jnp.sum(self.C[idx1, idx2])\n",
    "            else:\n",
    "                if self.sq_Euclidean:\n",
    "                    cost += jnp.sum((self.X[idx1] - self.Y[idx2])**2)\n",
    "                else:\n",
    "                    cost += jnp.linalg.norm(self.X[idx1] - self.Y[idx2])\n",
    "        return cost / self.N\n",
    "\n",
    "    def get_dist_mats(self, _x0, _x1, rankD, eps, sq_Euclidean):\n",
    "        \"\"\"\n",
    "        Retourne les facteurs de la matrice de distance low-rank.\n",
    "        \"\"\"\n",
    "        if sq_Euclidean:\n",
    "            # Facteurs pour une distance euclidienne au carré\n",
    "            C_factors = compute_lr_sqeuclidean_matrix(_x0, _x1, True)\n",
    "            A_factors = None\n",
    "            B_factors = None\n",
    "        else:\n",
    "            # Low-rank factorisation pour distance standard\n",
    "            C_factors = self.ret_normalized_cost(_x0, _x1, rankD, eps)\n",
    "            A_factors = None\n",
    "            B_factors = None\n",
    "        return C_factors, A_factors, B_factors\n",
    "\n",
    "    def ret_normalized_cost(self, X, Y, rankD, eps):\n",
    "        \"\"\"\n",
    "        Facteur de coût normalisé via factorisation low-rank de distance.\n",
    "        \"\"\"\n",
    "        C1, C2 = utils__low_rank_distance_factorization(\n",
    "            X, Y, r=rankD, eps=eps\n",
    "        )\n",
    "        c = (jnp.max(C1)**0.5) * (jnp.max(C2)**0.5)\n",
    "        C1 = (C1 / c).astype(X.dtype)\n",
    "        C2 = (C2 / c).astype(X.dtype)\n",
    "        return C1, C2\n",
    "\n",
    "def compute_lr_sqeuclidean_matrix(X_s, X_t, rescale_cost, device=None, dtype=None):\n",
    "    \"\"\"\n",
    "    Calcul de la factorisation low-rank de la distance euclidienne au carré.\n",
    "    \"\"\"\n",
    "    dtype = X_s.dtype\n",
    "    ns, _ = X_s.shape\n",
    "    nt, _ = X_t.shape\n",
    "\n",
    "    sum_Xs_sq = jnp.sum(X_s ** 2, axis=1).reshape(ns, 1)\n",
    "    ones_ns = jnp.ones((ns, 1), dtype=dtype)\n",
    "    neg_two_Xs = -2 * X_s\n",
    "    M1 = jnp.concatenate([sum_Xs_sq, ones_ns, neg_two_Xs], axis=1)\n",
    "\n",
    "    ones_nt = jnp.ones((nt, 1), dtype=dtype)\n",
    "    sum_Xt_sq = jnp.sum(X_t ** 2, axis=1).reshape(nt, 1)\n",
    "    M2 = jnp.concatenate([ones_nt, sum_Xt_sq, X_t], axis=1)\n",
    "\n",
    "    if rescale_cost:\n",
    "        max_M1 = jnp.max(M1)\n",
    "        max_M2 = jnp.max(M2)\n",
    "        if max_M1 > 0:\n",
    "            M1 = M1 / jnp.sqrt(max_M1)\n",
    "        if max_M2 > 0:\n",
    "            M2 = M2 / jnp.sqrt(max_M2)\n",
    "\n",
    "    return (M1, M2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fc0dfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized rank-annealing schedule: [2, 1250]\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "Initial Wasserstein cost: 4.628808975219727, GW-cost: 0, Total cost: 4.628808975219727\n",
      "Final Wasserstein cost: 4.5346856117248535, GW-cost: 0, Total cost: 4.5346856117248535\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last level, chunk-size 1250, 1 itérations.\n",
      "0/1 itérations finalistes\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "1/1 itérations finalistes\n",
      "Iteration: 0\n",
      "Iteration: 25\n",
      "Iteration: 50\n",
      "HR-OT cost: 18.2893009185791\n"
     ]
    }
   ],
   "source": [
    "rank_schedule = rank_annealing__optimal_rank_schedule( X.shape[0] , hierarchy_depth = 6, max_Q = int(2**11), max_rank = 64 )\n",
    "\n",
    "try:\n",
    "    hrot_lr = HierarchicalRefinementOT.init_from_point_clouds(X, Y, rank_schedule, base_rank=1)\n",
    "    F = hrot_lr.run(return_as_coupling=False)\n",
    "    cost_hrot_lr = hrot_lr.compute_OT_cost()\n",
    "    print(f'HR-OT cost: {cost_hrot_lr}')\n",
    "except Exception as e:\n",
    "    print(f'HROT-LR failed for sample size: {e}')\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80c7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2bed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
